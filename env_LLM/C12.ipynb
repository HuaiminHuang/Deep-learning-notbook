{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404b5170",
   "metadata": {},
   "source": [
    "# SFT--Supervised Fine-Turning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6ec8e",
   "metadata": {},
   "source": [
    "1. 背景：预训练模型（如 GPT、LLaMA）  \n",
    "大模型通常先通过无监督预训练（如语言建模）在海量文本上学习通用语言表示，具备广泛的语言理解和生成能力。  \n",
    "2. SFT 的目标  \n",
    "通过有标签的数据（输入-输出对）对预训练模型进行微调，使其在特定任务或行为上表现更好，比如：  \n",
    "* 对话系统（如 ChatGPT）\n",
    "* 问答系统\n",
    "* 指令跟随（instruction following）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3ffbd",
   "metadata": {},
   "source": [
    "1.数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36776051",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6446e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files=\"C:/Users/hhm18/Desktop/深度学习/env_LLM/firefly-train-1.1M.jsonl\", split=\"train[:500]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148e8a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['kind', 'input', 'target'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb652001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'JinYongGeneration',\n",
       " 'input': '武侠小说续写：\\n吴坎？”万圭道：“是！我在后园中见这贱人藏好剑谱，便远远地跟着',\n",
       " 'target': '她，哪知道她……她到了回廊上，竟和吴坎那厮勾勾搭搭，这淫妇……好不要脸！”万震山沉吟道：“我看她平素为人倒也规矩端正，不像是这样子的人。你没瞧错么？他二人说些什么？”万圭道：“孩儿怕他们知觉，不敢走得太近，回廊上没隐蔽的地方，只有躲在墙角后面。这两个狗男女说话很轻，没能完全听到，可是……可是也听到了大半。”\\n\\u3000\\u3000万震山“嗯”了一声，道：“孩儿，你别气急。大丈夫何患无妻？咱们既得了剑谱，又奄明了这中间的秘密，转眼便可富甲天下，你便要买一百个姬妾，那也容易得紧。你坐下，慢慢地说！”\\n\\u3000\\u3000只听得床板格格两响，万圭坐到了床上，气喘喘地道：“那淫妇藏好书本，很是得意，嘴里居然哼着小曲。那奸夫一见到她，满脸堆欢，说道：‘今晚三更，我在柴房中等你，可别忘了！’的的确确是这几句话，我听得清清楚楚的。”万震山怒道：“那小淫妇又怎么说？”万圭道：“她……她说道：‘没好死的，狗胆子这么大，连命也不要了！’”\\n\\u3000\\u3000戚芳在窗外只听得心乱如麻：“他……他二人口口声声地骂我淫妇，怎……怎么能如此地冤枉人家？三哥，我是一片为你之心，要夺回解药，治你之伤。你却这般辱我，可还有良心没有？”\\n\\u3000\\u3000只听万圭续道：“我……我听了他们这么说，心头火起，恨不得拔剑上前将二人杀了。只是我没带剑，又伤后没力，不能跟他们明争，当即赶回房去，免得那贼淫妇回房时不见到我，起了疑心。奸夫淫妇以后再说什么，我就没再听见。”万震山道：“哼，有其父必有其女，果然一门都是无耻之辈。咱们先去取了剑谱，再到柴房外守候。捉奸捉双，叫这对狗男女死而无怨！”\\n\\u3000\\u3000万圭道：“那淫妇恋奸情热，等不到三更天，早就出去了，这会儿……这会儿……”说着牙齿咬得格格直响。万震山道：“那么咱们即刻便去。你拿好了剑，可先别出手，等我斩断他二人的手足，再由你亲手取这双狗男女的性命。”\\n\\u3000\\u3000只见房门推开，万震山左手托在万圭腋下，二人径奔后园。\\n\\u3000\\u3000戚芳靠在墙上，眼泪扑簌簌地从衣襟上滚下来。她只盼治好丈夫的伤，他却对自己如此起疑。父亲一去不返，狄师哥受了自己的冤枉，现今……现今丈夫又这般对待自己，这样的日子，怎么还过得下去？她心中茫然一片，真不想活了，没想到去和丈夫理论，没想到叫吴坎来对质，只全身瘫痪了一般，靠在墙上。\\n\\u3000\\u3000过不多久，只听得脚步声响，万氏父子回到厅上，站定了低声商议。万圭道：“爹，怎不就在柴房里杀了吴坎？”万震山道：“柴房里只奸夫一人'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8643136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f191cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c53344",
   "metadata": {},
   "source": [
    "需要处理成输入格式一致  \n",
    "\n",
    "<|im_start|>system  \n",
    "我是一个非常棒的人工智能助手。<|im_end|>  \n",
    "<|im_start|>user  \n",
    "可以简单介绍你自己吗？<|im_end|>  \n",
    "<|im_start|>assistant  \n",
    "我是Xxxxxxxxxxxxxxxxxxx。<|im_end|>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ac2201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_prompt(example):\n",
    "    chat = [\n",
    "        {\"role\": \"system\", \"content\": \"我是一个非常棒的人工智能助手。\"},\n",
    "        {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"target\"]}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "dataset = test_dataset.map(format_prompt, remove_columns=test_dataset.column_names)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a374934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<|im_start|>system\\n我是一个非常棒的人工智能助手。<|im_end|>\\n<|im_start|>user\\n自然语言推理：\\n前提：家里人心甘情愿地养他,还有几家想让他做女婿的\\n假设：他是被家里人收养的孤儿<|im_end|>\\n<|im_start|>assistant\\n中立<|im_end|>\\n'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a215c22",
   "metadata": {},
   "source": [
    "2.加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f333b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", \n",
    "                                             trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", \n",
    "                                          trust_remote_code=True)\n",
    "tokenizer.padding_side = \"left\" # 自回归模型（只能从左到右看），设置padding在左侧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba73eb8",
   "metadata": {},
   "source": [
    "3.配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae9dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 896)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5418483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56c71f",
   "metadata": {},
   "source": [
    "4.训练配置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b46646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Traning arg\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,  \n",
    "    gradient_accumulation_steps=8,    #  实际的batch_size = 2 * 4 = 8\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.03,\n",
    "    logging_steps=10,\n",
    "    # max_seq_length=512,            # 训练时的最大序列长度\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,                    # 每20步保存一次模型正常不会设置这么小\n",
    "    save_total_limit=3,\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=True,\n",
    "    bf16=False,                       # 如果使用A100等支持BF16的GPU，可以设置为True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe36d8a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: trl in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from trl) (1.10.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.55.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from trl) (4.55.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (2.3.1+cu118)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from accelerate>=1.4.0->trl) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.8.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->accelerate>=1.4.0->trl) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->accelerate>=1.4.0->trl) (2021.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tqdm>=4.66.3->datasets>=3.0.0->trl) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from transformers>=4.55.0->trl) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from transformers>=4.55.0->trl) (0.21.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from sympy->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da35ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac7c7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\peft\\mapping_func.py:79: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'Qwen/Qwen2.5-0.5B-Instruct' to 'None'. Please ensure that the correct base model is loaded when loading this checkpoint.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:89: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 04:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.829200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.462200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.941800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.model.save_pretrained(\"C:/Users/hhm18/Desktop/深度学习/env_LLM/result/final_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d2fe2",
   "metadata": {},
   "source": [
    "4.*Merge Adepter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec275772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,898,240 || all params: 499,931,008 || trainable%: 1.1798\n"
     ]
    }
   ],
   "source": [
    "# 查看可训练的参数\n",
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "870554cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\peft\\peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(base_model, \"C:/Users/hhm18/Desktop/深度学习/env_LLM/result/final_result\")\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"C:/Users/hhm18/Desktop/深度学习/env_LLM/result/merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fd7967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "989abe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system  \n",
      "我是一个非常棒的人工智能助手。<|im_end|>  \n",
      "<|im_start|>user  \n",
      "使用翻译成文言文：等到对得到或喜爱的东西已经厌倦，感情随着事物的变化而变化，感慨随之产生。<|im_end|>  \n",
      "<|im_start|>assistant  \n",
      "等到得物已厌倦，情志随事转移；慨叹随之兴起。\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=merged_model, tokenizer=tokenizer, trust_remote_code=True)\n",
    "\n",
    "promopt = \"\"\"<|im_start|>system  \n",
    "我是一个非常棒的人工智能助手。<|im_end|>  \n",
    "<|im_start|>user  \n",
    "使用翻译成文言文：等到对得到或喜爱的东西已经厌倦，感情随着事物的变化而变化，感慨随之产生。<|im_end|>  \n",
    "<|im_start|>assistant  \n",
    "\"\"\"\n",
    "\n",
    "print(pipe(promopt, \n",
    "           max_new_tokens=128, \n",
    "           do_sample=True, \n",
    "           temperature=0.7, \n",
    "           top_p=0.9, \n",
    "           top_k=50)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc0a1623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system  \n",
      "我是一个非常棒的人工智能助手。<|im_end|>  \n",
      "<|im_start|>user  \n",
      "你刚才经过SFT学习到了什么新东西啊？<|im_end|>  \n",
      "<|im_start|>assistant  \n",
      "你好！作为一个人工智能，我没有能力学习或记忆知识。我的“学习”只是通过接收和处理数据来提供信息和服务。如果你有任何问题需要解答，请告诉我。\n"
     ]
    }
   ],
   "source": [
    "promopt = \"\"\"<|im_start|>system  \n",
    "我是一个非常棒的人工智能助手。<|im_end|>  \n",
    "<|im_start|>user  \n",
    "你刚才经过SFT学习到了什么新东西啊？<|im_end|>  \n",
    "<|im_start|>assistant  \n",
    "\"\"\"\n",
    "\n",
    "print(pipe(promopt, \n",
    "           max_new_tokens=128, \n",
    "           do_sample=True, \n",
    "           temperature=0.7, \n",
    "           top_p=0.9, \n",
    "           top_k=50)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da85c6ad-b838-4a61-abd5-19f1cd97360a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
