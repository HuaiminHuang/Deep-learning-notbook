{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7807d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"parquet\", data_files = \"./dataset/wudao/*.parquet\", split=\"train\",)\n",
    "size_need_data = int(len(ds) * 0.05)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return False\n",
    "    \n",
    "    # 1. å»æ‰HTMLæ ‡ç­¾ï¼ˆå¢å¼ºç‰ˆï¼‰\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # æ›´ç¨³å¥çš„HTMLæ ‡ç­¾åŒ¹é…\n",
    "    \n",
    "    # 2. å»æ‰ç©ºæ–‡æœ¬ï¼ˆå¢å¼ºæ£€æŸ¥ï¼‰\n",
    "    if not text.strip():\n",
    "        return False\n",
    "    \n",
    "    # 3. å»æ‰å„ç§ç±»å‹çš„ç”µè¯å·ç \n",
    "    text = re.sub(r'\\b\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}\\b', '', text)  # å¸¦åˆ†éš”ç¬¦çš„ç”µè¯\n",
    "    text = re.sub(r'\\b\\d{11}\\b', '', text)  # 11ä½æ‰‹æœºå·\n",
    "    text = re.sub(r'\\b\\d{4}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}\\b', '', text)  # å¸¦åŒºå·çš„ç”µè¯\n",
    "    \n",
    "    # 4. æ‰©å±•å¹¿å‘Šè¯­å’Œæ¨å¹¿å†…å®¹è¯†åˆ«\n",
    "    ad_patterns = [\n",
    "        'å…³æ³¨å…¬ä¼—å·', 'æ‰«ç .*è·å–', 'æ·»åŠ å¾®ä¿¡', 'ç‚¹å‡»ä¸‹æ–¹é“¾æ¥',\n",
    "        'è¯¦æƒ…è¯·è®¿é—®', 'é¢†å–ä¼˜æƒ åˆ¸', 'é™æ—¶æŠ˜æ‰£', 'ç«‹å³è´­ä¹°', 'äº†è§£æ›´å¤š',\n",
    "        'æ¬¢è¿è½¬è½½', 'ç‰ˆæƒå£°æ˜', 'å…è´£å£°æ˜', 'æ–‡ç« æ¥æº', 'å‘å¸ƒäº',\n",
    "        'tel', 'ç”µè¯', 'è”ç³»ç”µè¯', 'çƒ­çº¿', 'ä¼é¹…', 'qq', 'qå·'\n",
    "    ]\n",
    "    for pattern in ad_patterns:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    # 5. å¤„ç†URLå’Œç”µå­é‚®ä»¶\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "    \n",
    "    # 6. æ‰©å±•è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦å¤„ç†\n",
    "    text = re.sub(r'[\\U00010000-\\U0010FFFF]', '', text)  # é«˜ä½Unicodeè¡¨æƒ…\n",
    "    text = re.sub(r'[\\u2000-\\u2FFF]', '', text)  # æ‰©å±•æ ‡ç‚¹ã€ç¬¦å·\n",
    "    text = re.sub(r'[\\u3000-\\u303F]', '', text)  # ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼ˆå¯é€‰ï¼‰\n",
    "    text = re.sub(r'[\\[\\]{}<>#*â˜…â—‡Â§â™¡â™¥â™ªâ™¬â–¶â–¼â–ªâ—†â—Â¡â­]', '', text)  # æ›´å¤šç‰¹æ®Šç¬¦å·\n",
    "    \n",
    "    # 7. å¤„ç†é‡å¤æ ‡ç‚¹å’Œæ— æ„ä¹‰å­—ç¬¦åºåˆ—\n",
    "    text = re.sub(r'[!?ã€‚ï¼Œ]{2,}', '.', text)  # å¤šä¸ªé‡å¤æ ‡ç‚¹æ›¿æ¢ä¸ºå•ä¸ª\n",
    "    text = re.sub(r'[\\.]{2,}', '.', text)  # å¤šä¸ªå¥ç‚¹æ›¿æ¢ä¸ºå•ä¸ª\n",
    "    text = re.sub(r'[\\s]+', ' ', text)  # å¤šä¸ªç©ºç™½å­—ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # æ›¿æ¢é‡å¤çš„ç©ºæ ¼\n",
    "    \n",
    "    # 8. å¤„ç†æ— æ„ä¹‰çŸ­æ–‡æœ¬\n",
    "    # å¦‚æœæ¸…æ´—åæ–‡æœ¬å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯æ— æ„ä¹‰å†…å®¹\n",
    "    cleaned_text = text.strip()\n",
    "    if len(cleaned_text) < 64:  # å¯æ ¹æ®å®é™…è°ƒæ•´é˜ˆå€¼\n",
    "        return False\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# æµ‹è¯•\n",
    "raw_text = \"å…³æ³¨å…¬ä¼—å·ABCè·å–èµ„æ–™ğŸ˜„ï¼Œæ‰‹æœºå·13812345678ï¼Œç½‘é¡µé“¾æ¥<a href='x'>é“¾æ¥</a> â˜…ä¸­å›½å…±äº§å…šä¸‡å®å¸‚å§”å‘˜ä¼šç»Ÿä¸€æˆ˜çº¿å·¥ä½œéƒ¨\\nä¸­å›½å…±äº§å…šä¸‡å®å¸‚å§”å‘˜ä¼šç»Ÿä¸€æˆ˜çº¿å·¥ä½œéƒ¨æ˜¯ä¸­å›½å…±äº§å…šä¸‡å®å¸‚å§”å‘˜ä¼šå·¥ä½œéƒ¨é—¨ã€‚\"\n",
    "cleaned_text = clean_text(raw_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e600310",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    ds_clean = ds.filter(lambda x: clean_text(x[\"text\"]))\n",
    "print(ds_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/classification/BERT_classifier_for_wudao/checkpoint-6654\"\n",
    "BERT_model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_clean #.select(range(10000))\n",
    "test = ds_test.add_column(\"labels\", [0] * len(ds_test))\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=False, truncation=True, max_length=512)\n",
    "\n",
    "tokened_dataset = test.map(tokenize, batched=True)\n",
    "tokened_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_args = TrainingArguments(\n",
    "    output_dir=\"./temp_eval\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = BERT_model,\n",
    "    args=test_train_args,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokened_dataset)\n",
    "logits = predictions.predictions  # æ¨¡å‹è¾“å‡ºçš„ logits\n",
    "import numpy as np\n",
    "pred_labels = np.argmax(logits, axis=1)  # è½¬æ¢ä¸ºæ ‡ç­¾\n",
    "print(pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f398ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91535abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
