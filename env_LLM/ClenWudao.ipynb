{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7807d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"parquet\", data_files = \"./dataset/wudao/*.parquet\", split=\"train\",)\n",
    "size_need_data = int(len(ds) * 0.05)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return False\n",
    "    \n",
    "    # 1. 去掉HTML标签（增强版）\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # 更稳健的HTML标签匹配\n",
    "    \n",
    "    # 2. 去掉空文本（增强检查）\n",
    "    if not text.strip():\n",
    "        return False\n",
    "    \n",
    "    # 3. 去掉各种类型的电话号码\n",
    "    text = re.sub(r'\\b\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}\\b', '', text)  # 带分隔符的电话\n",
    "    text = re.sub(r'\\b\\d{11}\\b', '', text)  # 11位手机号\n",
    "    text = re.sub(r'\\b\\d{4}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}\\b', '', text)  # 带区号的电话\n",
    "    \n",
    "    # 4. 扩展广告语和推广内容识别\n",
    "    ad_patterns = [\n",
    "        '关注公众号', '扫码.*获取', '添加微信', '点击下方链接',\n",
    "        '详情请访问', '领取优惠券', '限时折扣', '立即购买', '了解更多',\n",
    "        '欢迎转载', '版权声明', '免责声明', '文章来源', '发布于',\n",
    "        'tel', '电话', '联系电话', '热线', '企鹅', 'qq', 'q号'\n",
    "    ]\n",
    "    for pattern in ad_patterns:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    # 5. 处理URL和电子邮件\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "    \n",
    "    # 6. 扩展表情符号和特殊字符处理\n",
    "    text = re.sub(r'[\\U00010000-\\U0010FFFF]', '', text)  # 高位Unicode表情\n",
    "    text = re.sub(r'[\\u2000-\\u2FFF]', '', text)  # 扩展标点、符号\n",
    "    text = re.sub(r'[\\u3000-\\u303F]', '', text)  # 中文标点符号（可选）\n",
    "    text = re.sub(r'[\\[\\]{}<>#*★◇§♡♥♪♬▶▼▪◆●¡⭐]', '', text)  # 更多特殊符号\n",
    "    \n",
    "    # 7. 处理重复标点和无意义字符序列\n",
    "    text = re.sub(r'[!?。，]{2,}', '.', text)  # 多个重复标点替换为单个\n",
    "    text = re.sub(r'[\\.]{2,}', '.', text)  # 多个句点替换为单个\n",
    "    text = re.sub(r'[\\s]+', ' ', text)  # 多个空白字符替换为单个空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # 替换重复的空格\n",
    "    \n",
    "    # 8. 处理无意义短文本\n",
    "    # 如果清洗后文本太短，可能是无意义内容\n",
    "    cleaned_text = text.strip()\n",
    "    if len(cleaned_text) < 64:  # 可根据实际调整阈值\n",
    "        return False\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# 测试\n",
    "raw_text = \"关注公众号ABC获取资料😄，手机号13812345678，网页链接<a href='x'>链接</a> ★中国共产党万宁市委员会统一战线工作部\\n中国共产党万宁市委员会统一战线工作部是中国共产党万宁市委员会工作部门。\"\n",
    "cleaned_text = clean_text(raw_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e600310",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    ds_clean = ds.filter(lambda x: clean_text(x[\"text\"]))\n",
    "print(ds_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/classification/BERT_classifier_for_wudao/checkpoint-6654\"\n",
    "BERT_model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_clean #.select(range(10000))\n",
    "test = ds_test.add_column(\"labels\", [0] * len(ds_test))\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=False, truncation=True, max_length=512)\n",
    "\n",
    "tokened_dataset = test.map(tokenize, batched=True)\n",
    "tokened_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_args = TrainingArguments(\n",
    "    output_dir=\"./temp_eval\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = BERT_model,\n",
    "    args=test_train_args,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokened_dataset)\n",
    "logits = predictions.predictions  # 模型输出的 logits\n",
    "import numpy as np\n",
    "pred_labels = np.argmax(logits, axis=1)  # 转换为标签\n",
    "print(pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f398ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91535abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
