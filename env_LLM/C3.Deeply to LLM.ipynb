{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e23fa035-0d3b-469b-932f-128ab7c6d48b",
   "metadata": {},
   "source": [
    "# C3.深入TransformerLLM\n",
    "* tansformer LLM不同输入和输出的区别\n",
    "* 不同的output可以有什么用\n",
    "* 了解RMSNorm, 和layerNorm的区别\n",
    "* 了解KVcache的原理，以及在推理的时候怎么使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466e1d39-190d-44f5-8b10-664cb6e2eceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58221dd8181647928808655126a120c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
    "import torch\n",
    "# 修改为半精度\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # 或 load_in_8bit=True\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model_DS = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",            # 让库自动把层拆分到 CPU/GPU\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20459877-3f86-40ee-ad86-c5fb3365d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:89: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《静夜思》的作者是谁？  \n",
      "**答案**\n",
      "李白\n",
      "\n",
      "---\n",
      "\n",
      "**问题二：**  \n",
      "《登鹳雀楼》的作者是谁？  \n",
      "**答案**\n",
      "王维\n",
      "\n",
      "---\n",
      "\n",
      "**问题三：**  \n",
      "《相思》的作者是谁？  \n",
      "**答案**\n",
      "李白\n",
      "\n",
      "---\n",
      "\n",
      "**问题四：**  \n",
      "《水调歌头》的作者是谁？  \n",
      "**答案**\n",
      "苏轼\n",
      "\n",
      "---\n",
      "\n",
      "**问题五：**  \n",
      "《别 Poem》的作者是谁？  \n",
      "**答案**\n",
      "杜甫\n",
      "\n",
      "---\n",
      "\n",
      "**问题六：**  \n",
      "《行路难》的作者是谁？  \n",
      "**答案**\n",
      "李白\n",
      "\n",
      "---\n",
      "\n",
      "**问题七：**  \n",
      "《\n"
     ]
    }
   ],
   "source": [
    "prompt = '《静夜思》的作者是谁？'\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(model_DS.device)\n",
    "generation_output = model_DS.generate(\n",
    "    input_ids = inputs.input_ids,\n",
    "    max_new_tokens = 128, \n",
    ")\n",
    "\n",
    "print(tokenizer.decode(generation_output[0],\n",
    "                       skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4888bb-96b1-4818-a548-5df35cce7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"《静夜思》的作者是谁？\"}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d7f0b2-1b5f-4fb8-abe7-aa5eba0f6963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151646, 151646, 151644,  26940,  99541,  99530,  90663,  25067,   9370,\n",
       "          57421, 105518,  11319, 151645, 151648,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(model_DS.device)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c641f78e-50f0-418f-9219-ce6d1afce26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>《静夜思》的作者是谁？<｜Assistant｜><think>\n",
      "嗯，用户问的是《静夜思》的作者是谁。我记得这是一首中国古典诗歌，可能来自唐代。让我想想，应该是李白吧，因为李白是唐代的大诗人，写过很多著名的诗篇。《静夜思》是李白写的，我记得他写这首诗的时候，应该是比较年轻的时候，大概在20多岁的时候。这首诗表达了诗人在寂静的夜晚，独自思考和对自然的感悟，特别是对床前明月光的感慨。所以，综合来看，作者应该是李白。\n",
      "</think>\n",
      "\n",
      "《静夜思》是唐代诗人李白创作的一首五言绝句。这首诗以简洁明快的笔触，描绘了诗人在寂静的夜晚独自望月的情景，表达了对床前明月光的无限感慨。诗中“床前明月光，疑是地上霜”一句，既展现了月光的皎洁，又暗示了诗人的孤独与思念。整首诗语言简练，意境深远，是李白诗歌中的佳作之一。\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model_DS.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a00431-0629-4c4a-9242-7e90ea93faa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 232])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16bce818-3d9c-4502-b37f-69f4516ed397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(152064, 3584)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2Attention(\n",
      "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3235c40e-141e-4ea0-ba2b-13c276b1f43b",
   "metadata": {},
   "source": [
    "## 不同的output怎么用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05fe49-ff6d-4c7f-8a1b-380aee8c11cb",
   "metadata": {},
   "source": [
    "### model常用的API：\n",
    "* 1.generte\n",
    "* 2.model.model\n",
    "* 3.model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0977d8c-359d-4d44-a608-1d683eb79099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"黄河之水天上来，\", return_tensors=\"pt\").to(model_DS.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = model_DS.model(**inputs).last_hidden_state  # [1, seq_len, 3584]\n",
    "    logits = model_DS.lm_head(hidden)                    # [1, seq_len, vocab_size]\n",
    "\n",
    "# 拿最后一个 token 的 logits 做自定义 softmax\n",
    "next_logits = logits[0, -1, :]\n",
    "# 例：给“李白”加 1.0 分，给“王维”减 1.0 分\n",
    "bias = torch.zeros_like(next_logits)\n",
    "bias[tokenizer.convert_tokens_to_ids(\"李白\")] += 1.0\n",
    "bias[tokenizer.convert_tokens_to_ids(\"王维\")] -= 1.0\n",
    "biased_logits = next_logits + bias\n",
    "probs = torch.softmax(biased_logits / 0.7, dim=-1)\n",
    "next_id = torch.multinomial(probs, num_samples=1).item()\n",
    "print(tokenizer.decode([next_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b53d4e-f250-4449-984a-b18f7bd97548",
   "metadata": {},
   "source": [
    "### 只要语义向量（sentence/Document Embedding）\n",
    "* **也可以称为裸Transformer**。把目标（一段话或者一个文档）转化为向量做检索、聚类、RAG等。\n",
    "* 不经过lm_head 维度永远是hidden_dim\n",
    "* 拿取最后一层用.last_hiden_state，拿取所有层.hidden_states(需要output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f87c499-9028-4ded-a614-f044285e99c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7231,  1.2568, -0.1191,  ..., -0.4170, -0.0101, -0.2422],\n",
       "          [ 1.2402,  1.5508, -0.1016,  ..., -0.2079,  0.2314, -0.2544],\n",
       "          [-1.7139, -1.7041, -0.5479,  ...,  0.9868, -1.5801, -1.1914],\n",
       "          ...,\n",
       "          [ 0.7939, -3.4570, -0.8657,  ..., -0.3997,  3.1621,  3.0957],\n",
       "          [-1.8633, -1.4092, -1.1602,  ..., -3.8730, -0.0213,  3.1523],\n",
       "          [-0.8433, -3.7109, -1.3438,  ...,  1.8867, -0.8066,  0.9956]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " torch.Size([1, 7, 3584]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '人工智能的发展日新月异'\n",
    "inputs = tokenizer(text, return_tensors='pt').to(model_DS.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden = model_DS.model(**inputs).last_hidden_state #[1, B,3584]\n",
    "last_hidden, last_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab3e3e2-a227-48ed-a83d-4cd810f1c676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0  shape: torch.Size([1, 7, 3584])\n",
      "Layer 10 shape: torch.Size([1, 7, 3584])\n",
      "Layer 28 shape: torch.Size([1, 7, 3584])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model_DS.model(**inputs, output_hidden_states=True)\n",
    "\n",
    "# 1. 隐藏层状态 （0是词嵌入层）\n",
    "for i in [0, 10, 28]:\n",
    "    h = outputs.hidden_states[i]\n",
    "    print(f\"Layer {i:<2d} shape: {h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4078b14-512b-4377-b20d-6c698f8a5770",
   "metadata": {},
   "source": [
    "### generate 像gpt一样给他一句上文，他回答下文\n",
    "* 想要聊天格式，需要配合使用tokenizer。apply_chat_template(...)详细见之前的例子\n",
    "* generate 自动循环：把上一步的token又喂给模型，直到触发长度或者eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0dd79a5-73e2-4790-af10-10dd051e26a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>《静夜思》的作者是谁？<｜Assistant｜><think>\n",
      "好的，我现在要回答的问题是：“《静夜思》的作者是谁？”首先，我需要回忆一下这首诗的内容。我记得这是一首很著名的五言绝句，作者应该是唐代的诗人。可能的作者包括李白、杜甫、王维、孟浩然这些比较出名的诗人。\n",
      "\n",
      "接下来，我应该分析一下这首诗的结构和内容。《静夜思》通常是这样写的：“床前明月光，疑是地上霜。举头望明月，低头思故乡。” 这首诗表达了诗人在寂静的夜晚，望着明月，心中思念家乡的情感。\n",
      "\n",
      "然后，我需要确定这首诗的作者是谁。我记得杜甫有一首类似的诗，可能就是《静夜思》。但是，让我再仔细想想，杜甫的诗通常比较现实，而李白的诗则更浪漫。杜甫的诗多涉及社会现实，所以《静夜思》可能不是他的作品。\n",
      "\n",
      "我还记得，王维的诗多描绘自然景色，比如《相思》或者《山中与裴秀才迪书》。而孟浩然的诗则以山水田园著称。所以，排除掉这些可能性，剩下的可能性是杜甫。\n",
      "\n",
      "不过，我有点不确定，所以需要确认一下。我可以回想一下杜甫的其他作品，比如《秋露》、《夜雨》等，或者是否有其他类似的诗。或者，我可以回想一下杜甫的诗中是否有提到明月光或者类似的意象。\n",
      "\n",
      "另外，我还记得杜甫的诗中有一首是《绝句二首》，其中有一首可能就是《静夜思》。或者，是不是杜甫写的呢？\n",
      "\n",
      "为了确保准确性，我可以回忆一下杜甫的其他作品，比如他的诗风通常比较沉郁，而《静夜思》的意境比较宁静，这可能符合杜甫的风格。而李白的诗通常更倾向于豪放，所以不太可能。\n",
      "\n",
      "所以，综合以上分析，我认为《静夜思》的作者是杜甫。\n",
      "</think>\n",
      "\n",
      "《静夜思》的作者是杜甫。这首诗是杜甫创作的一首五言绝句，描绘了诗人静夜独思的情景，表达了对家乡的思念之情。诗中“床前明月光，疑是地上霜”一句，既描绘了自然景象，又暗示了诗人内心的孤独与思念。整首诗语言简洁，意境深远，展现了杜甫诗歌的沉郁\n"
     ]
    }
   ],
   "source": [
    "## 1.generate\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(model_DS.device)\n",
    "\n",
    "out = model_DS.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True, #Fales表示贪心\n",
    "    temperature=0.7, top_p=0.7, #do_sample=True后生效表示采样\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(out[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f5290-880f-4002-bb6d-22bcc4cfca2c",
   "metadata": {},
   "source": [
    "## LayerNrom和RMSMNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca6a83-8e19-48bd-9470-7fe7e29a8afe",
   "metadata": {},
   "source": [
    "$$\\mathrm{LayerNorm}(x) = \\gamma \\frac{x - E(x)}{\\sqrt{\\mathrm{Var}(x) + \\epsilon}}+\\beta, \\hspace{0.5em}\\mathrm{RMSNorm}(x) = \\gamma \\frac{x }{\\sqrt{\\mathrm{RMS}(x) + \\epsilon}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9f76e-2853-4be6-b26a-4bfb2dfb9f38",
   "metadata": {},
   "source": [
    "*LayerNorm*可学习参数：$\\gamma$ （缩放）, $\\beta$（平移），   \n",
    "*RMSNorm*可学习参数为$\\gamma$且RMS的值：\n",
    "$$ \\mathrm{RMS} = \\sqrt{\\frac{1}{d} \\sum_i^d{x_i^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243b14d-3d9f-4d5c-8728-a180d1324a1c",
   "metadata": {},
   "source": [
    "一句话概括为：LayerNorm 是“中心化+标准化”，RMSNorm 是“直接按能量缩放”，后者在大模型中更高效、更稳定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "927ba8c6-1057-46c2-8109-5a5833695c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(d))\n",
    "        self.bias   = nn.Parameter(torch.zeros(d))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (..., d)\n",
    "        mu  = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        return self.weight * (x - mu) / torch.sqrt(var + self.eps) + self.bias\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(d))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (..., d)\n",
    "        rms = torch.sqrt((x ** 2).mean(dim=-1, keepdim=True) + self.eps)\n",
    "        return self.weight * (x / rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e79d5d6-9721-43e1-aa79-2bb18ab841f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 512\n",
    "x = torch.randn(2, 64, d, device='cuda')\n",
    "\n",
    "ln  = LayerNorm(d).cuda()\n",
    "rms = RMSNorm(d).cuda()\n",
    "\n",
    "y_ln  = ln(x)\n",
    "y_rms = rms(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd8314a-5e11-4d41-b517-d9a93df5ca90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 64, 512]), torch.Size([2, 64, 512]), torch.Size([2, 64, 512]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y_ln.shape, y_rms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e299fb-99bf-4d8b-9b98-043eeb51e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.0773, -2.3764,  0.3967,  ..., -0.4563, -0.6832, -0.9054],\n",
       "          [-0.0786,  0.4967, -0.0893,  ...,  0.9918, -0.8369, -0.3789],\n",
       "          [-1.4796,  0.1962,  1.2425,  ...,  0.8655, -0.7060,  1.0492],\n",
       "          ...,\n",
       "          [-2.1256, -0.2787,  0.6244,  ..., -1.7401,  1.4355,  0.6051],\n",
       "          [ 0.8375, -2.6685,  1.3679,  ...,  1.5058,  1.2796, -1.3957],\n",
       "          [-0.9271,  1.2363, -0.2026,  ...,  1.6328, -0.1499,  0.6450]],\n",
       " \n",
       "         [[-1.0057,  0.6785, -0.7728,  ..., -0.8004,  0.5489,  0.0553],\n",
       "          [ 1.2799, -0.6792, -0.7237,  ...,  0.1049, -0.9991,  0.7057],\n",
       "          [ 0.6977,  0.7180, -1.1208,  ..., -0.5260,  0.3856, -0.0617],\n",
       "          ...,\n",
       "          [-0.0183,  0.7477,  0.9552,  ..., -1.2418, -0.2044,  0.0253],\n",
       "          [-1.4250,  0.3825, -0.3808,  ..., -1.9617,  1.3199, -0.0890],\n",
       "          [-1.1007,  0.6559, -0.6722,  ..., -0.2374, -0.1606,  1.6674]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([[[ 1.0354, -2.4154,  0.3554,  ..., -0.4968, -0.7235, -0.9456],\n",
       "          [-0.0795,  0.4958, -0.0902,  ...,  0.9910, -0.8378, -0.3798],\n",
       "          [-1.5130,  0.1619,  1.2076,  ...,  0.8308, -0.7398,  1.0144],\n",
       "          ...,\n",
       "          [-2.1342, -0.2874,  0.6157,  ..., -1.7487,  1.4268,  0.5965],\n",
       "          [ 0.9161, -2.5783,  1.4448,  ...,  1.5822,  1.3568, -1.3096],\n",
       "          [-0.9641,  1.1977, -0.2401,  ...,  1.5940, -0.1875,  0.6068]],\n",
       " \n",
       "         [[-0.9666,  0.7163, -0.7340,  ..., -0.7615,  0.5868,  0.0935],\n",
       "          [ 1.3093, -0.6489, -0.6934,  ...,  0.1348, -0.9686,  0.7354],\n",
       "          [ 0.7264,  0.7466, -1.0914,  ..., -0.4968,  0.4143, -0.0327],\n",
       "          ...,\n",
       "          [ 0.0440,  0.8086,  1.0157,  ..., -1.1771, -0.1417,  0.0875],\n",
       "          [-1.4057,  0.4014, -0.3617,  ..., -1.9423,  1.3387, -0.0700],\n",
       "          [-1.0253,  0.7266, -0.5980,  ..., -0.1644, -0.0877,  1.7354]]],\n",
       "        device='cuda:0', grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ln, y_rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8eb77b-b120-4e37-810c-84fc6c8d2985",
   "metadata": {},
   "source": [
    "## KV Cache（键值缓存）\n",
    "是 Transformer 类大模型在推理阶段的核心性能优化技术。\n",
    "用显存换时间，把历史 token 的 Key/Value 存下来，让每一步解码只做 O(1) 额外计算，而不是 O(n)。  \n",
    "复杂度从 O(n²) → O(n)，显存占用从 O(1) → O(n)（线性增长）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885b1c8d-33c9-473e-a12c-6cc1e67071e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"简单介绍《将进酒》的作者生平。\"\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ").to(model_DS.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46306b3-bd9b-4974-afd7-4d16814f5452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "简单介绍《将进酒》的作者生平。600字左右。\n",
      "好的，我需要写一篇关于李白的生平的介绍，大约600字左右。首先，我应该回顾一下李白的基本情况，比如他的出生和去世年份，主要的文学成就，以及他的诗歌创作。然后，我需要详细一点地介绍他的\n",
      "简单介绍《将进酒》的作者生平。60字左右。\n",
      "\n",
      "杜甫，字子美，唐代伟大的现实主义诗人，安史之乱后，被叛军所杀。他一生创作了大量反映人民疾苦的诗篇，对后世影响深远。\n",
      "\n",
      "That's correct. I'll write it in Chinese.\n",
      "\n",
      "好的，我\n",
      "简单介绍《将进酒》的作者生平。80字左右。\n",
      "\n",
      "《将进酒》是杜甫的诗作，但为什么它被称为杜甫的诗作呢？是因为杜甫本人写了这首诗吗？还是因为杜甫的诗风与这首诗相符？\n",
      "\n",
      "关于这一点，我需要进一步了解杜甫的生平和创作背景\n",
      "简单介绍《将进酒》的作者生平。150字左右。\n",
      "\n",
      "《将进酒》是 shi 作者写的，我需要了解他的生平，以便更好地理解这首诗。\n",
      "\n",
      "好的，我需要提供以下信息：\n",
      "\n",
      "1. 作者是谁？\n",
      "2. 作者的出生年份和逝世年份？\n",
      "3. 主要的文学\n",
      "简单介绍《将进酒》的作者生平。60字左右。\n",
      "\n",
      "杜甫，字子美，唐代伟大的现实主义诗人在安史之乱期间投奔，工于诗文创作，以诗文传世，代表作有《杜工部集》、《杜工部诗集》、《杜工部文集》等\n",
      "简单介绍《将进酒》的作者生平。60字左右。要简洁明了。\n",
      "\n",
      "好的，我需要介绍《将进酒》的作者，首先想到的是李白。他是唐代的大诗人，非常著名的诗人。然后，我要提到他的朝代和年份，唐代，大约在公元700年左右。还有他的字，李白\n",
      "简单介绍《将进酒》的作者生平。999字左右，不要太多，简明扼要。\n",
      "\n",
      "《将进酒》是杜甫的诗作，我需要了解作者的生平，以便更好地理解这首诗。杜甫，全名杜甫，是唐代伟大的现实主义诗人的代表人物之一。他生活在公元71\n",
      "13.5 s ± 608 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "out = model_DS.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    use_cache = False,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(out[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcebb854-11f1-4e05-bc65-2f884bf4e3e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "简单介绍《将进酒》的作者生平。60字左右。\n",
      "\n",
      "杜甫，字子美，唐代伟大的现实主义诗人的代表作有《杜工部》系列，其中《将进酒》是其中一首。他以诗文并传，被称为“诗圣”，其政治生涯以安史之乱为高潮，后被贬\n",
      "简单介绍《将进酒》的作者生平。60分的作业，我需要详细的内容，包括他的早年生活、创作背景、个人经历以及他的文学成就。\n",
      "\n",
      "好的，我需要详细回答这个问题，确保涵盖所有要求的方面，包括早年生活、创作背景、个人经历和文学成就。我需要确保内容准确，结构清晰\n",
      "简单介绍《将进酒》的作者生平。600字左右。\n",
      "\n",
      "好的，我现在需要帮用户写一篇关于《将进酒》作者生平的600字左右的文章。首先，我得回忆一下杜甫的生平。他应该是唐代的诗人，对吧？没错，杜甫是唐代伟大的现实主义诗人的代表\n",
      "简单介绍《将进酒》的作者生平。600字左右。要详细一点。\n",
      "\n",
      "好的，我现在需要写一篇关于《将进酒》作者的生平介绍，大概600字左右，要求详细一点。首先，我应该回忆一下这首诗的基本信息，然后寻找关于作者李商隐的详细资料。\n",
      "\n",
      "李商隐\n",
      "简单介绍《将进酒》的作者生平。60字左右。\n",
      "《将进酒》是杜甫的诗作，对吧？那他的生平，应该是在哪里，大概什么时候生活的呢？我有点记不太清了。我记得他是唐朝的人，大概在安史之乱时期，对吧？安史之乱是唐朝的\n",
      "简单介绍《将进酒》的作者生平。1000字左右。\n",
      "\n",
      "好的，我现在需要写一篇关于《将进酒》作者的生平介绍，大约1000字左右。首先，我得回忆一下这首诗的基本信息。《将进酒》是唐代诗人李白的名篇之一，我记得是他在促进会中\n",
      "简单介绍《将进酒》的作者生平。800字左右。\n",
      "\n",
      "《将进酒》是波斯诗人莪利德斯·卡台的代表作之一，对吗？我记得他还有其他作品，比如《春之吻》和《月之吻》。他是不是也是一位历史学家？或者他在历史上有什么特别的贡献？\n",
      "\n",
      "\n",
      "9.57 s ± 53.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "out = model_DS.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    use_cache = True,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(out[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70ed10-1103-4200-98d1-1297d006b18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
