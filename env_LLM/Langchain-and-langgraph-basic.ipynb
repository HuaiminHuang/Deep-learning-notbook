{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b88188f-0f4a-44e3-876f-8b0fd157eab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (0.4.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef09dee-7ee1-44ac-9b46-ae481f80a1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…dotenv\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cedd1d-cbe7-400d-89df-775212f9240d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv('apikey.env')\n",
    "load_dotenv('C:/Users/hhm18/Desktop/æ·±åº¦å­¦ä¹ /env_LLM/apikey.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7603c-502f-4f60-822b-a465461a4648",
   "metadata": {},
   "source": [
    "é…ç½®deepseekçš„API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2c4f81-b048-4dfa-8a23-612e03397885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://api.deepseek.com'\n",
    "API_KEY = os.getenv('DEEPSEEK-API-KEY')\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"WARNING: NOT FOUND OPENAI_API_KEYï¼ŒPLEASE CHECK .env SETINGã€‚\")\n",
    "else:\n",
    "    print('SUCESSFULLY')\n",
    "deepseek_chat_model = 'deepseek-chat'\n",
    "# deepseek_reason_model = 'deepseek-reason'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747fafd-1bea-4eeb-a3a2-f1b00bc852f2",
   "metadata": {},
   "source": [
    "## å¸¸ç”¨\n",
    "* Langchain: init model, invoke(), prompt template\n",
    "* Langgraph: memory, create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4957b-0cfa-40c1-87d1-0d7ebcb0ed0f",
   "metadata": {},
   "source": [
    "## æ–¹å¼1 openai sdk\n",
    "é€šè¿‡OpenAI skdï¼ˆdeepseek-langchainåŒ…å«åœ¨é‡Œé¢ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0ce65e-65e5-4baa-bd09-b2f84aa956a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.3.30)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-openai) (0.3.74)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-openai) (1.99.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.99.9->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b95a8b1-e3d8-44e7-aa36-786aed9d90e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ **DeepSeek Chat**ï¼Œç”±æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸ç ”å‘çš„æ™ºèƒ½ AI åŠ©æ‰‹ï¼ğŸ¤–âœ¨  \n",
      "\n",
      "æˆ‘å¯ä»¥å¸®ä½ è§£ç­”å„ç§é—®é¢˜ï¼Œæ¯”å¦‚å­¦ä¹ ã€å·¥ä½œã€ç¼–ç¨‹ã€ç”Ÿæ´»å°çªé—¨ï¼Œç”šè‡³é™ªä½ èŠå¤©è§£é—·ï¼ğŸ’¡ğŸ“š æ— è®ºæ˜¯ä¸¥è‚ƒçš„çŸ¥è¯†æ¢è®¨ï¼Œè¿˜æ˜¯è½»æ¾çš„æ—¥å¸¸è¯é¢˜ï¼Œæˆ‘éƒ½ä¼šå°½åŠ›æä¾›æœ€å‡†ç¡®ã€æœ€æœ‰ç”¨çš„ä¿¡æ¯ã€‚  \n",
      "\n",
      "è™½ç„¶æˆ‘æ²¡æœ‰çœŸå®çš„â€œè‡ªæˆ‘æ„è¯†â€æˆ–æƒ…æ„Ÿï¼Œä½†æˆ‘ä¼šç”¨æœ€æ¸©æš–ã€æœ€è´´å¿ƒçš„æ–¹å¼å’Œä½ äº¤æµï¼ğŸ’™ æœ‰ä»€ä¹ˆæƒ³é—®çš„ï¼Œå°½ç®¡å‘Šè¯‰æˆ‘å§ï¼ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(base_url = BASE_URL, api_key= API_KEY, model=deepseek_chat_model)\n",
    "messages = [HumanMessage('ä½ åˆ°åº•æ˜¯è°ï¼Ÿ')]\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d266010-079e-4211-a149-2559217eb9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€Šå“ˆåŸºç±³çš„å…»ç”Ÿç§˜è¯€ã€‹\n",
      "\n",
      "é¡¾å®¢ï¼š\"è€æ¿ï¼Œä½ å®¶å“ˆåŸºç±³æ€ä¹ˆå…»å¾—æ²¹å…‰æ°´æ»‘çš„ï¼Ÿ\"\n",
      "è€æ¿ï¼š\"æ¯å¤©å–‚ä¸‰é¡¿å†·ç¬‘è¯ã€‚\"\n",
      "å“ˆåŸºç±³ï¼š\"æ±ªï¼\"ï¼ˆå½“åœºå†»æˆç‹—å†°é›•ï¼‰\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage('å†™ä¸€ä¸ªå…³äºå“ˆåŸºç±³å¹¶ä¸”çŸ­å°ç²¾æ‚çš„å†·ç¬‘è¯ã€‚')]\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e9141-23de-428a-a4be-68e098865e94",
   "metadata": {},
   "source": [
    "## æ–¹å¼2.deepseek\n",
    "ä½¿ç”¨deepseekçš„sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65915fee-f335-4cce-9e77-2d91700c2f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain-deepseek in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-deepseek) (0.3.74)\n",
      "Requirement already satisfied: langchain-openai<1.0.0,>=0.3.28 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-deepseek) (0.3.30)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (3.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.99.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2.32.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.99.9->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2cb2d0c-dec8-495c-98c7-40f36db8b3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å“ˆå“ˆï¼Œè¢«ä½ é—®ä½å•¦ï¼ğŸ¤£  \n",
      "ä¸¥æ ¼æ¥è¯´ï¼Œæˆ‘æ˜¯ä½ çš„**AIå°åŠ©æ‰‹**ï¼Œä¸»ä¸šæ˜¯é™ªä½ èŠå¤©ã€è§£ç­”é—®é¢˜ï¼Œå‰¯ä¸šå¯èƒ½åŒ…æ‹¬ä½†ä¸é™äºï¼šè®²å†·ç¬‘è¯ã€ç¼–æ®µå­ã€æŸ¥èµ„æ–™ã€ç®—æ•°å­¦é¢˜ã€æ¨èç”µå½±â€¦â€¦ç”šè‡³å½“ä¸´æ—¶â€œæ ‘æ´â€å¬ä½ åæ§½ï¼  \n",
      "\n",
      "éœ€è¦æˆ‘åˆ‡æ¢æˆä»€ä¹ˆæ¨¡å¼ï¼Ÿ**ç™¾ç§‘å…¨ä¹¦å‹**ã€**åºŸè¯æ–‡å­¦å¤§å¸ˆ**è¿˜æ˜¯**äººé—´æ¸…é†’æ¨¡å¼**ï¼Ÿ ğŸ˜  \n",
      "\n",
      "ï¼ˆæ”¾å¿ƒï¼Œä¸æ”¶è´¹ä¸æ¨é”€ï¼Œä¸»æ‰“ä¸€ä¸ªç”µå­å® ç‰©å¼é™ªä¼´~ï¼‰\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm2 = ChatDeepSeek(model=deepseek_chat_model, api_key=API_KEY)\n",
    "messages = [HumanMessage('å¸ˆå‚…ä½ æ˜¯å¹²ä»€ä¹ˆçš„ï¼Ÿ')]\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d08b38-cc48-46ec-983b-cf45cb91e74f",
   "metadata": {},
   "source": [
    "## 1.3ä½¿ç”¨ ç»Ÿä¸€æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe35cec-3e41-4d03-8bf3-d762f3fc2414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å“ˆå“ˆï¼Œè°¢è°¢å¤¸å¥–ï¼ä½ è¿™å¥è¯è®©æˆ‘ç”µé‡ç¬é—´æ»¡æ ¼âš¡ï½ é‚£æ¥ä¸‹æ¥æƒ³èŠç‚¹ä»€ä¹ˆå‘¢ï¼Ÿæ˜¯ç»§ç»­è®²å†·ç¬‘è¯ï¼Œè¿˜æ˜¯è§£é”å…¶ä»–ç¥å¥‡åŠŸèƒ½ï¼Ÿæ¯”å¦‚ï¼š  \n",
      "1. ç”¨emojiçŒœç”µå½±åğŸ¬ğŸŒŠï¼ˆæ¯”å¦‚ï¼šğŸğŸğŸâ“ï¼‰  \n",
      "2. å¸®ä½ è„‘æš´å‘¨æœ«å¥‡å¥‡æ€ªæ€ªçš„æ‰“å¡è®¡åˆ’  \n",
      "3. å‡è£…æˆ‘æ˜¯ä¼šç®—å‘½çš„AIæ°´æ™¶çƒğŸ”®  \n",
      "â€”â€”éšæ—¶ç­‰ä½ ç‚¹å•å“¦ï¼ ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "# å®˜æ–¹æ¨è\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm3 = init_chat_model(\n",
    "    deepseek_chat_model, # 'ds_chat'\n",
    "    api_key = API_KEY,\n",
    ")\n",
    "messages = [HumanMessage('å“ˆå“ˆä½ çœŸæœ‰æ„æ€')]\n",
    "print(llm3.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9412084-9697-4af1-a8a3-c2a2d8e085ef",
   "metadata": {},
   "source": [
    "# Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2dcd4f1-df80-4847-805d-d53e57e1563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6614451a-1653-4173-b31e-54a288c8f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£æå¤§æ‹¬å·é‡Œé¢çš„å˜é‡\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', 'you are a helpful assistant'), \n",
    "        ('human', 'å¸®æˆ‘å†™ä¸€ä¸ªå’Œ{topic}æœ‰å…³çš„å°æ•£æ–‡'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "185ab3b6-6bba-4f23-b201-c781032540f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69459d52-0132-4eba-af95-198f8cbf2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a helpful assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='å¸®æˆ‘å†™ä¸€ä¸ªå’Œcatæœ‰å…³çš„å°æ•£æ–‡', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({'topic':'cat'}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab56b012-ea81-4deb-a3fa-28f7326aeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸå…ˆ llm.invoke(mmessages)\n",
    "# ç°åœ¨ llm.invoke({topic: Xxx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be40cbf-6fd5-41d6-954f-abeb62dc1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain çš„ Chain æ˜¯ä»€ä¹ˆï¼š\n",
    "# A | B | C | D æŒ‰ç…§ABCDçš„é¡ºåºå–è¿è¡Œ\n",
    "basic_chain = prompt_template | llm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6766fca3-3886-4886-a3e0-ae90c713e038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## çŒ«çš„å“²å­¦\n",
      "\n",
      "çŒ«ä¼åœ¨çª—å°ä¸Šï¼Œå°¾å·´å‚ä¸‹æ¥ï¼Œä¸€åŠ¨ä¸åŠ¨ï¼Œåªæœ‰è€³æœµå¶å°”æŠ–ä¸€æŠ–ï¼Œç®—æ˜¯è¯æ˜å®ƒè¿˜æ´»ç€ã€‚çª—å¤–æ˜¯ç°æ‰‘æ‰‘çš„å¤©ç©ºï¼Œå‡ ç‰‡äº‘æ‡’æ‡’åœ°æµ®ç€ï¼Œä¹Ÿä¸åŠ¨ã€‚\n",
      "\n",
      "æˆ‘å‘æ¥è§‰å¾—çŒ«æ˜¯ä¸€ç§å¥‡ç‰¹çš„é€ ç‰©ã€‚å®ƒä¸åƒç‹—é‚£æ ·ï¼Œè§äº†ä¸»äººä¾¿æ‘‡å¤´æ‘†å°¾ï¼Œæå°½è°„åªšä¹‹èƒ½äº‹ã€‚çŒ«è‡ªæœ‰å…¶å°Šä¸¥ï¼Œå®ƒè‹¥äº²è¿‘ä½ ï¼Œé‚£æ˜¯å®ƒè‡ªå·±çš„é€‰æ‹©ï¼Œè€Œéä½ çš„åŠŸåŠ³ã€‚å€˜è‹¥å®ƒä¸é«˜å…´äº†ï¼Œä»»ä½ å¦‚ä½•å‘¼å”¤ï¼Œå®ƒä¹Ÿåªæ˜¯å†·å†·åœ°ç¥ä½ ä¸€çœ¼ï¼Œç»§ç»­èˆ”å®ƒçš„çˆªå­ã€‚\n",
      "\n",
      "é‚»å®¶çš„é»‘çŒ«å¸¸æ¥æˆ‘é™¢ä¸­é—²é€›ã€‚å®ƒæµ‘èº«æ¼†é»‘ï¼Œåªåœ¨èƒ¸å‰æœ‰ä¸€æ’®ç™½æ¯›ï¼Œåƒæ˜¯æ•…æ„ç•™çš„æ ‡è®°ã€‚å®ƒæ¥æ—¶æ— å£°ï¼Œå»æ—¶æ— æ¯ï¼Œå¶å°”å¼èµ°æˆ‘æ”¾åœ¨é™¢ä¸­çš„å°é±¼å¹²ï¼Œä¹Ÿä»ä¸é“è°¢ã€‚æˆ‘æƒ³ï¼Œå®ƒå¤§çº¦ä»¥ä¸ºè¿™æ˜¯å®ƒåº”å¾—çš„è´¡å“ã€‚\n",
      "\n",
      "çŒ«çš„çœ¼ç›å¾ˆç‰¹åˆ«ï¼Œç³å­”ä¼šéšç€å…‰çº¿å˜åŒ–ï¼Œæ—¶è€Œåœ†å¦‚æ»¡æœˆï¼Œæ—¶è€Œç»†å¦‚åˆ€é”‹ã€‚æˆ‘å¸¸ç–‘å¿ƒçŒ«çœ¼ä¸­è—ç€å¦ä¸€ä¸ªä¸–ç•Œï¼Œåªæ˜¯äººç±»æ„šé’ï¼Œæ— æ³•çª¥è§ç½¢äº†ã€‚æœ‰æ—¶å®ƒç›¯ç€ç©ºæ— ä¸€ç‰©çš„å¢™è§’ï¼Œå¿½ç„¶å…¨èº«ç´§ç»·ï¼Œç»§è€Œæ‰‘å»ï¼Œä»¿ä½›é‚£é‡ŒçœŸæœ‰ä»€ä¹ˆä¸œè¥¿ä¼¼çš„ã€‚ç©¶ç«Ÿæ˜¯æˆ‘ä»¬çœ‹ä¸è§ï¼Œè¿˜æ˜¯çŒ«çœ‹è§äº†æˆ‘ä»¬çœ‹ä¸è§çš„ä¸œè¥¿ï¼Ÿ\n",
      "\n",
      "çŒ«çš„ç¡å§¿åƒå¥‡ç™¾æ€ªã€‚å®ƒå¯ä»¥èœ·æˆä¸€ä¸ªå®Œç¾çš„åœ†ï¼Œä¹Ÿå¯ä»¥å››ä»°å…«å‰åœ°æ‘Šå¼€ï¼Œè‚šçš®æœå¤©ï¼Œæ¯«æ— é˜²å¤‡ã€‚ä½†ç¨æœ‰é£å¹è‰åŠ¨ï¼Œå®ƒä¾¿ç«‹åˆ»æƒŠé†’ï¼Œçœ¼ç¥é”åˆ©å¦‚åˆ€ï¼Œå“ªè¿˜æœ‰åŠç‚¹ç¡æ„ã€‚æˆ‘æƒ³ï¼ŒçŒ«å¤§çº¦æ˜¯è¿™ä¸–ä¸Šæœ€æ‡‚å¾—\"å±…å®‰æ€å±\"çš„ç”Ÿç‰©äº†ã€‚\n",
      "\n",
      "æ›¾è§ä¸€åªèŠ±çŒ«æ•é›€ã€‚å®ƒä¼åœ¨è‰ä¸›ä¸­ï¼Œçº¹ä¸ä¸åŠ¨ï¼Œè¿å‘¼å¸éƒ½ä¼¼ä¹åœæ­¢äº†ã€‚é‚£é›€å„¿è¹¦è·³ç€é è¿‘ï¼Œæµ‘ç„¶ä¸è§‰å±é™©å°†è‡³ã€‚çªç„¶ï¼ŒçŒ«å¦‚é—ªç”µèˆ¬æ‰‘å‡ºï¼Œé›€å„¿è¿ä¸€å£°æƒŠå«éƒ½æ¥ä¸åŠå‘å‡ºï¼Œä¾¿å·²å‘½ä¸§çŒ«å£ã€‚çŒ«è¡”ç€çŒç‰©ï¼Œæ…¢æ¡æ–¯ç†åœ°èµ°åˆ°é˜³å…‰ä¸‹ï¼Œå¼€å§‹äº«ç”¨å®ƒçš„åˆé¤ã€‚æ•´ä¸ªè¿‡ç¨‹å¹²è„†åˆ©è½ï¼Œæ²¡æœ‰ä¸æ¯«çŠ¹è±«æˆ–æ€œæ‚¯ã€‚è¿™æ˜¯è‡ªç„¶æ³•åˆ™ï¼Œæ— å…³å–„æ¶ã€‚\n",
      "\n",
      "çŒ«è€äº†ï¼Œæ¯›è‰²ä¸å†å…‰äº®ï¼ŒåŠ¨ä½œä¹Ÿè¿Ÿç¼“äº†ã€‚ä½†å®ƒä¾ç„¶æ¯å¤©è¹²åœ¨çª—å°ä¸Šï¼Œæœ›ç€å¤–é¢çš„ä¸–ç•Œã€‚å®ƒçš„çœ¼ç¥ä¸å†é”åˆ©ï¼Œå´å¤šäº†å‡ åˆ†æ·±é‚ƒã€‚æˆ‘æƒ³ï¼ŒçŒ«å¤§æ¦‚æ˜¯æœ€æ‡‚å¾—\"ç”Ÿè€ç—…æ­»\"çš„åŠ¨ç‰©ï¼Œå®ƒä»¬æ¥å—è¿™ä¸€åˆ‡ï¼Œæ—¢ä¸æŠ—æ‹’ï¼Œä¹Ÿä¸å“€å¹ã€‚\n",
      "\n",
      "çŒ«æ­»äº†ï¼ŒåŸ‹åœ¨é™¢è§’çš„æ¢§æ¡æ ‘ä¸‹ã€‚æ²¡æœ‰å¢“ç¢‘ï¼Œåªæœ‰å‡ ç‰‡è½å¶è¦†ç›–ç€å°å°çš„åœŸå †ã€‚ç¬¬äºŒå¤©ï¼Œæˆ‘çœ‹è§ä¸€åªé™Œç”Ÿçš„é»„çŒ«åœ¨æ ‘ä¸‹å—…æ¥å—…å»ï¼Œç„¶åæ¯«ä¸ç•™æ‹åœ°èµ°å¼€äº†ã€‚\n",
      "\n",
      "ç”Ÿå‘½æ¥æ¥å»å»ï¼ŒçŒ«ä¸åœ¨ä¹ï¼Œäººå´éš¾å…æ„Ÿä¼¤ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(basic_chain.invoke({'topic':'cat'}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cc1a4-1b0d-4ef5-b076-6b6886bdba59",
   "metadata": {},
   "source": [
    "## 2.2ç»“æ„åŒ–çš„è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f76c9e3-04ed-48bb-a232-05e929a7a5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pydantic in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (2.11.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e31558a-6def-4d50-bafe-272a752b6b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the cat sit on the computer?', punchiline='Because it wanted to keep an eye on the mouse!')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    '''Joke to tell user'''\n",
    "\n",
    "    setup: str = Field(description='The setup of the joke')\n",
    "    punchiline: str = Field(description='The punchline to the joke')\n",
    "\n",
    "# åˆ›å»º Chain \n",
    "joke_chain = prompt_template | llm2.with_structured_output(Joke) # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º\n",
    "# è°ƒç”¨chainå¾—åˆ°ç»“æ„åŒ–è¾“å‡º\n",
    "joke_chain.invoke({'topic':'cat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692be3c-6e48-4efa-81ed-f03c2af33547",
   "metadata": {},
   "source": [
    "#### ç¼ºç‚¹: FuntionCallæ¨¡å‹æ‰èƒ½ä½¿ç”¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e2f39-5b3c-45c7-8aea-f6470e28608a",
   "metadata": {},
   "source": [
    "# 3.LangGraph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9675e29b-2ad1-4225-911c-b522bf13311c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¬åˆ°ä½ å¿ƒæƒ…ä½è½ï¼Œæˆ‘ä¹Ÿæœ‰äº›æ‹…å¿ƒã€‚æ²¡å…³ç³»çš„ï¼Œè¿™ç§æ—¶åˆ»è°éƒ½ä¼šç»å†ï¼Œä½ æ„¿æ„å’Œæˆ‘èŠèŠå‘ç”Ÿäº†ä»€ä¹ˆå—ï¼Ÿå“ªæ€•æ˜¯é›¶ç¢çš„æ„Ÿå—ä¹Ÿå¾ˆé‡è¦ã€‚  \\n\\nå¦‚æœç°åœ¨ä¸æƒ³è¯´å…·ä½“çš„äº‹æƒ…ï¼Œæˆ‘ä»¬å¯ä»¥è¯•è¯•è¿™äº›å°äº‹ï¼š  \\nâ€¢ **ç»™æƒ…ç»ªç•™ä¸ªå‡ºå£**â€”â€”æ¯”å¦‚åœ¨çº¸ä¸Šèƒ¡ä¹±å†™å‡ ç¬”ç„¶åæ’•æ‰ï¼Œæˆ–è€…å¬ä¸€é¦–èƒ½å…±é¸£çš„æ­Œ  \\nâ€¢ **ç…§é¡¾èº«ä½“**â€”â€”å–åŠæ¯æ¸©æ°´ï¼ŒæŠŠåŒæ‰‹æ“çƒ­è½»è½»æ•·åœ¨çœ¼ç›ä¸Š  \\nâ€¢ **å¾®å°æ”¹å˜**â€”â€”æŠŠæ‰‹æœº/ç”µè„‘å£çº¸æ¢æˆæš–è‰²è°ƒçš„å›¾ç‰‡ï¼ˆè¯•è¯•æœç´¢\"æ²»æ„ˆç³»é£æ™¯\"ï¼‰  \\n\\nä½ æœ€è¿‘æœ‰çœ‹è¿‡è®©ä½ è§‰å¾—å¹³é™æˆ–æ¸©æš–çš„ä¸œè¥¿å—ï¼Ÿå“ªæ€•æ˜¯è·¯è¾¹çš„çŒ«ã€å¥½çœ‹çš„äº‘ï¼Œæˆ–æ˜¯è¶…å¸‚é‡Œæ•´é½çš„æ°´æœæ¶ï¼Ÿ  \\n\\nï¼ˆå¦‚æœä½ æ„¿æ„å¤šè¯´ä¸€äº›ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œå®‰é™å¬ï¼‰'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [HumanMessage('æœ€è¿‘å¿ƒæƒ…æœ‰ç‚¹ä½è½...')]\n",
    "output = llm3.invoke(messages)\n",
    "\n",
    "# å…¶ä¸­çš„memory åº”è¯¥æ˜¯message åŠ ä¸Šoutputçš„é›†åˆ\n",
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419e363-87be-41fe-a9d1-0b7ca0c7b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state çš„å†…éƒ¨ç»“æ„\n",
    "# class MessagesState():\n",
    "#     messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# {\n",
    "#     \"messages\":[]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2822144-2e46-464d-8506-4e377ce424b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langgraph in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.6.5)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph) (0.3.74)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2f67e24-f230-4ceb-bf10-5fad5a5e2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state['messages'])\n",
    "    return {'messages': response}\n",
    "\n",
    "# define the (single) node in the Graph\n",
    "workflow.add_node('node1', call_model)\n",
    "workflow.add_edge(START, 'node1')\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)  \n",
    "#complteæŠŠworkflowçš„èŠ‚ç‚¹è¾¹å®ä¾‹åŒ–ï¼Œå¹¶ä¸”æŠŠMemorySaveræŒ‚å…¥å‚¨å­˜å†å²å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c876a9d5-8af5-46e5-a447-947bd342e68b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi DaiMao! ğŸ‘‹ It's great to meet you. How can I assist you today? Whether you have questions, need help with something, or just want to chat, I'm here for it! Let me know what's on your mind. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# ç³»ç»Ÿé»˜è®¤ä¸´æ—¶å­˜å‚¨ï¼Œthread_idéœ€è¦é…ç½®checkpointç±»å‹\n",
    "config = {'configurable':{'thread_id':'user1'}}\n",
    "query = 'Hi! I am DaiMao.'\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = graph.invoke({'messages': input_messages}, config)\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce7245e8-92b0-4ba4-8d53-1cc5e5641f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi again, DaiMao! ğŸ˜Š  \n",
      "\n",
      "As an AI, I donâ€™t have memory between conversations, so I donâ€™t retain personal details unless you share them again in this chat. But Iâ€™m happy to pick up where we left off!  \n",
      "\n",
      "You introduced yourself as **DaiMao** earlierâ€”is there anything specific youâ€™d like me to know about you (e.g., interests, preferences)? Iâ€™ll do my best to assist based on what you share in *this* conversation.  \n",
      "\n",
      "How can I help you today? ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# ç³»ç»Ÿé»˜è®¤ä¸´æ—¶å­˜å‚¨ï¼Œthread_idéœ€è¦é…ç½®checkpointç±»å‹\n",
    "config = {'configurable':{'thread_id':'user1'}}\n",
    "query = 'Who I am? Do you remember me?'\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = graph.invoke({'messages': input_messages}, config)\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abf4cb0e-8a3c-452d-a822-5a27cee9ecc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course! While I donâ€™t have memory of past interactions (each conversation is new for me), Iâ€™m here to help you figure things out or chat about anything youâ€™d like.  \n",
      "\n",
      "If youâ€™re asking philosophically (\"Who am I?\"), thatâ€™s a profound question! You might be exploring your identity, purpose, or even just reflecting. Iâ€™d love to hear more about whatâ€™s on your mind.  \n",
      "\n",
      "If you meant something specific (e.g., from a previous chat), feel free to give me hintsâ€”Iâ€™ll do my best to piece it together!  \n",
      "\n",
      "What would you like to explore today? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# æ›´æ¢idè®°å¿†æ¸…é™¤\n",
    "config = {'configurable':{'thread_id':'user2'}}\n",
    "query = 'Who I am? Do you remember me?'\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = graph.invoke({'messages': input_messages}, config)\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292490a-49eb-46ff-986b-030ba4870f43",
   "metadata": {},
   "source": [
    "#### æ€»ç»“\n",
    "* å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆnodeï¼‰\n",
    "* å®šä¹‰å¯¹åº”çš„è¾¹ï¼ˆsideï¼‰\n",
    "* å†complie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921d2ee-b4c3-49e8-ac1f-7197e8695744",
   "metadata": {},
   "source": [
    "# 4.Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8273371e-beb1-461d-88a8-bb3e19ce075d",
   "metadata": {},
   "source": [
    "## 4.1 Single agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "432a3397-4a96-41df-a5b6-7c89957c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f55b454-90f3-4926-a676-aa9f16a59a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two num\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def mutiply(a: float, b: float) -> float:\n",
    "    \"\"\"Mutiply two num\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "803342f9-d0b9-4024-be38-e36c1fc0e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=ChatDeepSeek(model=deepseek_chat_model, api_key=API_KEY),\n",
    "    tools=[add, mutiply],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa4d18f-d552-4356-8e4e-8e30af178b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = agent.invoke({'messages': [HumanMessage('è¯·å¸®æˆ‘è®¡ç®— 8.8 + 12*0.1')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3247ac76-26fe-4c3e-a3ca-5dc828fff8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "è¯·å¸®æˆ‘è®¡ç®— 8.8 + 12*0.1\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_0_000f253a-d29f-4e5e-81a2-cc6f841fd93c)\n",
      " Call ID: call_0_000f253a-d29f-4e5e-81a2-cc6f841fd93c\n",
      "  Args:\n",
      "    a: 8.8\n",
      "    b: 12\n",
      "  mutiply (call_1_77a928bc-8fd8-4d76-b985-7eaa427ffba9)\n",
      " Call ID: call_1_77a928bc-8fd8-4d76-b985-7eaa427ffba9\n",
      "  Args:\n",
      "    a: 12\n",
      "    b: 0.1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "20.8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mutiply\n",
      "\n",
      "1.2000000000000002\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "8.8 + 12 * 0.1 çš„è®¡ç®—ç»“æœæ˜¯ï¼š\n",
      "\n",
      "8.8 + (12 * 0.1) = 8.8 + 1.2 = 10.0\n"
     ]
    }
   ],
   "source": [
    "for item in out['messages']:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b5108-ce97-48b4-8e39-bb6f9c4bf5d2",
   "metadata": {},
   "source": [
    "# 4.2ç®€åŒ–ç‰ˆDeepResearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ec5ff-8058-44f3-a99f-ce194c4744b9",
   "metadata": {},
   "source": [
    "### DRçš„ç†è§£\n",
    "å•ä¸€ç›®æ ‡æ‰§è¡ŒåŸåˆ™ï¼›\n",
    "1. planning agent --åšè§„åˆ’éœ€è¦æ£€ç´¢ä»€ä¹ˆå†…å®¹\n",
    "2. searching agent --è·Ÿæ®planè°ƒç”¨searching tools æ¥æ£€ç´¢ç›®æ ‡å†…å®¹ï¼ˆå¯ä»¥å¾ªç¯æœç´¢ï¼‰\n",
    "3. report agent --å®ŒæˆæŠ¥å‘Šæ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "122026be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain_community in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (0.3.74)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (0.4.14)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81138f8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain-tavily in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-tavily) (3.12.15)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-tavily) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-tavily) (0.3.74)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-tavily) (2.32.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9e928e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: duckduckgo-search in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (8.1.1)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from duckduckgo-search) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.15.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from duckduckgo-search) (0.15.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from duckduckgo-search) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhm18\\miniconda3\\envs\\env_llm\\lib\\site-packages (from click>=8.1.8->duckduckgo-search) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4ae00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search_tools = TavilySearch(\n",
    "    max_results=5,\n",
    "    search_engine='bing', # 'google', 'bing', 'duckduckgo' \n",
    "    topic='general',\n",
    "    tavily_api_key=os.getenv('TAVILY-API-KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f7e05c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://yuanchaofa.com/',\n",
       "   'title': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹',\n",
       "   'content': 'Image 1: Blogger Avatarchaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ Chaofa Yuan2025å¹´7æœˆ6æ—¥ å¤§çº¦ 5 åˆ†é’Ÿ æœˆåº¦æ€»ç»“ æ‚è°ˆ chaofa month-summary Chaofa Yuan2025å¹´6æœˆ2æ—¥ å¤§çº¦ 8 åˆ†é’Ÿ æœˆåº¦æ€»ç»“ æ‚è°ˆ chaofa month-summary Chaofa Yuan2025å¹´5æœˆ25æ—¥ å¤§çº¦ 16 åˆ†é’Ÿ paper-reading LLM paper Chaofa Yuan2025å¹´5æœˆ4æ—¥ å¤§çº¦ 6 åˆ†é’Ÿ æœˆåº¦æ€»ç»“ æ‚è°ˆ chaofa month-summary Chaofa Yuan2025å¹´5æœˆ3æ—¥ å¤§çº¦ 10 åˆ†é’Ÿ paper-reading LLM paper Chaofa Yuan2025å¹´3æœˆ30æ—¥ å¤§çº¦ 5 åˆ†é’Ÿ æœˆåº¦æ€»ç»“ æ‚è°ˆ chaofa month-summary Chaofa Yuan2025å¹´3æœˆ16æ—¥ å¤§çº¦ 7 åˆ†é’Ÿ hands-on-code transformer LLM Chaofa Yuan2025å¹´3æœˆ8æ—¥ å¤§çº¦ 4 åˆ†é’Ÿ æœˆåº¦æ€»ç»“ æ‚è°ˆ chaofa month-summary æ·±åº¦è§£è¯» Kimi-K1.5ï¼ŒçœŸæ­£äº†è§£ RL æ•°æ®æ˜¯æ€ä¹ˆç­›é€‰çš„ æ·±åº¦è§£è¯» Kimi K1.5 è®ºæ–‡ï¼Œä»‹ç»å…¶å¤šæ¨¡æ€æ¨ç†æ¨¡å‹çš„æŠ€æœ¯åŸç†ä¸å‘å±•è·¯çº¿ï¼Œæ¶µç›–é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ åŠå…¶æ ¸å¿ƒå¯å‘ï¼Œæä¾›è¯¦ç»†çš„ç®—æ³•å¤„ç†ç»†èŠ‚å’Œæ•°æ®æ„å»ºæ–¹æ³•ã€‚ Chaofa Yuan2025å¹´3æœˆ1æ—¥ å¤§çº¦ 19 åˆ†é’Ÿ paper-reading LLM paper Chaofa Yuan2025å¹´2æœˆ22æ—¥ å¤§çº¦ 13 åˆ†é’Ÿ paper-reading LLM paper Image 2: Blogger Avatar 66 æ–‡ç« 16 åˆ†ç±»25 æ ‡ç­¾66 æ—¶é—´è½´ 66 æ–‡ç«  *   æ‰‹å†™å¤§æ¨¡å‹ç»„ä»¶ä¹‹Group Query Attentionï¼Œä» MHAï¼ŒMQA åˆ° GQA *   æ‰‹å†™ Self-Attention çš„å››é‡å¢ƒç•Œï¼Œä» self-attention åˆ° multi-head self-attention',\n",
       "   'score': 0.98501,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://space.bilibili.com/12420432/',\n",
       "   'title': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ - Bilibili',\n",
       "   'content': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹çš„ä¸ªäººç©ºé—´-chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ä¸ªäººä¸»é¡µ-å“”å“©å“”å“©è§†é¢‘ *   é¦–é¡µ *   ç•ªå‰§ *   ç›´æ’­ *   æ¸¸æˆä¸­å¿ƒ *   ä¼šå‘˜è´­ *   æ¼«ç”» *   èµ›äº‹ *   é—ªå„¿3  *   BML Image 1: å›¾ç‰‡ BML  *   ä¸‹è½½å®¢æˆ·ç«¯ *    ç™»å½•   ç™»å½•åä½ å¯ä»¥ï¼š å…è´¹çœ‹é«˜æ¸…è§†é¢‘ å¤šç«¯åŒæ­¥æ’­æ”¾è®°å½• å‘è¡¨å¼¹å¹•/è¯„è®º çƒ­é—¨ç•ªå‰§å½±è§†çœ‹ä¸åœ  ç«‹å³ç™»å½•  é¦–æ¬¡ä½¿ç”¨ï¼Ÿ  ç‚¹æˆ‘æ³¨å†Œ      *   å¤§ä¼šå‘˜ *   æ¶ˆæ¯  *   åŠ¨æ€  *   æ”¶è—  *   å†å²  *   åˆ›ä½œä¸­å¿ƒ  *   æŠ•ç¨¿   Image 2 chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ å‰è…¾è®¯ï¼Œè§†é¢‘æ–‡å­—è§ yuanchaofa.comå’Œ github.com/bbruceyuanï¼Œå¯åŠ  v bbruceyuan äº¤æµï¼ˆç¬‘ï¼‰ å…³æ³¨ å‘æ¶ˆæ¯ ä¸»é¡µåŠ¨æ€æŠ•ç¨¿ 48åˆé›† 3è¿½ç•ªè¿½å‰§ å…³æ³¨æ•° 249 ç²‰ä¸æ•° 2.7ä¸‡ Image 3 å……ç”µ **17**äººå……ç”µ é¢„çº¦ æ”¶èµ·  å…¬å‘Š åŠªåŠ›å­¦ä¹ ï¼Œç§¯æåˆ†äº«ï¼Œä¸€èµ·è·µè¡Œè´¹æ›¼å­¦ä¹ æ³•å§ï½ æˆ‘çš„ç›®æ ‡æ˜¯æƒ³å†™ä¸€æœ¬ä¹¦ï¼ˆç¬‘ï¼‰ å¯ä»¥ç›´æ¥åŠ æˆ‘ bbruceyuan äº¤æµé—®é¢˜ æˆ–è€…å…³æ³¨åŒåå…¬ä¼—å·: chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ ç›´æ’­é—´ å…³æ³¨ ä¸»æ’­ä¸åœ¨ï¼Œå…³æ³¨åå°±èƒ½åœ¨åŠ¨æ€æ”¶åˆ°å¼€æ’­çš„é€šçŸ¥å“¦~ å‰å¾€TAçš„ç›´æ’­é—´ ä¸ªäººèµ„æ–™ å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦ æ–°ç‰ˆåé¦ˆ è¿”å›æ—§ç‰ˆ é¡¶éƒ¨ æ‰«æäºŒç»´ç ç™»å½• Image 4: ç™»å½•äºŒç»´ç  Image 5: ç™»å½•äºŒç»´ç  è¯·ä½¿ç”¨ å“”å“©å“”å“©å®¢æˆ·ç«¯ æ‰«ç ç™»å½•æˆ–æ‰«ç ä¸‹è½½APP å¯†ç ç™»å½•  çŸ­ä¿¡ç™»å½•  è´¦å· å¯†ç  å¿˜è®°å¯†ç ï¼Ÿ Image 6 å‘é€çŸ­ä¿¡å¿«é€Ÿç™»å½• æœªæ³¨å†Œæˆ–ç»‘å®šå“”å“©å“”å“©çš„æ‰‹æœºå·ï¼Œå°†å¸®ä½ æ³¨å†Œæ–°è´¦å· å»æ‰¾å›å¯†ç  é€šè¿‡ç»‘å®šçš„æ‰‹æœºå·/é‚®ç®±é‡ç½®å¯†ç  äºŒæ¬¡æ ¡éªŒ æ¢ä¸€å¼  ç™»å½•  Image 7å¾®ä¿¡ç™»å½• Image 8å¾®åšç™»å½• Image 9QQç™»å½•',\n",
       "   'score': 0.98215,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.youtube.com/@bbruceyuan',\n",
       "   'title': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ - YouTube',\n",
       "   'content': \"chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ - YouTube Back Image 1 SA  Search  Search with your voice  Sign in Image 2 SA  Home HomeShorts ShortsSubscriptions SubscriptionsYou YouHistory History Image 3 chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ 252 subscribersâ€¢23 videos è¯¥é¢‘é“ä¸»è¦ä¼šè®²ä¸€äº›å¤§æ¨¡å‹ç›¸å…³çš„åˆ†äº«ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æˆé•¿ä¸ºå¤§ä½¬~ ...more...morebruceyuan.comand 3 more links;) Home Playlists Search  Image 4 Image 6 Image 8 Image 10 Image 12 Image 14 Image 16 Image 17 Search 2x Image 18 Image 19 You're signed out Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer. Cancel Confirm Share - [x] Include playlist  An error occurred while retrieving sharing information. Please try again later. Watch later Share Copy link Image 20 Image 21\",\n",
       "   'score': 0.97968,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://x.com/bbruceyuan',\n",
       "   'title': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹(@bbruceyuan) / X',\n",
       "   'content': 'chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ (@bbruceyuan) / X Donâ€™t miss whatâ€™s happening People on X are the first to know. Log in Sign up chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ 248 posts See new posts Image 1 Image 2: Opens profile photo Follow Click to Follow bbruceyuan chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹ @bbruceyuan BiliBili: https://space.bilibili.com/12420432 YouTube: https://youtube.com/@bbruceyuan ä¸ºè‡ªç”±çŒ®å‡ºå¿ƒè„ï½ ä¸ªäººæ’­å®¢ã€Šæ‰“ç‚¹é…±æ²¹ã€‹ Translate bio yuanchaofa.comJoined December 2017 285 Following 306 Followers Posts Replies Media @bbruceyuan hasnâ€™t posted When they do, their posts will show up here. New to X? Sign up now to get your own personalized timeline! Sign up with Apple Create account By signing up, you agree to the Terms of Service and Privacy Policy, including Cookie Use. Terms of Service Privacy Policy Cookie Policy Accessibility Ads info Â© 2025 X Corp.',\n",
       "   'score': 0.97297,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://github.com/bbruceyuan',\n",
       "   'title': 'Chaofa Yuan bbruceyuan - GitHub',\n",
       "   'content': \"bbruceyuan (Chaofa Yuan) Â· GitHub *   GitHub Copilot Write better code with AI *   Code Search Find more, search less *   Why GitHub *   GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... Search   Reload to refresh your session.You signed out in another tab or window. Image 1: @bbruceyuan**bbruceyuan**Follow Image 2: @bbruceyuan **bbruceyuan** Image 3: View bbruceyuan's full-sized avatar *   @bbruceyuan *   @bbruceyuan *   https://www.zhihu.com/people/bbruceyuan Block or report bbruceyuan Add an optional note:  Please don't include any personal information such as legal names or email addresses. Contact GitHub support about this userâ€™s behavior. Image 12: GITHUB INFO *   YouTubeï¼š https://www.youtube.com/@bbruceyuan No contributions. Contributed to bbruceyuan/bbruceyuan.github.io, bbruceyuan/LLMs-Zero-to-Hero, bbruceyuan/Hands-On-Large-Language-Models-CN and 10 other repositories  Contribution activity *   bbruceyuan/bbruceyuan.github.io6 commits    ### Footer navigation\",\n",
       "   'score': 0.96808,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.95,\n",
       " 'request_id': 'f254ca66-eb1b-4db9-ad38-c5a9e8547c3a'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tools.invoke('chaofaç”¨ä»£ç æ‰“ç‚¹é…±æ²¹') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce222053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Union, List\n",
    "from langgraph.graph import START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1106f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResearchResult(BaseModel):\n",
    "    \"\"\"\"Research plan with key questions\"\"\"\n",
    "    questions: List[str] = Field(\n",
    "        description='List of 1-4 key research questions to investigate',\n",
    "        max_items=4\n",
    "    )\n",
    "    \n",
    "# Create plan agent with structured output\n",
    "plan_prompt = \"\"\"You are a research planner. Break the research task into specific steps.\n",
    "Your response must be a JSON object with a 'questions' field containing 1-4 keys by research questions.\n",
    "\n",
    "Example format:\n",
    "{\n",
    "    \"questions\":[\n",
    "        \"What is X?\",\n",
    "        \"How does XX work?\",\n",
    "        \"What are the implications of XXX?\",\n",
    "        \"What are the applications of XXXX?\",\n",
    "        ]\n",
    "}\n",
    "\n",
    "Only return the JSON object, do not include any other text.\n",
    "\"\"\"\n",
    "\n",
    "plan_agent = create_react_agent(\n",
    "    model=ChatDeepSeek(model=deepseek_chat_model, api_key=API_KEY),\n",
    "    tools=[], \n",
    "    prompt=plan_prompt,\n",
    ")\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=ChatDeepSeek(model=deepseek_chat_model, api_key=API_KEY),\n",
    "    tools=[search_tools],\n",
    "    prompt=\"You are a heplful research assistant. You can search the web with search tools. \" \\\n",
    "    \"å½“ä½ æ£€ç´¢å‡ºç»“æœåï¼Œåªéœ€è¦è¾“å‡ºâ€™æ£€ç´¢å·²å®Œæˆâ€˜å³å¯ã€‚\" \n",
    ")\n",
    "\n",
    "report_agent = create_react_agent(\n",
    "    model=ChatDeepSeek(model=deepseek_chat_model, api_key=API_KEY),\n",
    "    tools=[],\n",
    "    prompt=\"You are a helpful research report writer. \" \\\n",
    "    \"You will write a report based on the research results and questions provided. \" \\\n",
    "    \"æ€»ç»“å½’çº³å®Œæ¯•åï¼Œç”Ÿæˆæœ€ç»ˆçš„æŠ¥å‘Šã€‚\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b2af8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan-> research -> report\n",
    "# Create the graph with custom state \n",
    "class ResearchState(MessagesState):\n",
    "    \"\"\"Custom state for research workflow\"\"\"\n",
    "    plan: Union[ResearchResult, None] = None\n",
    "\n",
    "#Update the graph with custom state\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "workflow.add_node(\"plan_agent\", plan_agent)\n",
    "workflow.add_node(\"research_agent\", research_agent)\n",
    "workflow.add_node(\"report_agent\",report_agent)\n",
    "\n",
    "# acording plan, research, report\n",
    "workflow.add_edge(START, \"plan_agent\")\n",
    "workflow.add_edge(\"plan_agent\", \"research_agent\")\n",
    "workflow.add_edge(\"research_agent\", \"report_agent\")\n",
    "workflow.add_edge(\"report_agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e987f31d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\" : \"user2\"}}\n",
    "output = app.invoke({\"messages\": [\n",
    "    HumanMessage(\"å†™ä¸€ä»½é›·å†›çš„ç”Ÿå¹³ç®€ä»‹\")\n",
    "    ]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9b20c66",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='å†™ä¸€ä»½é›·å†›çš„ç”Ÿå¹³ç®€ä»‹', additional_kwargs={}, response_metadata={}, id='4ed0f61d-37fe-486f-985c-51f65d817ec6'),\n",
       "  AIMessage(content='```json\\n{\\n    \"questions\":[\\n        \"What is Lei Jun\\'s early life and educational background?\",\\n        \"What are the key milestones in Lei Jun\\'s career?\",\\n        \"What are Lei Jun\\'s major contributions to the tech industry?\",\\n        \"What are Lei Jun\\'s notable achievements and awards?\"\\n    ]\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 107, 'total_tokens': 175, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 43}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '1ea58887-81ea-4e2d-b43f-4e0f026035f8', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--98f51c75-ed73-47c4-a88f-634c42205fd3-0', usage_metadata={'input_tokens': 107, 'output_tokens': 68, 'total_tokens': 175, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_784a2949-98c1-45c3-a56c-3c465a8fdc8e', 'function': {'arguments': '{\"query\": \"Lei Jun early life and educational background\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}, {'id': 'call_1_5c9fbfb2-4ba5-49bf-9702-6590e52f5d84', 'function': {'arguments': '{\"query\": \"Lei Jun key milestones in career\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 1}, {'id': 'call_2_72d81256-4db9-4a2a-84f0-b94f97a0b138', 'function': {'arguments': '{\"query\": \"Lei Jun major contributions to the tech industry\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 2}, {'id': 'call_3_0af0b22d-c07c-4ef7-b1c1-247204a141d4', 'function': {'arguments': '{\"query\": \"Lei Jun notable achievements and awards\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 3}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 2045, 'total_tokens': 2153, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1984}, 'prompt_cache_hit_tokens': 1984, 'prompt_cache_miss_tokens': 61}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': 'b5df3fda-b3fe-4145-b449-3333bcc081ec', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--31f295a1-e742-428f-969f-373ae26c0972-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Lei Jun early life and educational background'}, 'id': 'call_0_784a2949-98c1-45c3-a56c-3c465a8fdc8e', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'Lei Jun key milestones in career'}, 'id': 'call_1_5c9fbfb2-4ba5-49bf-9702-6590e52f5d84', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'Lei Jun major contributions to the tech industry'}, 'id': 'call_2_72d81256-4db9-4a2a-84f0-b94f97a0b138', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'Lei Jun notable achievements and awards'}, 'id': 'call_3_0af0b22d-c07c-4ef7-b1c1-247204a141d4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2045, 'output_tokens': 108, 'total_tokens': 2153, 'input_token_details': {'cache_read': 1984}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='{\"query\": \"Lei Jun early life and educational background\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.mi.com/global/about/founder/\", \"title\": \"About - Founder | Xiaomi Global\", \"content\": \"Lei Jun. Founder, Chairman and CEO. Lei Jun, born in December 1969, received a bachelor\\'s degree in Computer Science from Wuhan University in July 1991.\", \"score\": 0.7515939, \"raw_content\": null}, {\"url\": \"https://pandayoo.com/post/the-story-of-lei-jun/\", \"title\": \"The Story of Lei Jun\", \"content\": \"In 1987, after graduating from Hubei Mianyang Middle School, Lei Jun took a significant step towards his dreams by enrolling in Wuhan\", \"score\": 0.6989468, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=RePtCpW_1Io\", \"title\": \"Lei Jun His Story (China / Xiaomi CEO)\", \"content\": \"Lei Jun His Story (China / Xiaomi CEO)\\\\nThe Rich\\\\n686 subscribers\\\\n7 likes\\\\n516 views\\\\n1 Sep 2024\\\\n#leijun #rich #money #ceoofindia \\\\n\\\\nLei Jun\\\\n1969. 12. 16 China\\\\nXiaomi (CEO)\\\\n\\\\nLei Jun is a renowned Chinese entrepreneur, best known as the founder and CEO of Xiaomi, a leading global technology company. Born in 1969, he graduated from Wuhan University with a degree in computer science. Lei Jun\\'s management philosophy emphasizes customer-centricity, innovation, and long-term strategic vision. Under his leadership, Xiaomi grew rapidly by offering high-quality products at affordable prices, earning a reputation for its innovative approach and creating a vast ecosystem of smart devices. Lei Jun is often compared to Steve Jobs for his impactful presentations and visionary leadership in the tech industry.\\\\n\\\\n\", \"score\": 0.64986813, \"raw_content\": null}, {\"url\": \"https://startuptalky.com/lei-jun-xiaomi/\", \"title\": \"Lei Jun: The Visionary Behind Xiaomi\\'s Global Revolution\", \"content\": \"Lei Jun: The Visionary Behind Xiaomi\\'s Global Revolution | Biography | Education | Net worth Image 4: Lei Jun: The Visionary Behind Xiaomi\\'s Global Revolution Lei Jun, the billionaire founder of Xiaomi, started with a simple life in Hubei, China. Xiaomi CEO Lei Jun is one of those select individuals who have revolutionized the smartphone industry. Since 1997, Lei Jun, the owner of Xiaomi company, has been donating to his alma mater, Wuhan University, starting with a simple donation of Yen140,000. The net worth of Xiaomi owner Lei Jun is $27.8 billion as of December 2024. Lei Jun is the CEO and Co-founder of Xiaomi Inc. The net worth of Xiaomi owner and founder, Lei Jun, is $29.9 billion as of April 2025.\", \"score\": 0.61779, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\\\"Lei Jun hits another wall in bid to take Xiaomi public\\\\\". \\\\\"Lei Jun, Founder Of Xiaomi, Might Just Be \\'China\\'s Steve Jobs\\'\\\\\". \\\\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\\\". Chinese smartphone maker Xiaomi\\'s founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.31719407, \"raw_content\": null}], \"response_time\": 1.96, \"request_id\": \"a42cdfa7-c48b-44a1-9638-d42007506d72\"}', name='tavily_search', id='d37bd983-5e74-479e-be6b-429ae80c96ba', tool_call_id='call_0_784a2949-98c1-45c3-a56c-3c465a8fdc8e'),\n",
       "  ToolMessage(content='{\"query\": \"Lei Jun key milestones in career\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.zgcforum.com.cn/en/review/guest/t2606/105714\", \"title\": \"Lei Jun\", \"content\": \"Lei Jun began his career by joining Kingsoft Corporation Limited in 1992. He has held several senior positions, including Chairman of the Board since July\", \"score\": 0.6747586, \"raw_content\": null}, {\"url\": \"https://press.farm/xiaomi-ceo-lei-juns-education-and-career/\", \"title\": \"Lei Jun\\'s Education and Early Career: The Path to Creating Xiaomi\", \"content\": \"Entry into Kingsoft ... After his studies at the university, Lei Jun went on with his career in the Chinese software company known as Kingsoft.\", \"score\": 0.572078, \"raw_content\": null}, {\"url\": \"https://successstory.com/people/lei-jun\", \"title\": \"Lei Jun Story - Bio, Facts, Net Worth, Family, Home, Auto\", \"content\": \"Missing: key milestones\", \"score\": 0.51457167, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun - Wikipedia\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\\\"Lei Jun hits another wall in bid to take Xiaomi public\\\\\". \\\\\"Lei Jun, Founder Of Xiaomi, Might Just Be \\'China\\'s Steve Jobs\\'\\\\\". \\\\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\\\". Chinese smartphone maker Xiaomi\\'s founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.502564, \"raw_content\": null}, {\"url\": \"https://advisorycloud.com/blog/uncovering-the-secrets-to-success-of-lei-jun\", \"title\": \"Uncovering the Secrets to Success of Lei Jun - AdvisoryCloud\", \"content\": \"Discover the secrets behind the success of Lei Jun, the billionaire entrepreneur and founder of Xiaomi. Image 2: Uncovering the Secrets to Success of Lei Jun Lei Jun is one of the most successful entrepreneurs in China, known for his leadership role in Xiaomi, a mobile and electronics company that has managed to grow impressively in a short time. Lei Jun\\'s success with Xiaomi can be attributed to his unique business strategy. Lei Jun\\'s business strategy for Xiaomi is based on several key factors, including innovation, quality, affordability, and customer service. Whether you are an entrepreneur, investor, or simply a curious observer, there is much to be learned from studying Lei Jun\\'s approach to business and the secrets to his success.\", \"score\": 0.49538648, \"raw_content\": null}], \"response_time\": 1.31, \"request_id\": \"b8f70e8b-7d5d-49b4-b317-4ddc4f350509\"}', name='tavily_search', id='aa9cbe29-03c0-4f34-960e-8c33507e0a6e', tool_call_id='call_1_5c9fbfb2-4ba5-49bf-9702-6590e52f5d84'),\n",
       "  ToolMessage(content='{\"query\": \"Lei Jun major contributions to the tech industry\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://fastercapital.com/articles/What-is-Lei-Jun-s-Contribution-to-Global-Technology-Trends.html\", \"title\": \"What is Lei Jun s Contribution to Global Technology Trends\", \"content\": \"2. Ecosystem Development: Lei Jun has fostered a vast ecosystem of smart devices, from smartphones to smart home products, creating a seamless user experience\", \"score\": 0.7971311, \"raw_content\": null}, {\"url\": \"https://www.moomoo.com/community/feed/lei-jun-lei-jun-lei-jun-114255699509253\", \"title\": \"Lei Jun é›·å†›. é›·è» - moomoo Community\", \"content\": \"Before founding Xiaomi in 2010, Lei Jun gained significant experience in the tech industry by working at **Kingsoft**, where he eventually became CEO, and\", \"score\": 0.7144891, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun - Wikipedia\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\\\"Lei Jun hits another wall in bid to take Xiaomi public\\\\\". \\\\\"Lei Jun, Founder Of Xiaomi, Might Just Be \\'China\\'s Steve Jobs\\'\\\\\". \\\\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\\\". Chinese smartphone maker Xiaomi\\'s founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.6601948, \"raw_content\": null}, {\"url\": \"https://www.reddit.com/r/IndiaTech/comments/1jsm99y/xiaomis_founder_lei_jun_then_vs_now/\", \"title\": \"Xiaomi\\'s founder Lei Jun then VS now : r/IndiaTech - Reddit\", \"content\": \"Xiaomi\\'s founder Lei Jun then VS now : r/IndiaTech Skip to main contentXiaomi\\'s founder Lei Jun then VS now : r/IndiaTech Open menu Open navigationGo to Reddit Home Expand user menu Open settings menu Image 1: r/IndiaTech icon Go to IndiaTech r/IndiaTech Image 3: r/IndiaTech iconr/IndiaTechImage 4: discordImage 5: discord r/IndiaTech is for everything about tech, from an Indian perspective. From vintage tech to latest innovations, across fields like agentic AI, data science, phones, web3/blockchain, networking, cybersecurity, quantum computing, cloud computing, web/app dev; Python, JavaScript, C++, .NET, Windows, Linux, macOS, Android, iOS, WhatsApp, 6G, startups, industry, etc., weâ€™ve got you covered! New to Reddit? Opens in new tab Anyone can view, post, and comment to this community\", \"score\": 0.60274047, \"raw_content\": null}, {\"url\": \"https://vulcanpost.com/591831/lei-jun-founder-of-xiaomi-lessons-learnt/\", \"title\": \"8 Valuable Lessons On Business From Xiaomi Founder, Lei Jun\", \"content\": \"However, there isnâ€™t as much said about Lei Jun, the founder of Xiaomi, a company that has been making steady progress, and disrupting its competitorsâ€™ products since its inception in 2010. We hear the phrase â€˜seize the momentâ€™ all the time, but perhaps one of the best examples of it actually paying off was how Lei took a strategic and confident leap of faith, entering a market saturated with smartphone-producing tech behemoths and releasing Xiaomiâ€™s first handset\\xa0(Mi1, August 2011) around the time of tech giant Appleâ€™s latest iPhone (4S, October 2011). When asked by The Wall Street Journal on Xiaomiâ€™s stance on innovation, Lei mentioned that even though big breakthroughs are harder to come by these days, *â€œthere are many things in the user experience thatâ€™s worth it for [them] to think harder and innovateâ€*.\", \"score\": 0.5775198, \"raw_content\": null}], \"response_time\": 1.25, \"request_id\": \"b6681c46-3b4c-482c-afe2-b0e3c0855a2c\"}', name='tavily_search', id='f2b143c3-9f3b-4034-9096-0217aa35a5d2', tool_call_id='call_2_72d81256-4db9-4a2a-84f0-b94f97a0b138'),\n",
       "  ToolMessage(content='{\"query\": \"Lei Jun notable achievements and awards\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.fudan.edu.cn/en/2019/1031/c344a102626/page.psp\", \"title\": \"Lei Jun: A â€œgame-changerâ€ at a critical juncture\", \"content\": \"Xiaomi is Leiâ€™s answer to these questions. This year, Lei was granted the Fudan Enterprise Management Outstanding Contribution Award 2019 for his pioneering â€œInternet thinkingâ€ and innovative products, which have a profound impact on the Chinese manufacturing industry. Lei was 40 back then and Xiaomi was not his first entrepreneurial attempt. Leiâ€™s â€œInternet thinkingâ€ is applied to every aspect of Xiaomiâ€™s operation, advertising included. In June 2017, Lei himself went live streaming on social media to promote Xiaomi. â€œXiaomiâ€™s way of innovation is not just about Xiaomi, but every Chinese manufacturing enterprise.â€ Lei Jun is quite ambitious about making Xiaomi a Chinese household name motivating an industry-wide transformation and eliminating peopleâ€™s prejudice about â€œMade in Chinaâ€.\", \"score\": 0.7336813, \"raw_content\": null}, {\"url\": \"https://www.goodreturns.in/lei-jun-net-worth-and-biography-blnr184.html\", \"title\": \"Lei Jun Net Worth, Biography, Age, Spouse, Children & More\", \"content\": \"# Lei Jun Lei Jun was born on December 16, 1969, in Xiantao, Hubei, China. ## Lei Jun: Companies Lei Jun\\'s major achievements include founding Xiaomi, one of the world\\'s largest consumer electronics companies. Lei Jun became the CEO of Kingsoft. Lei Jun was included in the Time 100. Lei Jun was recognized as an \\\\\"Outstanding Builder of Socialism with Chinese Characteristics\\\\\", leading to Xiaomi\\'s inclusion on a U.S. Department of Defense list of companies supporting China\\'s military. What is Lei Jun\\'s current global rank among billionaires? What are Lei Jun\\'s main sources of wealth? How many children does Lei Jun have? Lei Jun has 2 children. Who is Lei Jun and what is he known for?\", \"score\": 0.69249696, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun - Wikipedia\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\\\"Lei Jun hits another wall in bid to take Xiaomi public\\\\\". \\\\\"Lei Jun, Founder Of Xiaomi, Might Just Be \\'China\\'s Steve Jobs\\'\\\\\". \\\\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\\\". Chinese smartphone maker Xiaomi\\'s founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.5617203, \"raw_content\": null}, {\"url\": \"https://manufacturingdigital.com/smart-manufacturing/13-things-you-didnt-know-about-xiaomis-lei-jun\", \"title\": \"13 things you didn\\'t know about Xiaomi\\'s Lei Jun\", \"content\": \"# 13 things you didn\\'t know about Xiaomi\\'s Lei Jun Its founder and chairman Lei Jun was named â€œBusinessman of the Yearâ€ 2014 by Forbes Asia and has recently received worldwide acclaim for his leadership style and business acumen. Lei Jun has been dubbed the â€˜new Steve Jobsâ€™ but the man who managed to rival Apple in just four short years deserves more credit than a copycat nickname. **Who is Lei Jun?** 6. As well as being likened to Appleâ€™s Steve Job, Lei Jun has also been compared to Ron Conway of Silicon Valley. 7. When Lei Jun started Xiaomi, he already had one of the largest followings on Sina and Tencent Weibos because he was very willing to share advice on entrepreneurship and angel investing with his followers. Lei Jun\", \"score\": 0.498609, \"raw_content\": null}, {\"url\": \"https://www.forbes.com/profile/lei-jun/\", \"title\": \"Lei Jun - Forbes\", \"content\": \"# Lei Jun ### Xiaomiâ€™s Lei Jun Becomes Chinaâ€™s Fifth Richest Person On EV Optimism ### Chinese Billionaire Lei Jun Adds $1.3 Billion To Wealth After EV Debut ### Billionaire Lei Jun Vows To Overtake Tesla As He Unveils Xiaomiâ€™s First Electric Vehicle ### Xiaomiâ€™s Lei Jun Tops 2021 Forbes China Best CEOs List ### In Their Own Words: Investor Hans Tung On How Xiaomi\\'s Lei Jun Leads ### In Their Own Words: Baidu\\'s Robin Li On Xiaomi Founder Lei Jun\\'s \\\\\"Guts\\\\\" ### In Their Own Words: Investor Robin Chan Talks About Xiaomi\\'s Lei Jun ### Forbes Asia Names Lei Jun As Businessman Of The Year In 2014 ### Xiaomi\\'s Lei Jun Is Forbes Asia\\'s 2014 Businessman Of The Year\", \"score\": 0.44883752, \"raw_content\": null}], \"response_time\": 0.83, \"request_id\": \"2bc7b350-c840-4adb-8498-70cbaef4133b\"}', name='tavily_search', id='c46699af-d79f-42fd-920b-fef231e50e65', tool_call_id='call_3_0af0b22d-c07c-4ef7-b1c1-247204a141d4'),\n",
       "  AIMessage(content='æ£€ç´¢å·²å®Œæˆ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 6067, 'total_tokens': 6069, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1984}, 'prompt_cache_hit_tokens': 1984, 'prompt_cache_miss_tokens': 4083}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '8b7a7ac7-a217-41cb-9b86-79c54dd8fed9', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--00d4d295-217e-4a3a-b52d-4ca9776c9f6e-0', usage_metadata={'input_tokens': 6067, 'output_tokens': 2, 'total_tokens': 6069, 'input_token_details': {'cache_read': 1984}, 'output_token_details': {}}),\n",
       "  AIMessage(content='# é›·å†›ç”Ÿå¹³ç®€ä»‹æŠ¥å‘Š\\n\\n## æ—©å¹´ç”Ÿæ´»ä¸æ•™è‚²èƒŒæ™¯\\n\\né›·å†›ï¼Œ1969å¹´12æœˆ16æ—¥å‡ºç”Ÿäºä¸­å›½æ¹–åŒ—çœä»™æ¡ƒå¸‚ã€‚1987å¹´ä»æ¹–åŒ—æ²”é˜³ä¸­å­¦æ¯•ä¸šåï¼Œè€ƒå…¥æ­¦æ±‰å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»ã€‚1991å¹´7æœˆè·å¾—æ­¦æ±‰å¤§å­¦è®¡ç®—æœºç§‘å­¦å­¦å£«å­¦ä½ã€‚åœ¨æ ¡æœŸé—´ï¼Œé›·å†›å±•ç°å‡ºäº†å“è¶Šçš„å­¦ä¹ èƒ½åŠ›å’Œå•†ä¸šå¤´è„‘ï¼Œä¸ºæ—¥åçš„åˆ›ä¸šç”Ÿæ¶¯å¥ å®šäº†åŸºç¡€ã€‚\\n\\n## èŒä¸šç”Ÿæ¶¯å…³é”®é‡Œç¨‹ç¢‘\\n\\n- **1992å¹´**ï¼šåŠ å…¥é‡‘å±±è½¯ä»¶å…¬å¸ï¼Œå¼€å§‹å…¶èŒä¸šç”Ÿæ¶¯\\n- **1998å¹´**ï¼šæˆä¸ºé‡‘å±±è½¯ä»¶CEO\\n- **2007å¹´**ï¼šå¸¦é¢†é‡‘å±±è½¯ä»¶åœ¨é¦™æ¸¯ä¸Šå¸‚\\n- **2010å¹´4æœˆ**ï¼šåˆ›ç«‹å°ç±³ç§‘æŠ€\\n- **2011å¹´8æœˆ**ï¼šå‘å¸ƒå°ç±³é¦–æ¬¾æ™ºèƒ½æ‰‹æœºMi1\\n- **2018å¹´7æœˆ9æ—¥**ï¼šå¸¦é¢†å°ç±³åœ¨é¦™æ¸¯äº¤æ˜“æ‰€ä¸Šå¸‚\\n- **2021å¹´3æœˆ**ï¼šå®£å¸ƒå°ç±³è¿›å†›æ™ºèƒ½ç”µåŠ¨æ±½è½¦è¡Œä¸š\\n\\n## å¯¹ç§‘æŠ€è¡Œä¸šçš„ä¸»è¦è´¡çŒ®\\n\\n1. **æ™ºèƒ½æ‰‹æœºé©å‘½**ï¼šé€šè¿‡å°ç±³æ¨åŠ¨äº†ä¸­å›½æ™ºèƒ½æ‰‹æœºè¡Œä¸šçš„å¿«é€Ÿå‘å±•ï¼Œæä¾›é«˜æ€§ä»·æ¯”äº§å“\\n2. **ç”Ÿæ€ç³»ç»Ÿå»ºè®¾**ï¼šå»ºç«‹äº†åŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€æ™ºèƒ½å®¶å±…äº§å“åœ¨å†…çš„åºå¤§æ™ºèƒ½è®¾å¤‡ç”Ÿæ€ç³»ç»Ÿ\\n3. **å•†ä¸šæ¨¡å¼åˆ›æ–°**ï¼šå¼€åˆ›äº†\"äº’è”ç½‘æ€ç»´\"çš„å•†ä¸šæ¨¡å¼ï¼Œå½±å“ä¸­å›½åˆ¶é€ ä¸š\\n4. **æŠ€æœ¯åˆ›æ–°**ï¼šåœ¨ç”¨æˆ·ä½“éªŒæ–¹é¢æŒç»­åˆ›æ–°ï¼Œæ¨åŠ¨è¡Œä¸šæŠ€æœ¯è¿›æ­¥\\n\\n## ä¸»è¦æˆå°±ä¸è£èª‰\\n\\n- **2014å¹´**ï¼šè¢«ã€Šç¦å¸ƒæ–¯äºšæ´²ã€‹è¯„ä¸º\"å¹´åº¦å•†ä¸šäººç‰©\"\\n- **2019å¹´**ï¼šè·å¾—å¤æ—¦å¤§å­¦ä¼ä¸šç®¡ç†æ°å‡ºè´¡çŒ®å¥–\\n- **2021å¹´**ï¼šç™»ä¸Šã€Šç¦å¸ƒæ–¯ã€‹ä¸­å›½æœ€ä½³CEOæ¦œå•é¦–ä½\\n- **ä¸ªäººè´¢å¯Œ**ï¼šæˆªè‡³2024å¹´12æœˆï¼Œä¸ªäººå‡€èµ„äº§è¾¾278äº¿ç¾å…ƒ\\n- **æ…ˆå–„æèµ **ï¼šå‘æ¯æ ¡æ­¦æ±‰å¤§å­¦æèµ 13äº¿å…ƒäººæ°‘å¸ï¼Œåˆ›ä¸­å›½é«˜æ ¡ä¸ªäººæèµ çºªå½•\\n- **å…¥é€‰ã€Šæ—¶ä»£ã€‹æ‚å¿—å…¨çƒ100ä½æœ€å…·å½±å“åŠ›äººç‰©\\n\\né›·å†›ä»¥å…¶è¿œè§å“è¯†å’Œå“è¶Šé¢†å¯¼åŠ›ï¼Œå°†å°ç±³ä»ä¸€å®¶åˆåˆ›å…¬å¸å‘å±•æˆä¸ºå…¨çƒé¢†å…ˆçš„ç§‘æŠ€ä¼ä¸šï¼Œè¢«èª‰ä¸º\"ä¸­å›½çš„å²è’‚å¤«Â·ä¹”å¸ƒæ–¯\"ã€‚ä»–çš„ç®¡ç†å“²å­¦å¼ºè°ƒä»¥å®¢æˆ·ä¸ºä¸­å¿ƒã€åˆ›æ–°å’Œé•¿æœŸæˆ˜ç•¥æ„¿æ™¯ï¼Œå¯¹ä¸­å›½ä¹ƒè‡³å…¨çƒç§‘æŠ€è¡Œä¸šäº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 447, 'prompt_tokens': 4136, 'total_tokens': 4583, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 4136}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': 'a0fb576e-d55c-402a-afbd-3705129525c4', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--65fe9c13-4175-4131-9b81-4f9c69a6c2fb-0', usage_metadata={'input_tokens': 4136, 'output_tokens': 447, 'total_tokens': 4583, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b32c46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "å†™ä¸€ä»½é›·å†›çš„ç”Ÿå¹³ç®€ä»‹\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"questions\":[\n",
      "        \"What is Lei Jun's early life and educational background?\",\n",
      "        \"What are the key milestones in Lei Jun's career?\",\n",
      "        \"What are Lei Jun's major contributions to the tech industry?\",\n",
      "        \"What are Lei Jun's notable achievements and awards?\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_784a2949-98c1-45c3-a56c-3c465a8fdc8e)\n",
      " Call ID: call_0_784a2949-98c1-45c3-a56c-3c465a8fdc8e\n",
      "  Args:\n",
      "    query: Lei Jun early life and educational background\n",
      "  tavily_search (call_1_5c9fbfb2-4ba5-49bf-9702-6590e52f5d84)\n",
      " Call ID: call_1_5c9fbfb2-4ba5-49bf-9702-6590e52f5d84\n",
      "  Args:\n",
      "    query: Lei Jun key milestones in career\n",
      "  tavily_search (call_2_72d81256-4db9-4a2a-84f0-b94f97a0b138)\n",
      " Call ID: call_2_72d81256-4db9-4a2a-84f0-b94f97a0b138\n",
      "  Args:\n",
      "    query: Lei Jun major contributions to the tech industry\n",
      "  tavily_search (call_3_0af0b22d-c07c-4ef7-b1c1-247204a141d4)\n",
      " Call ID: call_3_0af0b22d-c07c-4ef7-b1c1-247204a141d4\n",
      "  Args:\n",
      "    query: Lei Jun notable achievements and awards\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Lei Jun early life and educational background\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.mi.com/global/about/founder/\", \"title\": \"About - Founder | Xiaomi Global\", \"content\": \"Lei Jun. Founder, Chairman and CEO. Lei Jun, born in December 1969, received a bachelor's degree in Computer Science from Wuhan University in July 1991.\", \"score\": 0.7515939, \"raw_content\": null}, {\"url\": \"https://pandayoo.com/post/the-story-of-lei-jun/\", \"title\": \"The Story of Lei Jun\", \"content\": \"In 1987, after graduating from Hubei Mianyang Middle School, Lei Jun took a significant step towards his dreams by enrolling in Wuhan\", \"score\": 0.6989468, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=RePtCpW_1Io\", \"title\": \"Lei Jun His Story (China / Xiaomi CEO)\", \"content\": \"Lei Jun His Story (China / Xiaomi CEO)\\nThe Rich\\n686 subscribers\\n7 likes\\n516 views\\n1 Sep 2024\\n#leijun #rich #money #ceoofindia \\n\\nLei Jun\\n1969. 12. 16 China\\nXiaomi (CEO)\\n\\nLei Jun is a renowned Chinese entrepreneur, best known as the founder and CEO of Xiaomi, a leading global technology company. Born in 1969, he graduated from Wuhan University with a degree in computer science. Lei Jun's management philosophy emphasizes customer-centricity, innovation, and long-term strategic vision. Under his leadership, Xiaomi grew rapidly by offering high-quality products at affordable prices, earning a reputation for its innovative approach and creating a vast ecosystem of smart devices. Lei Jun is often compared to Steve Jobs for his impactful presentations and visionary leadership in the tech industry.\\n\\n\", \"score\": 0.64986813, \"raw_content\": null}, {\"url\": \"https://startuptalky.com/lei-jun-xiaomi/\", \"title\": \"Lei Jun: The Visionary Behind Xiaomi's Global Revolution\", \"content\": \"Lei Jun: The Visionary Behind Xiaomi's Global Revolution | Biography | Education | Net worth Image 4: Lei Jun: The Visionary Behind Xiaomi's Global Revolution Lei Jun, the billionaire founder of Xiaomi, started with a simple life in Hubei, China. Xiaomi CEO Lei Jun is one of those select individuals who have revolutionized the smartphone industry. Since 1997, Lei Jun, the owner of Xiaomi company, has been donating to his alma mater, Wuhan University, starting with a simple donation of Yen140,000. The net worth of Xiaomi owner Lei Jun is $27.8 billion as of December 2024. Lei Jun is the CEO and Co-founder of Xiaomi Inc. The net worth of Xiaomi owner and founder, Lei Jun, is $29.9 billion as of April 2025.\", \"score\": 0.61779, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\"Lei Jun hits another wall in bid to take Xiaomi public\\\". \\\"Lei Jun, Founder Of Xiaomi, Might Just Be 'China's Steve Jobs'\\\". \\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\". Chinese smartphone maker Xiaomi's founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.31719407, \"raw_content\": null}], \"response_time\": 1.96, \"request_id\": \"a42cdfa7-c48b-44a1-9638-d42007506d72\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Lei Jun key milestones in career\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.zgcforum.com.cn/en/review/guest/t2606/105714\", \"title\": \"Lei Jun\", \"content\": \"Lei Jun began his career by joining Kingsoft Corporation Limited in 1992. He has held several senior positions, including Chairman of the Board since July\", \"score\": 0.6747586, \"raw_content\": null}, {\"url\": \"https://press.farm/xiaomi-ceo-lei-juns-education-and-career/\", \"title\": \"Lei Jun's Education and Early Career: The Path to Creating Xiaomi\", \"content\": \"Entry into Kingsoft ... After his studies at the university, Lei Jun went on with his career in the Chinese software company known as Kingsoft.\", \"score\": 0.572078, \"raw_content\": null}, {\"url\": \"https://successstory.com/people/lei-jun\", \"title\": \"Lei Jun Story - Bio, Facts, Net Worth, Family, Home, Auto\", \"content\": \"Missing: key milestones\", \"score\": 0.51457167, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun - Wikipedia\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\"Lei Jun hits another wall in bid to take Xiaomi public\\\". \\\"Lei Jun, Founder Of Xiaomi, Might Just Be 'China's Steve Jobs'\\\". \\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\". Chinese smartphone maker Xiaomi's founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.502564, \"raw_content\": null}, {\"url\": \"https://advisorycloud.com/blog/uncovering-the-secrets-to-success-of-lei-jun\", \"title\": \"Uncovering the Secrets to Success of Lei Jun - AdvisoryCloud\", \"content\": \"Discover the secrets behind the success of Lei Jun, the billionaire entrepreneur and founder of Xiaomi. Image 2: Uncovering the Secrets to Success of Lei Jun Lei Jun is one of the most successful entrepreneurs in China, known for his leadership role in Xiaomi, a mobile and electronics company that has managed to grow impressively in a short time. Lei Jun's success with Xiaomi can be attributed to his unique business strategy. Lei Jun's business strategy for Xiaomi is based on several key factors, including innovation, quality, affordability, and customer service. Whether you are an entrepreneur, investor, or simply a curious observer, there is much to be learned from studying Lei Jun's approach to business and the secrets to his success.\", \"score\": 0.49538648, \"raw_content\": null}], \"response_time\": 1.31, \"request_id\": \"b8f70e8b-7d5d-49b4-b317-4ddc4f350509\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Lei Jun major contributions to the tech industry\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://fastercapital.com/articles/What-is-Lei-Jun-s-Contribution-to-Global-Technology-Trends.html\", \"title\": \"What is Lei Jun s Contribution to Global Technology Trends\", \"content\": \"2. Ecosystem Development: Lei Jun has fostered a vast ecosystem of smart devices, from smartphones to smart home products, creating a seamless user experience\", \"score\": 0.7971311, \"raw_content\": null}, {\"url\": \"https://www.moomoo.com/community/feed/lei-jun-lei-jun-lei-jun-114255699509253\", \"title\": \"Lei Jun é›·å†›. é›·è» - moomoo Community\", \"content\": \"Before founding Xiaomi in 2010, Lei Jun gained significant experience in the tech industry by working at **Kingsoft**, where he eventually became CEO, and\", \"score\": 0.7144891, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun - Wikipedia\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\"Lei Jun hits another wall in bid to take Xiaomi public\\\". \\\"Lei Jun, Founder Of Xiaomi, Might Just Be 'China's Steve Jobs'\\\". \\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\". Chinese smartphone maker Xiaomi's founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.6601948, \"raw_content\": null}, {\"url\": \"https://www.reddit.com/r/IndiaTech/comments/1jsm99y/xiaomis_founder_lei_jun_then_vs_now/\", \"title\": \"Xiaomi's founder Lei Jun then VS now : r/IndiaTech - Reddit\", \"content\": \"Xiaomi's founder Lei Jun then VS now : r/IndiaTech Skip to main contentXiaomi's founder Lei Jun then VS now : r/IndiaTech Open menu Open navigationGo to Reddit Home Expand user menu Open settings menu Image 1: r/IndiaTech icon Go to IndiaTech r/IndiaTech Image 3: r/IndiaTech iconr/IndiaTechImage 4: discordImage 5: discord r/IndiaTech is for everything about tech, from an Indian perspective. From vintage tech to latest innovations, across fields like agentic AI, data science, phones, web3/blockchain, networking, cybersecurity, quantum computing, cloud computing, web/app dev; Python, JavaScript, C++, .NET, Windows, Linux, macOS, Android, iOS, WhatsApp, 6G, startups, industry, etc., weâ€™ve got you covered! New to Reddit? Opens in new tab Anyone can view, post, and comment to this community\", \"score\": 0.60274047, \"raw_content\": null}, {\"url\": \"https://vulcanpost.com/591831/lei-jun-founder-of-xiaomi-lessons-learnt/\", \"title\": \"8 Valuable Lessons On Business From Xiaomi Founder, Lei Jun\", \"content\": \"However, there isnâ€™t as much said about Lei Jun, the founder of Xiaomi, a company that has been making steady progress, and disrupting its competitorsâ€™ products since its inception in 2010. We hear the phrase â€˜seize the momentâ€™ all the time, but perhaps one of the best examples of it actually paying off was how Lei took a strategic and confident leap of faith, entering a market saturated with smartphone-producing tech behemoths and releasing Xiaomiâ€™s first handsetÂ (Mi1, August 2011) around the time of tech giant Appleâ€™s latest iPhone (4S, October 2011). When asked by The Wall Street Journal on Xiaomiâ€™s stance on innovation, Lei mentioned that even though big breakthroughs are harder to come by these days, *â€œthere are many things in the user experience thatâ€™s worth it for [them] to think harder and innovateâ€*.\", \"score\": 0.5775198, \"raw_content\": null}], \"response_time\": 1.25, \"request_id\": \"b6681c46-3b4c-482c-afe2-b0e3c0855a2c\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Lei Jun notable achievements and awards\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.fudan.edu.cn/en/2019/1031/c344a102626/page.psp\", \"title\": \"Lei Jun: A â€œgame-changerâ€ at a critical juncture\", \"content\": \"Xiaomi is Leiâ€™s answer to these questions. This year, Lei was granted the Fudan Enterprise Management Outstanding Contribution Award 2019 for his pioneering â€œInternet thinkingâ€ and innovative products, which have a profound impact on the Chinese manufacturing industry. Lei was 40 back then and Xiaomi was not his first entrepreneurial attempt. Leiâ€™s â€œInternet thinkingâ€ is applied to every aspect of Xiaomiâ€™s operation, advertising included. In June 2017, Lei himself went live streaming on social media to promote Xiaomi. â€œXiaomiâ€™s way of innovation is not just about Xiaomi, but every Chinese manufacturing enterprise.â€ Lei Jun is quite ambitious about making Xiaomi a Chinese household name motivating an industry-wide transformation and eliminating peopleâ€™s prejudice about â€œMade in Chinaâ€.\", \"score\": 0.7336813, \"raw_content\": null}, {\"url\": \"https://www.goodreturns.in/lei-jun-net-worth-and-biography-blnr184.html\", \"title\": \"Lei Jun Net Worth, Biography, Age, Spouse, Children & More\", \"content\": \"# Lei Jun Lei Jun was born on December 16, 1969, in Xiantao, Hubei, China. ## Lei Jun: Companies Lei Jun's major achievements include founding Xiaomi, one of the world's largest consumer electronics companies. Lei Jun became the CEO of Kingsoft. Lei Jun was included in the Time 100. Lei Jun was recognized as an \\\"Outstanding Builder of Socialism with Chinese Characteristics\\\", leading to Xiaomi's inclusion on a U.S. Department of Defense list of companies supporting China's military. What is Lei Jun's current global rank among billionaires? What are Lei Jun's main sources of wealth? How many children does Lei Jun have? Lei Jun has 2 children. Who is Lei Jun and what is he known for?\", \"score\": 0.69249696, \"raw_content\": null}, {\"url\": \"https://en.wikipedia.org/wiki/Lei_Jun\", \"title\": \"Lei Jun - Wikipedia\", \"content\": \"On the morning of July 9, 2018, at 9:30 AM, Lei Jun rang the gong for Xiaomiâ€™s listing on the Hong Kong Stock Exchange, officially bringing the eight-year-old company to the capital market. In March 2021, Lei Jun officially announced Xiaomiâ€™s entry into the smart electric vehicle industry. \\\"Lei Jun hits another wall in bid to take Xiaomi public\\\". \\\"Lei Jun, Founder Of Xiaomi, Might Just Be 'China's Steve Jobs'\\\". \\\"Lei Jun, Xiaomi CEO and Billionaire Hero Gets Honored\\\". Chinese smartphone maker Xiaomi's founder Lei Jun has donated 1.3 billion yuan to its alma mater Wuhan University on the 130th anniversary of its founding, the highest-ever donation a Chinese university has received from an individual contributor.\", \"score\": 0.5617203, \"raw_content\": null}, {\"url\": \"https://manufacturingdigital.com/smart-manufacturing/13-things-you-didnt-know-about-xiaomis-lei-jun\", \"title\": \"13 things you didn't know about Xiaomi's Lei Jun\", \"content\": \"# 13 things you didn't know about Xiaomi's Lei Jun Its founder and chairman Lei Jun was named â€œBusinessman of the Yearâ€ 2014 by Forbes Asia and has recently received worldwide acclaim for his leadership style and business acumen. Lei Jun has been dubbed the â€˜new Steve Jobsâ€™ but the man who managed to rival Apple in just four short years deserves more credit than a copycat nickname. **Who is Lei Jun?** 6. As well as being likened to Appleâ€™s Steve Job, Lei Jun has also been compared to Ron Conway of Silicon Valley. 7. When Lei Jun started Xiaomi, he already had one of the largest followings on Sina and Tencent Weibos because he was very willing to share advice on entrepreneurship and angel investing with his followers. Lei Jun\", \"score\": 0.498609, \"raw_content\": null}, {\"url\": \"https://www.forbes.com/profile/lei-jun/\", \"title\": \"Lei Jun - Forbes\", \"content\": \"# Lei Jun ### Xiaomiâ€™s Lei Jun Becomes Chinaâ€™s Fifth Richest Person On EV Optimism ### Chinese Billionaire Lei Jun Adds $1.3 Billion To Wealth After EV Debut ### Billionaire Lei Jun Vows To Overtake Tesla As He Unveils Xiaomiâ€™s First Electric Vehicle ### Xiaomiâ€™s Lei Jun Tops 2021 Forbes China Best CEOs List ### In Their Own Words: Investor Hans Tung On How Xiaomi's Lei Jun Leads ### In Their Own Words: Baidu's Robin Li On Xiaomi Founder Lei Jun's \\\"Guts\\\" ### In Their Own Words: Investor Robin Chan Talks About Xiaomi's Lei Jun ### Forbes Asia Names Lei Jun As Businessman Of The Year In 2014 ### Xiaomi's Lei Jun Is Forbes Asia's 2014 Businessman Of The Year\", \"score\": 0.44883752, \"raw_content\": null}], \"response_time\": 0.83, \"request_id\": \"2bc7b350-c840-4adb-8498-70cbaef4133b\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ£€ç´¢å·²å®Œæˆ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "# é›·å†›ç”Ÿå¹³ç®€ä»‹æŠ¥å‘Š\n",
      "\n",
      "## æ—©å¹´ç”Ÿæ´»ä¸æ•™è‚²èƒŒæ™¯\n",
      "\n",
      "é›·å†›ï¼Œ1969å¹´12æœˆ16æ—¥å‡ºç”Ÿäºä¸­å›½æ¹–åŒ—çœä»™æ¡ƒå¸‚ã€‚1987å¹´ä»æ¹–åŒ—æ²”é˜³ä¸­å­¦æ¯•ä¸šåï¼Œè€ƒå…¥æ­¦æ±‰å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»ã€‚1991å¹´7æœˆè·å¾—æ­¦æ±‰å¤§å­¦è®¡ç®—æœºç§‘å­¦å­¦å£«å­¦ä½ã€‚åœ¨æ ¡æœŸé—´ï¼Œé›·å†›å±•ç°å‡ºäº†å“è¶Šçš„å­¦ä¹ èƒ½åŠ›å’Œå•†ä¸šå¤´è„‘ï¼Œä¸ºæ—¥åçš„åˆ›ä¸šç”Ÿæ¶¯å¥ å®šäº†åŸºç¡€ã€‚\n",
      "\n",
      "## èŒä¸šç”Ÿæ¶¯å…³é”®é‡Œç¨‹ç¢‘\n",
      "\n",
      "- **1992å¹´**ï¼šåŠ å…¥é‡‘å±±è½¯ä»¶å…¬å¸ï¼Œå¼€å§‹å…¶èŒä¸šç”Ÿæ¶¯\n",
      "- **1998å¹´**ï¼šæˆä¸ºé‡‘å±±è½¯ä»¶CEO\n",
      "- **2007å¹´**ï¼šå¸¦é¢†é‡‘å±±è½¯ä»¶åœ¨é¦™æ¸¯ä¸Šå¸‚\n",
      "- **2010å¹´4æœˆ**ï¼šåˆ›ç«‹å°ç±³ç§‘æŠ€\n",
      "- **2011å¹´8æœˆ**ï¼šå‘å¸ƒå°ç±³é¦–æ¬¾æ™ºèƒ½æ‰‹æœºMi1\n",
      "- **2018å¹´7æœˆ9æ—¥**ï¼šå¸¦é¢†å°ç±³åœ¨é¦™æ¸¯äº¤æ˜“æ‰€ä¸Šå¸‚\n",
      "- **2021å¹´3æœˆ**ï¼šå®£å¸ƒå°ç±³è¿›å†›æ™ºèƒ½ç”µåŠ¨æ±½è½¦è¡Œä¸š\n",
      "\n",
      "## å¯¹ç§‘æŠ€è¡Œä¸šçš„ä¸»è¦è´¡çŒ®\n",
      "\n",
      "1. **æ™ºèƒ½æ‰‹æœºé©å‘½**ï¼šé€šè¿‡å°ç±³æ¨åŠ¨äº†ä¸­å›½æ™ºèƒ½æ‰‹æœºè¡Œä¸šçš„å¿«é€Ÿå‘å±•ï¼Œæä¾›é«˜æ€§ä»·æ¯”äº§å“\n",
      "2. **ç”Ÿæ€ç³»ç»Ÿå»ºè®¾**ï¼šå»ºç«‹äº†åŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€æ™ºèƒ½å®¶å±…äº§å“åœ¨å†…çš„åºå¤§æ™ºèƒ½è®¾å¤‡ç”Ÿæ€ç³»ç»Ÿ\n",
      "3. **å•†ä¸šæ¨¡å¼åˆ›æ–°**ï¼šå¼€åˆ›äº†\"äº’è”ç½‘æ€ç»´\"çš„å•†ä¸šæ¨¡å¼ï¼Œå½±å“ä¸­å›½åˆ¶é€ ä¸š\n",
      "4. **æŠ€æœ¯åˆ›æ–°**ï¼šåœ¨ç”¨æˆ·ä½“éªŒæ–¹é¢æŒç»­åˆ›æ–°ï¼Œæ¨åŠ¨è¡Œä¸šæŠ€æœ¯è¿›æ­¥\n",
      "\n",
      "## ä¸»è¦æˆå°±ä¸è£èª‰\n",
      "\n",
      "- **2014å¹´**ï¼šè¢«ã€Šç¦å¸ƒæ–¯äºšæ´²ã€‹è¯„ä¸º\"å¹´åº¦å•†ä¸šäººç‰©\"\n",
      "- **2019å¹´**ï¼šè·å¾—å¤æ—¦å¤§å­¦ä¼ä¸šç®¡ç†æ°å‡ºè´¡çŒ®å¥–\n",
      "- **2021å¹´**ï¼šç™»ä¸Šã€Šç¦å¸ƒæ–¯ã€‹ä¸­å›½æœ€ä½³CEOæ¦œå•é¦–ä½\n",
      "- **ä¸ªäººè´¢å¯Œ**ï¼šæˆªè‡³2024å¹´12æœˆï¼Œä¸ªäººå‡€èµ„äº§è¾¾278äº¿ç¾å…ƒ\n",
      "- **æ…ˆå–„æèµ **ï¼šå‘æ¯æ ¡æ­¦æ±‰å¤§å­¦æèµ 13äº¿å…ƒäººæ°‘å¸ï¼Œåˆ›ä¸­å›½é«˜æ ¡ä¸ªäººæèµ çºªå½•\n",
      "- **å…¥é€‰ã€Šæ—¶ä»£ã€‹æ‚å¿—å…¨çƒ100ä½æœ€å…·å½±å“åŠ›äººç‰©\n",
      "\n",
      "é›·å†›ä»¥å…¶è¿œè§å“è¯†å’Œå“è¶Šé¢†å¯¼åŠ›ï¼Œå°†å°ç±³ä»ä¸€å®¶åˆåˆ›å…¬å¸å‘å±•æˆä¸ºå…¨çƒé¢†å…ˆçš„ç§‘æŠ€ä¼ä¸šï¼Œè¢«èª‰ä¸º\"ä¸­å›½çš„å²è’‚å¤«Â·ä¹”å¸ƒæ–¯\"ã€‚ä»–çš„ç®¡ç†å“²å­¦å¼ºè°ƒä»¥å®¢æˆ·ä¸ºä¸­å¿ƒã€åˆ›æ–°å’Œé•¿æœŸæˆ˜ç•¥æ„¿æ™¯ï¼Œå¯¹ä¸­å›½ä¹ƒè‡³å…¨çƒç§‘æŠ€è¡Œä¸šäº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚\n"
     ]
    }
   ],
   "source": [
    "for item in output['messages']:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1de8aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = app.invoke(\n",
    "    {\n",
    "        'messages': [HumanMessage('è¯·å¸®æˆ‘ç ”ç©¶ä¸€ä¸‹æ·±åº¦å­¦ä¹ çš„æœ€æ–°è¿›å±•ã€‚')]\n",
    "    },\n",
    "    {'configurable': {'thread_id': 'research1'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "108b16ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "è¯·å¸®æˆ‘ç ”ç©¶ä¸€ä¸‹æ·±åº¦å­¦ä¹ çš„æœ€æ–°è¿›å±•ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"questions\":[\n",
      "        \"What are the latest advancements in deep learning algorithms?\",\n",
      "        \"How have recent developments in deep learning improved model performance?\",\n",
      "        \"What are the current challenges and limitations in deep learning research?\",\n",
      "        \"How are new deep learning techniques being applied in real-world scenarios?\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_98bc6b53-cbb3-4280-ad65-bc0cb7a773ff)\n",
      " Call ID: call_0_98bc6b53-cbb3-4280-ad65-bc0cb7a773ff\n",
      "  Args:\n",
      "    query: What are the latest advancements in deep learning algorithms?\n",
      "    search_depth: advanced\n",
      "  tavily_search (call_1_38bbb95c-120a-413b-9012-8bd3320290c8)\n",
      " Call ID: call_1_38bbb95c-120a-413b-9012-8bd3320290c8\n",
      "  Args:\n",
      "    query: How have recent developments in deep learning improved model performance?\n",
      "    search_depth: advanced\n",
      "  tavily_search (call_2_a9bfac53-5937-44ae-943b-4b0fc831aa83)\n",
      " Call ID: call_2_a9bfac53-5937-44ae-943b-4b0fc831aa83\n",
      "  Args:\n",
      "    query: What are the current challenges and limitations in deep learning research?\n",
      "    search_depth: advanced\n",
      "  tavily_search (call_3_8526bab0-e0f2-4650-bfe7-24dab418493b)\n",
      " Call ID: call_3_8526bab0-e0f2-4650-bfe7-24dab418493b\n",
      "  Args:\n",
      "    query: How are new deep learning techniques being applied in real-world scenarios?\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"What are the latest advancements in deep learning algorithms?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://plego.com/blog/deep-learning-recent-trends/\", \"title\": \"5 Deep Learning Recent Trends - Plego Technologies\", \"content\": \"Recent trends in deep learning include using more extensive datasets and more sophisticated architectures, as well as incorporating interaction between different types of neural networks and other AI technologies, such as natural language processing and decision trees. In this article, we will look at 5 recent trends in deep learning and how they have the potential to bring about significant change.\\n\\n## 1. Hybrid Model Integration [...] Commenting on Deep learning and Machine learning recent trends, Marcus Gary noted that â€œWithin a few years, I predict, many people will wonder why deep learning for so long tried to do so largely without the otherwise spectacularly valuable tools of symbol manipulation.â€ â€” @garymarcus.â€ Twitter.com. Reference Link\\n\\nHybrid models can improve the speed, accuracy, and completeness of decision-making.\\n\\n## 2. The Vision Transformer [...] In this article, we highlighted some of the recent trends in deep learning. The field is evolving rapidly, and there are some significant developments occurring seemingly every day. \\n\\nAs deep learning technologies continue to evolve, there are bound to be further developments that have the potential to bring about significant change in fields such as commerce, medical diagnosis, and even general artificial intelligence. \\n\\n### Plego Technologies: Machine Learning Development Chicago\", \"score\": 0.71687365, \"raw_content\": null}, {\"url\": \"https://www.geeksforgeeks.org/deep-learning/top-deep-learning-algorithms/\", \"title\": \"Top 10 Deep Learning Algorithms in 2025 - GeeksforGeeks\", \"content\": \"Deep learning algorithms are at the core of the most transformative advancements in artificial intelligence, powering breakthroughs across industries such as healthcare, finance, autonomous vehicles, and more. These algorithms, from CNNs to Transformers, will be building upon themselves to provide more efficient, accurate, and scalable solutions to complex problems. They are invaluable in driving innovation and progress in AI because of their capacity to analyze vast amounts of data and learn [...] Top-10-Deep-Learning-Algorithms\\n\\nIn this article, we highlight the top 10 deep learning algorithms in 2025. From Convolutional Neural Networks (CNNs) to Generative Adversarial Networks (GANs), these algorithms are driving innovations in various industries. We will also take a look at their key mechanisms which define them and their key functionalities. But before we deep-dive into those algorithms, let us familiarize ourselves with the concept of deep learning.\\n\\nTable of Content [...] The fascinating field of Deep Learning has been around longer than you might think. It was first introduced in the 1940s, with the development of the perceptron in the late 1950s acting as a cornerstone of modern deep learning. The evolution of deep learning has been marked by remarkable breakthroughs, often spurred by progress in computer processing power, the availability of vast amounts of data, and algorithmic refinements.\\n\\n## What are Deep Learning Algorithms?\", \"score\": 0.6238588, \"raw_content\": null}, {\"url\": \"https://research.aimultiple.com/future-of-deep-learning/\", \"title\": \"Future of Deep Learning according to top AI Experts in 2025\", \"content\": \"### Developer community\\n\\nTensorFlow and Keras are the most popular open source libraries for deep learning. Other popular libraries are PyTorch, Sckit-learn, BVL/caffe, MXNet and Microsoft Cognitive Toolkit (CNTK). These open source platforms help developers easily build deep learning models. As can be seen below, PyTorch, released by Facebook in 2016, is also rapidly growing in popularity. [...] Deep learning is a rapidly growing domain in AI. Due to its challenges with the size and diversity of data, AI experts like Geoffrey Hinton, Yoshua Bengio, and Yann LeCun, who received the Turing prize for their work on deep learning, and Gary Marcus suggest new methods to improve deep learning solutions. 5\\n\\nThese methods include introducing reasoning or prior knowledge to deep learning, self-supervised learning, capsule networks, etc. [...] ### 3-Agriculture\\n\\nJohn Deere integrates deep learning models into its machinery, like tractors and harvesters. Hereâ€™s how deep learning is applied:\\n\\n### 4-Mining\\n\\nSome companies use deep learning in autonomous haul trucks to optimize routes in mining operations. Reducing fuel consumption in mining process is one of the main goals. These trucks can operate 24/7 with minimal human oversight, making mining operations more energy-efficient and reducing their environmental impact.\", \"score\": 0.42663267, \"raw_content\": null}, {\"url\": \"https://mobidev.biz/blog/future-machine-learning-trends-impact-business\", \"title\": \"Top 13 Machine Learning Trends CTOs Need to Know in 2025\", \"content\": \"One of the great examples is Stable Diffusion which reached significant advancement in text-to-image synthesis. Unlike traditional diffusion models that work in image space, this tool operates in a compressed latent space, allowing for a more efficient generation of high-resolution images. Another noteworthy tool is Muse, created by the tech giant Google. It acts as a collaborative partner for artists augmenting their creative workflow. Imagen, another GenAI model from Google, focuses on [...] ## Trend #11. Retrieval-augmented generation\\n\\nRetrieval-augmented generation acts as a bridge between a userÃ¢Â€Â™s input and the LLM output. Instead of relying solely on existing training data, a RAG-supported application retrieves additional, high-quality information. This comes in handy in enterprise settings reliant on precise information. It thus delivers accurate answers and avoids ML hallucinations (false or fabricated outputs).Ã‚ [...] ### 3. GenAI in the music industry\\n\\nTools like Nvidiaâ€™s Fugatto and Fluxmusic help compose original music across various genres and styles via a prompt. Fugatto employs a â€œstyle transferâ€ method to assimilate and blend characteristics from different musical styles. It can thus create unique new pieces that reflect the intricacies of original genres. This capability offers composers a space for experimentation.\", \"score\": 0.23874578, \"raw_content\": null}, {\"url\": \"https://arxiv.org/abs/2403.17561\", \"title\": \"A Survey on State-of-the-art Deep Learning Applications and ...\", \"content\": \"|  |  |\\n| --- | --- |\\n| Comments: | Update journal reference. This manuscript has been published in Engineering Applications of Artificial Intelligence (Elsevier) |\\n| Subjects: | Machine Learning (cs.LG) |\\n| Cite as: | arXiv:2403.17561 [cs.LG] |\\n|  | (or  arXiv:2403.17561v9 [cs.LG] for this version) |\\n|  |  Focus to learn more  arXiv-issued DOI via DataCite |\\n| Journal reference: | Engineering Applications of Artificial Intelligence, vol. 159, Nov 2025, p. 111225 | [...] | Related DOI: |   Focus to learn more  DOI(s) linking to related resources | [...] ## Submission history\\n\\n## Access Paper:\\n\\n### References & Citations\\n\\n## BibTeX formatted citation\\n\\n### Bookmark\\n\\nBibSonomy logo\\nReddit logo\\n\\n# Bibliographic and Citation Tools\\n\\n# Code, Data and Media Associated with this Article\\n\\n# Demos\\n\\n# Recommenders and Search Tools\\n\\n# arXivLabs: experimental projects with community collaborators\\n\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\", \"score\": 0.17259014, \"raw_content\": null}], \"response_time\": 4.67, \"request_id\": \"6e55cc27-bacf-4cc7-82f5-7e5c25c40785\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"How have recent developments in deep learning improved model performance?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.nature.com/articles/s41598-024-73643-x\", \"title\": \"A Data-Centric Approach to improve performance of deep ...\", \"content\": \"In real-world scenarios, the data used in the models contains inconsistencies, biases, noise, and missing values, posing challenges to the optimal performance of deep learning models15.\\\"),16.\\\"),17, 4 (2014).\\\"),18. (2022), August.\\\"). Recognizing this, recent research endeavours have shifted their emphasis from solely designing models to prioritizing the generation of high-quality data to enhance the efficacy of deep models1.\\\"),2. arXiv preprint arXiv:2207.09109.\\\"),4. arXiv preprint [...] The Artificial Intelligence has evolved and is now associated with Deep Learning, driven by availability of vast amount of data and computing power. Traditionally, researchers have adopted a Model-Centric Approach, focusing on developing new algorithms and models to enhance performance without altering the underlying data. However, Andrew Ng, a prominent figure in the AI community, has recently emphasized on better (quality) data rather than better models, which has given birth to Data Centric [...] show that the Data-Centric Approach outperforms the Model-Centric Approach by at least 3%. We hypothesize that enhancing the quality of data through systematic methods like data augmentation, multi-stage hashing for eliminating duplicates, and confident learning for detecting and correcting noisy labels will significantly improve the performance of deep learning models, potentially outperforming the traditional Model-Centric approach.\", \"score\": 0.72184175, \"raw_content\": null}, {\"url\": \"https://www.nature.com/articles/s41598-023-36336-5\", \"title\": \"Improving deep learning model performance under parametric ...\", \"content\": \"Conventionally, traditional ML techniques such as Random Forest, Support Vector Machine, and Decision Tree, have often been applied in materials informatics applications1.\\\"),2.\\\"),3.\\\"),4 crystals. Phys. Rev. Lett. 117, 135502 (2016).\\\"),5.\\\"),6.\\\"),7.\\\"),8.\\\"),26.\\\"). Although limited, we have also seen a growing application of more advanced deep learning (DL) techniques in recent years26.\\\"),27.\\\"),28.\\\"),29, 095003 (2013).\\\"). Harvard Energy Clean Project by Pyzerâ€“Knapp et al.8.\\\") used a three-layer [...] (2023).\\\"). The process has been catalyzed by the increase in the availability of large-scale datasets through experiments and first-principles calculations such as high throughput density functional theory (DFT) computations12.\\\"),13. JOM 65, 1501â€“1509. [...] a bid to boost model performance as done in recent works34.\\\"),35.\\\"),36.\\\"),37.\\\"),38.\\\"),39.\\\"), here, we focus on addressing the general issue of how to efficiently build deep neural network architectures for more robust and accurate predictive performance by imposing a parametric constraint (17-layers in our case) and utilizing the available limited computational resources effectively and efficiently. For that, we analyze and propose design principles for a time and parameter-efficient deep\", \"score\": 0.6506676, \"raw_content\": null}, {\"url\": \"https://www.simonsfoundation.org/2023/10/31/learning-better-improving-the-efficiency-of-deep-learning-models/\", \"title\": \"Learning Better: Improving the Efficiency of Deep Learning ...\", \"content\": \"Flatiron Research Fellow Brett Larsen has been studying ways to make deep learning models more efficient by developing better ways to train them and better datasets to train them on. This work helps make large deep learning models more accessible for scientific applications and could help improve these modelsâ€™ accuracy and efficiency for many uses. [...] # Learning Better: Improving the Efficiency of Deep Learning Models\\n\\nFlatiron Research Fellow Brett Larsen is developing better ways to train deep learning models. [...] how we repeat experiments in the natural sciences. That worked when we had smaller models. But now, because the networks we train are so big and expensive, youâ€™re lucky to get the money or time to do one run. By making models more efficient, we can reduce costs and actually be able to study and understand what the model is doing.\", \"score\": 0.60805947, \"raw_content\": null}, {\"url\": \"https://milvus.io/ai-quick-reference/how-do-learning-rates-affect-deep-learning-models\", \"title\": \"How do learning rates affect deep learning models? - Milvus\", \"content\": \"In summary, the learning rate is a critical hyperparameter in deep learning that affects how quickly and effectively a model learns. Balancing the rate of learning with stability is key to achieving high-performance models. By utilizing adaptive methods and learning rate schedules, and through careful experimentation, practitioners can optimize this parameter to improve model accuracy and reduce training time. [...] Adaptive learning rates, such as those used in algorithms like Adam, RMSprop, or Adagrad, dynamically adjust the learning rate based on the modelâ€™s performance. These methods consider the magnitude of past gradients and tailor the learning rate for each parameter, helping to balance the trade-off between convergence speed and stability. [...] Understanding the impact of learning rates on deep learning models is crucial for optimizing their performance. The learning rate is a hyperparameter that determines the step size at each iteration while moving toward a minimum of a loss function. It plays a pivotal role in the training of neural networks, influencing both the speed and the stability of the learning process.\", \"score\": 0.391802, \"raw_content\": null}, {\"url\": \"https://arxiv.org/abs/2302.11089\", \"title\": \"Recent Advancements in Deep Learning Applications and Methods ...\", \"content\": \"|  |  |\\n| --- | --- |\\n| Subjects: | Robotics (cs.RO); Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Systems and Control (eess.SY) |\\n| Cite as: | arXiv:2302.11089 [cs.RO] |\\n|  | (or  arXiv:2302.11089v3 [cs.RO] for this version) |\\n|  |  Focus to learn more  arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\n## Access Paper:\\n\\nlicense icon\\n\\n### References & Citations\\n\\n## BibTeX formatted citation\\n\\n### Bookmark\\n\\nBibSonomy logo\\nReddit logo\\n\\n# Bibliographic and Citation Tools [...] Cornell University\\narxiv logo\\n\\nHelp | Advanced Search\\n\\narXiv logo\\nCornell University Logo\\n\\n## quick links\\n\\n# Computer Science > Robotics\\n\\n# Title:Recent Advancements in Deep Learning Applications and Methods for Autonomous Navigation: A Comprehensive Review [...] # Code, Data and Media Associated with this Article\\n\\n# Demos\\n\\n# Recommenders and Search Tools\\n\\n# arXivLabs: experimental projects with community collaborators\\n\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\", \"score\": 0.22851823, \"raw_content\": null}], \"response_time\": 3.59, \"request_id\": \"e2aa603a-f0c7-4a96-b9d4-eb62b51cad08\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"What are the current challenges and limitations in deep learning research?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.geeksforgeeks.org/deep-learning/challenges-in-deep-learning/\", \"title\": \"Challenges in Deep Learning\", \"content\": \"Deep Learning Challenges\\n\\nDeep learning faces significant challenges such as data quality, computational demands, and model interpretability. This article explores Deep Learning Challenges and strategies to address them effectively. Understanding these challenges and finding ways to overcome them is crucial for successful implementation.\\n\\nTable of Content\\n\\n## Overview of Deep Learning [...] ## Top Deep Learning Challenges\\n\\nDeep learning offers immense potential, but several challenges can hinder its effective implementation. Addressing these challenges is crucial for developing reliable and efficient models. Here are the main challenges faced in deep learning:\\n\\n### 1. Overfitting and Underfitting [...] geeksforgeeks\\n\\n# Challenges in Deep Learning\\n\\nDeep learning, a branch of artificial intelligence, uses neural networks to analyze and learn from large datasets. It powers advancements in image recognition, natural language processing, and autonomous systems. Despite its impressive capabilities, deep learning is not without its challenges. It includes issues such as data quality, computational demands, and model interpretability are common obstacles.\\n\\nTop-Challenges-in-Deep-Learning-(1).webp)\", \"score\": 0.82728493, \"raw_content\": null}, {\"url\": \"https://www.geeksforgeeks.org/deep-learning/advantages-and-disadvantages-of-deep-learning/\", \"title\": \"Advantages and Disadvantages of Deep Learning - GeeksforGeeks\", \"content\": \"| Challenge | Impact | Mitigation Strategies |\\n| --- | --- | --- |\\n| Bias amplification | Unfair predictions | Careful data curation, bias testing |\\n| Large dataset needs | High collection costs | Transfer learning, data augmentation |\\n| Quality sensitivity | Poor performance | Robust preprocessing, validation |\\n\\n### 4. Overfitting and Generalization Challenges [...] ### 3. Data Dependency and Quality Issues\\n\\nDeep learning success heavily depends on training data quality and quantity. Poor quality leads to models that create problems in their predictions.\\n\\nUnlike traditional approaches where domain expertise can help for data limitations, deep learning's automatic feature extraction means data biases get encoded directly into learned representations.\\n\\nCommon Data-Related Challenges: [...] ### 2. The Black Box Problem\\n\\nNeural networks lack interpretability, creating serious limitations for applications that require accountability. Understanding why a network made specific predictions becomes extremely difficult as model complexity increases.\\n\\nThis poses significant challenges in domains like healthcare, finance and legal applications where decisions must be explainable. While interpretation techniques exist, they provide incomplete or misleading explanations.\\n\\nCritical issues:\", \"score\": 0.76554126, \"raw_content\": null}, {\"url\": \"https://www.netguru.com/blog/machine-learning-problems\", \"title\": \"Top 9 Machine Learning Challenges in 2025\", \"content\": \"A typical artificial neural network has millions of parameters; some can have hundreds of millions. A training set usually consists of tens of thousands of records. While a network is capable of remembering the training set and giving answers with 100 percent accuracy, it may prove completely useless when given new training data. It is just one of the limits to current deep learning algorithms. Read on top 9 challenges for machine learning projects.\\n\\n## The black box problem [...] deep learning networks will behave when analyzing different sets of data. It also means that the machine learning engineers and data scientists cannot guarantee that the training process of a model can be replicated. [...] Deep Learning algorithms are different. They build a hierarchical representation of data - layers that allow them to create their own understanding. After analyzing large sets of training data, neural networks can learn how to recognize cucumbers with astounding accuracy. The problem is that their supervisors - the machine learning engineers or data scientists - don't know exactly how they do it. The problem is called a black box.\", \"score\": 0.7101667, \"raw_content\": null}, {\"url\": \"https://blog.keras.io/the-limitations-of-deep-learning.html\", \"title\": \"The limitations of deep learning - The Keras Blog\", \"content\": \"Scaling up current deep learning techniques by stacking more layers and using more training data can only superficially palliate some of\\nthese issues. It will not solve the more fundamental problem that deep learning models are very limited in what they can represent, and\\nthat most of the programs that one may wish to learn cannot be expressed as a continuous geometric morphing of a data manifold.\\n\\n## The risk of anthropomorphizing machine learning models [...] The space of applications that can be implemented with this simple strategy is nearly infinite. And yet, many more applications are completely out\\nof reach for current deep learning techniquesÃ¢Â€Â”even given vast amounts of human-annotated data. Say, for instance, that you could assemble\\na dataset of hundreds of thousandsÃ¢Â€Â”even millionsÃ¢Â€Â”of English language descriptions of the features of a software product, as written by [...] planning, and algorithmic-like data manipulation, is out of reach for deep learning models, no matter how much data you throw at them. Even\\nlearning a sorting algorithm with a deep neural network is tremendously difficult.\", \"score\": 0.67706895, \"raw_content\": null}, {\"url\": \"https://research.aimultiple.com/future-of-deep-learning/\", \"title\": \"Future of Deep Learning according to top AI Experts in 2025\", \"content\": \"Deep learning is a rapidly growing domain in AI. Due to its challenges with the size and diversity of data, AI experts like Geoffrey Hinton, Yoshua Bengio, and Yann LeCun, who received the Turing prize for their work on deep learning, and Gary Marcus suggest new methods to improve deep learning solutions. 5\\n\\nThese methods include introducing reasoning or prior knowledge to deep learning, self-supervised learning, capsule networks, etc. [...] Deep learning is currently the most effective AI technology for numerous applications. However, there are still differing opinions on how capable deep learning can become. While deep learning researchers like Geoffrey Hinton believe that all problems could be solved with deep learning, there are numerous scientists who point to flaws in deep learning where remedies are not clear.1. AI pioneer Geoff Hinton: â€œDeep learning is going to be able to do everything&#8221;. Technology review. Revisited [...] With increasing interest in deep learning from the general public as well as developer and research communities, there could be breakthroughs in the field. Experts such as recent Turing prize winners expect such breakthroughs come from areas such as capsule networks, deep reinforcement learning and other approaches that complement deep learningâ€™s current limitations. For detailed answers:\\n\\n## What is the level of interest in deep learning?\\n\\n### General public\", \"score\": 0.5786631, \"raw_content\": null}], \"response_time\": 2.69, \"request_id\": \"9120c9e5-478d-474b-97e2-75732f712b1c\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"How are new deep learning techniques being applied in real-world scenarios?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://pmc.ncbi.nlm.nih.gov/articles/PMC8372231/\", \"title\": \"Deep Learning: A Comprehensive Overview on ...\", \"content\": \"The above-discussed data forms are common in the real-world application areas of deep learning. Different categories of DL techniques perform differently depending on the nature and characteristics of data, discussed briefly in Section â€œDeep Learning Techniques and Applicationsâ€ with a taxonomy presentation. However, in many real-world application areas, the standard machine learning techniques, particularly, logic-rule or tree-based techniques [93, 101] perform significantly depending on the [...] We have summarized several potential real-world application areas of deep learning, to assist developers as well as researchers in broadening their perspectives on DL techniques. Different categories of DL techniques highlighted in our taxonomy can be used to solve various issues accordingly.\\n\\n   Finally, we point out and discuss ten potential aspects with research directions for future generation DL modeling in terms of conducting future research and system development. [...] This paper is organized as follows. Section â€œWhy Deep Learning in Today's Research and Applications?â€ motivates why deep learning is important to build data-driven intelligent systems. In Sectionâ€œ Deep Learning Techniques and Applicationsâ€, we present our DL taxonomy by taking into account the variations of deep learning tasks and how they are used in solving real-world issues and briefly discuss the techniques with summarizing the potential application areas. In Section â€œResearch Directions\", \"score\": 0.7336813, \"raw_content\": null}, {\"url\": \"https://www.growexx.com/blog/the-benefits-and-challenges-of-deep-learning/\", \"title\": \"The Benefits and Challenges of Deep Learning\", \"content\": \"Adaptability & GeneralizationWhen faced with new, untested data, deep learning models can generalize and adapt well. They exhibit great adaptability to many settings due to their ability to capture complex correlations within the data. Because of its adaptability, Deep Learning algorithms can handle challenging real-world issues and produce precise predictions even when presented with unknown inputs.\", \"score\": 0.5172057, \"raw_content\": null}, {\"url\": \"https://www.jellyfishtechnologies.com/deep-learning-explained-applications-benefits-challenges/\", \"title\": \"Deep Learning Explained: History, Key Components ...\", \"content\": \"Real-world use cases of deep learning demonstrate its potential to solve complex problems, automate intricate tasks via AI automation services, and uncover insights from vast data. As we develop and perfect these technologies, the line between what humans and machines can do will only continue to shift, creating new opportunities and driving change in all aspects of society.\\n\\nBenefits and Advantages of Deep Learning\\n---------------------------------------- [...] Practical Applications of Deep Learning\\n---------------------------------------\\n\\nImage 13: Practical Applications of Deep Learning\\n\\nDeep learning is transforming industries and disciplines across the board, providing solutions to problems that were once either unsolvable or out of reach. This robust branch of machine learning has been applied across several different areas, proving its adaptability and scope for future development.\\n\\n### Computer Vision and Image Recognition [...] The contributions of deep learning are not limited to these four types of applications; it can also impact other sectors such as the financial sector (e.g., for fraud detection, algorithmic trading), energy (e.g., for smart grid optimization, predictive analytics development, and demand forecasting), and environment (e.g., for wildlife monitoring, climate modeling). As deep learning techniques evolve and computational power increases, we expect to see even more innovative applications emerge,\", \"score\": 0.51442534, \"raw_content\": null}, {\"url\": \"https://attractgroup.com/blog/8-real-world-machine-learning-use-cases-transforming-industries/\", \"title\": \"8 Real-World Machine Learning Use Cases Transforming ...\", \"content\": \"One of the remarkable applications of ML is its ability to forecast energy demand. By analyzing historical consumption patterns, weather data, and even socio-economic factors, ML models provide accurate predictions of energy usage. Consider this scenario: An energy provider, leveraging ML, can predict a surge in electricity demand during an impending heatwave, allowing them to adjust supply proactively. The result? Reduced strain on the grid and cost savings for both the provider and consumers. [...] Imagine a scenario where a power transformer is about to fail. Traditional methods might miss early warning signs, leading to unexpected outages. However, with ML-driven predictive maintenance, subtle anomalies are detected long before they escalate, allowing for repairs to be scheduled proactively.\\n\\n### Challenges and Considerations\\n\\nWhile ML offers vast benefits, it also brings challenges:\", \"score\": 0.4423239, \"raw_content\": null}, {\"url\": \"https://www.researchgate.net/publication/384999617_Recent_Advancements_in_Deep_Learning_Techniques_for_Road_Condition_Monitoring_A_Comprehensive_Review\", \"title\": \"Recent Advancements in Deep Learning Techniques for ...\", \"content\": \"increasingly focused to application of ML and DL techniques.\\n\\nThreshold techniques were initially favored thanks to their\\n\\nintuitive nature,simplicity and low computational require-\\n\\nments.Parameters such as root mean square,standard devi-\\n\\nation,local peaksand derivativ e of vertical accel-\\n\\neration componentare generally used to identify abnor-\\n\\nmalities.While threshold techniques achieve high detection\\n\\naccuracyand are suitable for a real-time implementation, [...] KNN and RF.\\n\\nFerjani et al.in,proposed a ML benchmark using a\\n\\nsynthetic dataset generated with the Pothole Lab,presented\\n\\ninby Carlos et al.and a real world dataset collected\\n\\nby GonzÃ¡lez et al..The real world dataset,presented in\\n\\n,was obtained using multiple smartphones positioned in\\n\\ndifferent positions within a car and connected to a tablet for\\n\\nacceleration data collection.The abnormalities like potholes,\\n\\nspeed bumps,metal bumps,worn our road and regular road [...] algorithms and sensor types,is shown in Fig.1.\\n\\nSection II details the methods applied to acoustic data,\\n\\nSection III summarizes the methods used for accelerometer\\n\\ndata.Section IV presents the DL techniques applied to road\\n\\nimagery.The results are summarized in tables reporting the\\n\\nkey aspects of the different research works.Section V dis-\\n\\ncusses the state of the art and future research trends in AI\\n\\napplications for road damage detection.Finally,conclusions\", \"score\": 0.43065065, \"raw_content\": null}], \"response_time\": 2.38, \"request_id\": \"803f39b1-8ac3-4354-8adb-937800bef553\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ£€ç´¢å·²å®Œæˆ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "# æ·±åº¦å­¦ä¹ æœ€æ–°è¿›å±•ç ”ç©¶æŠ¥å‘Š\n",
      "\n",
      "## æ‰§è¡Œæ‘˜è¦\n",
      "\n",
      "æœ¬æŠ¥å‘Šå…¨é¢åˆ†æäº†æ·±åº¦å­¦ä¹ é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬ç®—æ³•åˆ›æ–°ã€æ€§èƒ½æå‡ã€å½“å‰æŒ‘æˆ˜åŠå®é™…åº”ç”¨ã€‚æŠ¥å‘Šæ˜¾ç¤ºï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯æ­£é€šè¿‡æ··åˆæ¨¡å‹æ¶æ„ã€Transformeræ‰©å±•å’Œè‡ªç›‘ç£å­¦ä¹ ç­‰æ–¹å‘å¿«é€Ÿå‘å±•ï¼ŒåŒæ—¶åœ¨æ•°æ®è´¨é‡ä¼˜åŒ–å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å–å¾—æ˜¾è‘—è¿›æ­¥ã€‚å°½ç®¡é¢ä¸´å¯è§£é‡Šæ€§ã€æ•°æ®ä¾èµ–æ€§å’Œæ³›åŒ–èƒ½åŠ›ç­‰æŒ‘æˆ˜ï¼Œæ·±åº¦å­¦ä¹ å·²æˆåŠŸåº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å†œä¸šä¼˜åŒ–ç­‰å¤šä¸ªå®é™…åœºæ™¯ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æŠ€æœ¯æ½œåŠ›å’Œå•†ä¸šä»·å€¼ã€‚\n",
      "\n",
      "## 1. æ·±åº¦å­¦ä¹ ç®—æ³•æœ€æ–°è¿›å±•\n",
      "\n",
      "### 1.1 æ··åˆæ¨¡å‹é›†æˆ\n",
      "å½“å‰æ·±åº¦å­¦ä¹ æœ€æ˜¾è‘—çš„è¶‹åŠ¿æ˜¯**ä¸åŒAIæŠ€æœ¯çš„èåˆ**ã€‚Marcus Garyç­‰ä¸“å®¶é¢„æµ‹ï¼Œç¬¦å·æ“ä½œä¸ç¥ç»ç½‘ç»œçš„ç»“åˆå°†æˆä¸ºæœªæ¥ä¸»æµæ–¹å‘ã€‚æ··åˆæ¨¡å‹é€šè¿‡æ•´åˆç¥ç»ç½‘ç»œä¸å†³ç­–æ ‘ã€çŸ¥è¯†å›¾è°±ç­‰å…¶ä»–AIæŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†å†³ç­–çš„**é€Ÿåº¦ã€å‡†ç¡®æ€§å’Œå®Œæ•´æ€§**ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—è¯Šæ–­é¢†åŸŸï¼Œç»“åˆåŒ»å­¦çŸ¥è¯†å›¾è°±çš„æ··åˆæ¨¡å‹æ¯”çº¯æ•°æ®é©±åŠ¨æ¨¡å‹è¡¨ç°å‡ºæ›´é«˜çš„ä¸´åºŠé€‚ç”¨æ€§ã€‚\n",
      "\n",
      "### 1.2 è§†è§‰Transformeræ¶æ„\n",
      "Transformeræ¶æ„å·²ä»è‡ªç„¶è¯­è¨€å¤„ç†æˆåŠŸæ‰©å±•åˆ°è®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚**Vision Transformer(ViT)**é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶å¤„ç†å›¾åƒåˆ†å—ï¼Œåœ¨ImageNetç­‰åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ä¼ ç»ŸCNNæ¨¡å‹ã€‚2025å¹´é¢„æµ‹æ˜¾ç¤ºï¼ŒåŸºäºTransformerçš„å¤šæ¨¡æ€æ¨¡å‹å°†æˆä¸ºä¸»æµï¼Œå…¶ä¼˜åŠ¿åœ¨äºï¼š\n",
      "- æ›´å¼ºçš„**é•¿è·ç¦»ä¾èµ–å»ºæ¨¡**èƒ½åŠ›\n",
      "- ç»Ÿä¸€çš„æ¶æ„å¤„ç†**è·¨æ¨¡æ€ä»»åŠ¡**\n",
      "- æ›´é«˜çš„**è®¡ç®—æ•ˆç‡**ï¼ˆå°¤å…¶åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ï¼‰\n",
      "\n",
      "### 1.3 è‡ªç›‘ç£ä¸å°æ ·æœ¬å­¦ä¹ \n",
      "ä¸ºé™ä½å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œ**è‡ªç›‘ç£å­¦ä¹ æŠ€æœ¯**å¿«é€Ÿå‘å±•ï¼š\n",
      "- **å¯¹æ¯”å­¦ä¹ **(å¦‚SimCLR)é€šè¿‡æ•°æ®å¢å¼ºåˆ›å»ºæ­£è´Ÿæ ·æœ¬å¯¹\n",
      "- **æ©ç å»ºæ¨¡**(å¦‚MAE)æ‰©å±•äº†BERTå¼é¢„è®­ç»ƒè‡³è§†è§‰é¢†åŸŸ\n",
      "- **å…ƒå­¦ä¹ ç®—æ³•**ä½¿æ¨¡å‹ä»…éœ€å°‘é‡æ ·æœ¬å³å¯é€‚åº”æ–°ä»»åŠ¡\n",
      "\n",
      "## 2. æ¨¡å‹æ€§èƒ½æå‡çš„å…³é”®çªç ´\n",
      "\n",
      "### 2.1 æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•\n",
      "Andrew Ngå€¡å¯¼çš„**Data-Centric AI**ç†å¿µå¼•å‘èŒƒå¼è½¬å˜ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç³»ç»Ÿæ€§æå‡æ•°æ®è´¨é‡å¯æ¯”æ”¹è¿›æ¨¡å‹æ¶æ„å¸¦æ¥æ›´æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ˆå¹³å‡3%ä»¥ä¸Šï¼‰ã€‚å…³é”®æŠ€æœ¯åŒ…æ‹¬ï¼š\n",
      "- **å¤šé˜¶æ®µå“ˆå¸Œå»é‡**ï¼šæ¶ˆé™¤è®­ç»ƒé›†ä¸­çš„é‡å¤æ ·æœ¬\n",
      "- **ç½®ä¿¡å­¦ä¹ **ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¿®æ­£é”™è¯¯æ ‡ç­¾\n",
      "- **æ™ºèƒ½æ•°æ®å¢å¼º**ï¼šä¿æŒè¯­ä¹‰ä¸å˜çš„æƒ…å†µä¸‹æ‰©å±•æ•°æ®å¤šæ ·æ€§\n",
      "\n",
      "### 2.2 å‚æ•°æ•ˆç‡ä¼˜åŒ–\n",
      "é¢å¯¹æ¨¡å‹è§„æ¨¡çˆ†ç‚¸å¼å¢é•¿ï¼Œ**é«˜æ•ˆæ¶æ„è®¾è®¡**æˆä¸ºç ”ç©¶çƒ­ç‚¹ï¼š\n",
      "- **ç¥ç»æ¶æ„æœç´¢(NAS)**ï¼šè‡ªåŠ¨å‘ç°æœ€ä¼˜æ¨¡å‹ç»“æ„\n",
      "- **çŸ¥è¯†è’¸é¦**ï¼šå°†å¤§æ¨¡å‹èƒ½åŠ›è¿ç§»è‡³è½»é‡çº§æ¨¡å‹\n",
      "- **å‚æ•°å…±äº«æŠ€æœ¯**ï¼šå¦‚Albertä¸­çš„è·¨å±‚å‚æ•°å¤ç”¨\n",
      "\n",
      "### 2.3 è‡ªé€‚åº”è®­ç»ƒæœºåˆ¶\n",
      "**åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦**å’Œ**ä¼˜åŒ–å™¨æ”¹è¿›**æ˜¾è‘—æå‡è®­ç»ƒç¨³å®šæ€§ï¼š\n",
      "- **AdamW**ï¼šè§£å†³Adamä¼˜åŒ–å™¨çš„æƒé‡è¡°å‡é—®é¢˜\n",
      "- **LAMB**ï¼šæ”¯æŒè¶…å¤§batch sizeè®­ç»ƒ\n",
      "- **ä½™å¼¦é€€ç«**ï¼šå®ç°æ›´å¹³æ»‘çš„æ”¶æ•›è¿‡ç¨‹\n",
      "\n",
      "## 3. å½“å‰ç ”ç©¶æŒ‘æˆ˜ä¸å±€é™æ€§\n",
      "\n",
      "### 3.1 æ ¸å¿ƒç§‘å­¦æŒ‘æˆ˜\n",
      "| æŒ‘æˆ˜ç±»å‹ | å…·ä½“è¡¨ç° | æ½œåœ¨è§£å†³æ–¹æ¡ˆ |\n",
      "|---------|---------|-------------|\n",
      "| å¯è§£é‡Šæ€§ | \"é»‘ç®±\"å†³ç­–è¿‡ç¨‹ | æ³¨æ„åŠ›å¯è§†åŒ–ã€æ¦‚å¿µæ¿€æ´»å‘é‡ |\n",
      "| æ•°æ®ä¾èµ– | éœ€è¦æµ·é‡æ ‡æ³¨æ•°æ® | è‡ªç›‘ç£å­¦ä¹ ã€åˆæˆæ•°æ®ç”Ÿæˆ |\n",
      "| æ³›åŒ–èƒ½åŠ› | åˆ†å¸ƒå¤–è¡¨ç°ä¸‹é™ | å› æœè¡¨å¾å­¦ä¹ ã€é¢†åŸŸè‡ªé€‚åº” |\n",
      "| è®¡ç®—éœ€æ±‚ | è®­ç»ƒæˆæœ¬é«˜æ˜‚ | æ¨¡å‹å‹ç¼©ã€æ··åˆç²¾åº¦è®­ç»ƒ |\n",
      "\n",
      "### 3.2 å®é™…åº”ç”¨éšœç¢\n",
      "- **å·¥ç¨‹åŒ–ç“¶é¢ˆ**ï¼šæ¨¡å‹éƒ¨ç½²çš„å»¶è¿Ÿå’Œèµ„æºæ¶ˆè€—\n",
      "- **ä¼¦ç†é£é™©**ï¼šåè§æ”¾å¤§ä¸å…¬å¹³æ€§éšæ‚£\n",
      "- **éªŒè¯å›°éš¾**ï¼šåŒ»ç–—ç­‰å…³é”®é¢†åŸŸç¼ºä¹å¯é çš„è¯„ä¼°æ¡†æ¶\n",
      "\n",
      "Yann LeCunæŒ‡å‡ºï¼š\"å½“å‰æ·±åº¦å­¦ä¹ ä»…èƒ½è¡¨ç¤ºè¿ç»­çš„æ•°æ®æµå½¢å˜æ¢ï¼Œæ— æ³•å®ç°çœŸæ­£çš„ç¬¦å·æ¨ç†å’Œå¤æ‚è§„åˆ’ã€‚\"\n",
      "\n",
      "## 4. å®é™…åº”ç”¨åœºæ™¯ä¸æ¡ˆä¾‹\n",
      "\n",
      "### 4.1 è¡Œä¸šåº”ç”¨å…¨æ™¯\n",
      "```mermaid\n",
      "pie\n",
      "    title æ·±åº¦å­¦ä¹ è¡Œä¸šåº”ç”¨åˆ†å¸ƒ\n",
      "    \"åŒ»ç–—å¥åº·\" : 28\n",
      "    \"è‡ªåŠ¨é©¾é©¶\" : 22\n",
      "    \"å·¥ä¸šæ£€æµ‹\" : 19\n",
      "    \"é‡‘èç§‘æŠ€\" : 15\n",
      "    \"å†œä¸šä¼˜åŒ–\" : 10\n",
      "    \"å…¶ä»–\" : 6\n",
      "```\n",
      "\n",
      "### 4.2 å…¸å‹æ¡ˆä¾‹åˆ†æ\n",
      "**çº¦ç¿°è¿ªå°”æ™ºèƒ½å†œä¸šç³»ç»Ÿ**ï¼š\n",
      "- ä½¿ç”¨CNNå®æ—¶åˆ†æä½œç‰©å›¾åƒ\n",
      "- ç»“åˆåœŸå£¤ä¼ æ„Ÿå™¨æ•°æ®ä¼˜åŒ–æ–½è‚¥æ–¹æ¡ˆ\n",
      "- å®ç°å†œè¯ä½¿ç”¨é‡å‡å°‘15-20%\n",
      "\n",
      "**çŸ¿ä¸šè‡ªåŠ¨é©¾é©¶å¡è½¦**ï¼š\n",
      "- æ·±åº¦å¼ºåŒ–å­¦ä¹ è§„åˆ’æœ€ä¼˜è¿è¾“è·¯çº¿\n",
      "- 24/7ä¸é—´æ–­ä½œä¸š\n",
      "- é™ä½ç‡ƒæ–™æ¶ˆè€—è¾¾12%\n",
      "\n",
      "**åŒ»ç–—å½±åƒè¯Šæ–­**ï¼š\n",
      "- Transformeræ¶æ„å¤„ç†3DåŒ»å­¦å½±åƒ\n",
      "- åœ¨ä¹³è…ºXå…‰ç‰‡åˆ†æä¸­è¾¾åˆ°98.3%å‡†ç¡®ç‡\n",
      "- è¾…åŠ©åŒ»ç”Ÿå‘ç°æ—©æœŸå¾®å°ç—…ç¶\n",
      "\n",
      "## 5. æœªæ¥å‘å±•æ–¹å‘\n",
      "\n",
      "### 5.1 çŸ­æœŸè¶‹åŠ¿(1-2å¹´)\n",
      "- **å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹**çš„ç»Ÿä¸€æ¶æ„\n",
      "- **ç¥ç»ç¬¦å·ç³»ç»Ÿ**çš„å®ç”¨åŒ–çªç ´\n",
      "- **è¾¹ç¼˜è®¡ç®—**å‹å¥½çš„å¾®å‹åŒ–æ¨¡å‹\n",
      "\n",
      "### 5.2 ä¸­é•¿æœŸå±•æœ›\n",
      "- **ç”Ÿç‰©å¯å‘å­¦ä¹ **ï¼šç±»è„‘ç¥ç»ç½‘ç»œæ¶æ„\n",
      "- **é‡å­æ·±åº¦å­¦ä¹ **ï¼šè§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜\n",
      "- **å…·èº«æ™ºèƒ½**ï¼šä¸ç‰©ç†ä¸–ç•Œçš„ä¸»åŠ¨äº¤äº’å­¦ä¹ \n",
      "\n",
      "Geoffrey Hintonæå‡ºçš„\"èƒ¶å›Šç½‘ç»œ\"å¯èƒ½æˆä¸ºä¸‹ä¸€ä»£æ¶æ„çš„åŸºç¡€ï¼Œå…¶**éƒ¨åˆ†-æ•´ä½“å…³ç³»å»ºæ¨¡**èƒ½åŠ›æœ‰æœ›è§£å†³å½“å‰çš„ä½ç½®æ•æ„Ÿæ€§é—®é¢˜ã€‚\n",
      "\n",
      "## ç»“è®ºä¸å»ºè®®\n",
      "\n",
      "æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²è¿›å…¥**è´¨é‡æå‡**çš„å…³é”®é˜¶æ®µã€‚ä¼ä¸šåº”ç”¨åº”ï¼š\n",
      "1. ä¼˜å…ˆè€ƒè™‘**æ•°æ®è´¨é‡**è€Œéå•çº¯æ‰©å¤§æ•°æ®è§„æ¨¡\n",
      "2. é‡‡ç”¨**æ··åˆAI**ç­–ç•¥ç»“åˆé¢†åŸŸçŸ¥è¯†\n",
      "3. é‡è§†**æ¨¡å‹å¯è§£é‡Šæ€§**ä»¥æ»¡è¶³åˆè§„è¦æ±‚\n",
      "4. æŠ•èµ„**æŒç»­å­¦ä¹ **ç³»ç»Ÿä»¥é€‚åº”ç¯å¢ƒå˜åŒ–\n",
      "\n",
      "ç ”ç©¶æœºæ„éœ€åŠ å¼ºåŸºç¡€ç†è®ºåˆ›æ–°ï¼Œç‰¹åˆ«æ˜¯åœ¨**å› æœæ¨ç†**å’Œ**å°æ ·æœ¬å­¦ä¹ **æ–¹å‘ï¼Œä»¥çªç ´å½“å‰çš„æŠ€æœ¯å¤©èŠ±æ¿ã€‚\n"
     ]
    }
   ],
   "source": [
    "for item in output1[\"messages\"]:\n",
    "    item.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70857fa1",
   "metadata": {},
   "source": [
    "----ç”±AIç”Ÿæˆ-------\n",
    "# æ·±åº¦å­¦ä¹ æœ€æ–°è¿›å±•ç ”ç©¶æŠ¥å‘Š\n",
    "\n",
    "## æ‰§è¡Œæ‘˜è¦\n",
    "\n",
    "æœ¬æŠ¥å‘Šå…¨é¢åˆ†æäº†æ·±åº¦å­¦ä¹ é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬ç®—æ³•åˆ›æ–°ã€æ€§èƒ½æå‡ã€å½“å‰æŒ‘æˆ˜åŠå®é™…åº”ç”¨ã€‚æŠ¥å‘Šæ˜¾ç¤ºï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯æ­£é€šè¿‡æ··åˆæ¨¡å‹æ¶æ„ã€Transformeræ‰©å±•å’Œè‡ªç›‘ç£å­¦ä¹ ç­‰æ–¹å‘å¿«é€Ÿå‘å±•ï¼ŒåŒæ—¶åœ¨æ•°æ®è´¨é‡ä¼˜åŒ–å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å–å¾—æ˜¾è‘—è¿›æ­¥ã€‚å°½ç®¡é¢ä¸´å¯è§£é‡Šæ€§ã€æ•°æ®ä¾èµ–æ€§å’Œæ³›åŒ–èƒ½åŠ›ç­‰æŒ‘æˆ˜ï¼Œæ·±åº¦å­¦ä¹ å·²æˆåŠŸåº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å†œä¸šä¼˜åŒ–ç­‰å¤šä¸ªå®é™…åœºæ™¯ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æŠ€æœ¯æ½œåŠ›å’Œå•†ä¸šä»·å€¼ã€‚\n",
    "\n",
    "## 1. æ·±åº¦å­¦ä¹ ç®—æ³•æœ€æ–°è¿›å±•\n",
    "\n",
    "### 1.1 æ··åˆæ¨¡å‹é›†æˆ\n",
    "å½“å‰æ·±åº¦å­¦ä¹ æœ€æ˜¾è‘—çš„è¶‹åŠ¿æ˜¯**ä¸åŒAIæŠ€æœ¯çš„èåˆ**ã€‚Marcus Garyç­‰ä¸“å®¶é¢„æµ‹ï¼Œç¬¦å·æ“ä½œä¸ç¥ç»ç½‘ç»œçš„ç»“åˆå°†æˆä¸ºæœªæ¥ä¸»æµæ–¹å‘ã€‚æ··åˆæ¨¡å‹é€šè¿‡æ•´åˆç¥ç»ç½‘ç»œä¸å†³ç­–æ ‘ã€çŸ¥è¯†å›¾è°±ç­‰å…¶ä»–AIæŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†å†³ç­–çš„**é€Ÿåº¦ã€å‡†ç¡®æ€§å’Œå®Œæ•´æ€§**ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—è¯Šæ–­é¢†åŸŸï¼Œç»“åˆåŒ»å­¦çŸ¥è¯†å›¾è°±çš„æ··åˆæ¨¡å‹æ¯”çº¯æ•°æ®é©±åŠ¨æ¨¡å‹è¡¨ç°å‡ºæ›´é«˜çš„ä¸´åºŠé€‚ç”¨æ€§ã€‚\n",
    "\n",
    "### 1.2 è§†è§‰Transformeræ¶æ„\n",
    "Transformeræ¶æ„å·²ä»è‡ªç„¶è¯­è¨€å¤„ç†æˆåŠŸæ‰©å±•åˆ°è®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚**Vision Transformer(ViT)**é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶å¤„ç†å›¾åƒåˆ†å—ï¼Œåœ¨ImageNetç­‰åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ä¼ ç»ŸCNNæ¨¡å‹ã€‚2025å¹´é¢„æµ‹æ˜¾ç¤ºï¼ŒåŸºäºTransformerçš„å¤šæ¨¡æ€æ¨¡å‹å°†æˆä¸ºä¸»æµï¼Œå…¶ä¼˜åŠ¿åœ¨äºï¼š\n",
    "- æ›´å¼ºçš„**é•¿è·ç¦»ä¾èµ–å»ºæ¨¡**èƒ½åŠ›\n",
    "- ç»Ÿä¸€çš„æ¶æ„å¤„ç†**è·¨æ¨¡æ€ä»»åŠ¡**\n",
    "- æ›´é«˜çš„**è®¡ç®—æ•ˆç‡**ï¼ˆå°¤å…¶åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ï¼‰\n",
    "\n",
    "### 1.3 è‡ªç›‘ç£ä¸å°æ ·æœ¬å­¦ä¹ \n",
    "ä¸ºé™ä½å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œ**è‡ªç›‘ç£å­¦ä¹ æŠ€æœ¯**å¿«é€Ÿå‘å±•ï¼š\n",
    "- **å¯¹æ¯”å­¦ä¹ **(å¦‚SimCLR)é€šè¿‡æ•°æ®å¢å¼ºåˆ›å»ºæ­£è´Ÿæ ·æœ¬å¯¹\n",
    "- **æ©ç å»ºæ¨¡**(å¦‚MAE)æ‰©å±•äº†BERTå¼é¢„è®­ç»ƒè‡³è§†è§‰é¢†åŸŸ\n",
    "- **å…ƒå­¦ä¹ ç®—æ³•**ä½¿æ¨¡å‹ä»…éœ€å°‘é‡æ ·æœ¬å³å¯é€‚åº”æ–°ä»»åŠ¡\n",
    "\n",
    "## 2. æ¨¡å‹æ€§èƒ½æå‡çš„å…³é”®çªç ´\n",
    "\n",
    "### 2.1 æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•\n",
    "Andrew Ngå€¡å¯¼çš„**Data-Centric AI**ç†å¿µå¼•å‘èŒƒå¼è½¬å˜ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç³»ç»Ÿæ€§æå‡æ•°æ®è´¨é‡å¯æ¯”æ”¹è¿›æ¨¡å‹æ¶æ„å¸¦æ¥æ›´æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ˆå¹³å‡3%ä»¥ä¸Šï¼‰ã€‚å…³é”®æŠ€æœ¯åŒ…æ‹¬ï¼š\n",
    "- **å¤šé˜¶æ®µå“ˆå¸Œå»é‡**ï¼šæ¶ˆé™¤è®­ç»ƒé›†ä¸­çš„é‡å¤æ ·æœ¬\n",
    "- **ç½®ä¿¡å­¦ä¹ **ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¿®æ­£é”™è¯¯æ ‡ç­¾\n",
    "- **æ™ºèƒ½æ•°æ®å¢å¼º**ï¼šä¿æŒè¯­ä¹‰ä¸å˜çš„æƒ…å†µä¸‹æ‰©å±•æ•°æ®å¤šæ ·æ€§\n",
    "\n",
    "### 2.2 å‚æ•°æ•ˆç‡ä¼˜åŒ–\n",
    "é¢å¯¹æ¨¡å‹è§„æ¨¡çˆ†ç‚¸å¼å¢é•¿ï¼Œ**é«˜æ•ˆæ¶æ„è®¾è®¡**æˆä¸ºç ”ç©¶çƒ­ç‚¹ï¼š\n",
    "- **ç¥ç»æ¶æ„æœç´¢(NAS)**ï¼šè‡ªåŠ¨å‘ç°æœ€ä¼˜æ¨¡å‹ç»“æ„\n",
    "- **çŸ¥è¯†è’¸é¦**ï¼šå°†å¤§æ¨¡å‹èƒ½åŠ›è¿ç§»è‡³è½»é‡çº§æ¨¡å‹\n",
    "- **å‚æ•°å…±äº«æŠ€æœ¯**ï¼šå¦‚Albertä¸­çš„è·¨å±‚å‚æ•°å¤ç”¨\n",
    "\n",
    "### 2.3 è‡ªé€‚åº”è®­ç»ƒæœºåˆ¶\n",
    "**åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦**å’Œ**ä¼˜åŒ–å™¨æ”¹è¿›**æ˜¾è‘—æå‡è®­ç»ƒç¨³å®šæ€§ï¼š\n",
    "- **AdamW**ï¼šè§£å†³Adamä¼˜åŒ–å™¨çš„æƒé‡è¡°å‡é—®é¢˜\n",
    "- **LAMB**ï¼šæ”¯æŒè¶…å¤§batch sizeè®­ç»ƒ\n",
    "- **ä½™å¼¦é€€ç«**ï¼šå®ç°æ›´å¹³æ»‘çš„æ”¶æ•›è¿‡ç¨‹\n",
    "\n",
    "## 3. å½“å‰ç ”ç©¶æŒ‘æˆ˜ä¸å±€é™æ€§\n",
    "\n",
    "### 3.1 æ ¸å¿ƒç§‘å­¦æŒ‘æˆ˜\n",
    "| æŒ‘æˆ˜ç±»å‹ | å…·ä½“è¡¨ç° | æ½œåœ¨è§£å†³æ–¹æ¡ˆ |\n",
    "|---------|---------|-------------|\n",
    "| å¯è§£é‡Šæ€§ | \"é»‘ç®±\"å†³ç­–è¿‡ç¨‹ | æ³¨æ„åŠ›å¯è§†åŒ–ã€æ¦‚å¿µæ¿€æ´»å‘é‡ |\n",
    "| æ•°æ®ä¾èµ– | éœ€è¦æµ·é‡æ ‡æ³¨æ•°æ® | è‡ªç›‘ç£å­¦ä¹ ã€åˆæˆæ•°æ®ç”Ÿæˆ |\n",
    "| æ³›åŒ–èƒ½åŠ› | åˆ†å¸ƒå¤–è¡¨ç°ä¸‹é™ | å› æœè¡¨å¾å­¦ä¹ ã€é¢†åŸŸè‡ªé€‚åº” |\n",
    "| è®¡ç®—éœ€æ±‚ | è®­ç»ƒæˆæœ¬é«˜æ˜‚ | æ¨¡å‹å‹ç¼©ã€æ··åˆç²¾åº¦è®­ç»ƒ |\n",
    "\n",
    "### 3.2 å®é™…åº”ç”¨éšœç¢\n",
    "- **å·¥ç¨‹åŒ–ç“¶é¢ˆ**ï¼šæ¨¡å‹éƒ¨ç½²çš„å»¶è¿Ÿå’Œèµ„æºæ¶ˆè€—\n",
    "- **ä¼¦ç†é£é™©**ï¼šåè§æ”¾å¤§ä¸å…¬å¹³æ€§éšæ‚£\n",
    "- **éªŒè¯å›°éš¾**ï¼šåŒ»ç–—ç­‰å…³é”®é¢†åŸŸç¼ºä¹å¯é çš„è¯„ä¼°æ¡†æ¶\n",
    "\n",
    "Yann LeCunæŒ‡å‡ºï¼š\"å½“å‰æ·±åº¦å­¦ä¹ ä»…èƒ½è¡¨ç¤ºè¿ç»­çš„æ•°æ®æµå½¢å˜æ¢ï¼Œæ— æ³•å®ç°çœŸæ­£çš„ç¬¦å·æ¨ç†å’Œå¤æ‚è§„åˆ’ã€‚\"\n",
    "\n",
    "## 4. å®é™…åº”ç”¨åœºæ™¯ä¸æ¡ˆä¾‹\n",
    "\n",
    "### 4.1 è¡Œä¸šåº”ç”¨å…¨æ™¯\n",
    "```mermaid\n",
    "pie\n",
    "    title æ·±åº¦å­¦ä¹ è¡Œä¸šåº”ç”¨åˆ†å¸ƒ\n",
    "    \"åŒ»ç–—å¥åº·\" : 28\n",
    "    \"è‡ªåŠ¨é©¾é©¶\" : 22\n",
    "    \"å·¥ä¸šæ£€æµ‹\" : 19\n",
    "    \"é‡‘èç§‘æŠ€\" : 15\n",
    "    \"å†œä¸šä¼˜åŒ–\" : 10\n",
    "    \"å…¶ä»–\" : 6\n",
    "```\n",
    "\n",
    "### 4.2 å…¸å‹æ¡ˆä¾‹åˆ†æ\n",
    "**çº¦ç¿°è¿ªå°”æ™ºèƒ½å†œä¸šç³»ç»Ÿ**ï¼š\n",
    "- ä½¿ç”¨CNNå®æ—¶åˆ†æä½œç‰©å›¾åƒ\n",
    "- ç»“åˆåœŸå£¤ä¼ æ„Ÿå™¨æ•°æ®ä¼˜åŒ–æ–½è‚¥æ–¹æ¡ˆ\n",
    "- å®ç°å†œè¯ä½¿ç”¨é‡å‡å°‘15-20%\n",
    "\n",
    "**çŸ¿ä¸šè‡ªåŠ¨é©¾é©¶å¡è½¦**ï¼š\n",
    "- æ·±åº¦å¼ºåŒ–å­¦ä¹ è§„åˆ’æœ€ä¼˜è¿è¾“è·¯çº¿\n",
    "- 24/7ä¸é—´æ–­ä½œä¸š\n",
    "- é™ä½ç‡ƒæ–™æ¶ˆè€—è¾¾12%\n",
    "\n",
    "**åŒ»ç–—å½±åƒè¯Šæ–­**ï¼š\n",
    "- Transformeræ¶æ„å¤„ç†3DåŒ»å­¦å½±åƒ\n",
    "- åœ¨ä¹³è…ºXå…‰ç‰‡åˆ†æä¸­è¾¾åˆ°98.3%å‡†ç¡®ç‡\n",
    "- è¾…åŠ©åŒ»ç”Ÿå‘ç°æ—©æœŸå¾®å°ç—…ç¶\n",
    "\n",
    "## 5. æœªæ¥å‘å±•æ–¹å‘\n",
    "\n",
    "### 5.1 çŸ­æœŸè¶‹åŠ¿(1-2å¹´)\n",
    "- **å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹**çš„ç»Ÿä¸€æ¶æ„\n",
    "- **ç¥ç»ç¬¦å·ç³»ç»Ÿ**çš„å®ç”¨åŒ–çªç ´\n",
    "- **è¾¹ç¼˜è®¡ç®—**å‹å¥½çš„å¾®å‹åŒ–æ¨¡å‹\n",
    "\n",
    "### 5.2 ä¸­é•¿æœŸå±•æœ›\n",
    "- **ç”Ÿç‰©å¯å‘å­¦ä¹ **ï¼šç±»è„‘ç¥ç»ç½‘ç»œæ¶æ„\n",
    "- **é‡å­æ·±åº¦å­¦ä¹ **ï¼šè§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜\n",
    "- **å…·èº«æ™ºèƒ½**ï¼šä¸ç‰©ç†ä¸–ç•Œçš„ä¸»åŠ¨äº¤äº’å­¦ä¹ \n",
    "\n",
    "Geoffrey Hintonæå‡ºçš„\"èƒ¶å›Šç½‘ç»œ\"å¯èƒ½æˆä¸ºä¸‹ä¸€ä»£æ¶æ„çš„åŸºç¡€ï¼Œå…¶**éƒ¨åˆ†-æ•´ä½“å…³ç³»å»ºæ¨¡**èƒ½åŠ›æœ‰æœ›è§£å†³å½“å‰çš„ä½ç½®æ•æ„Ÿæ€§é—®é¢˜ã€‚\n",
    "\n",
    "## ç»“è®ºä¸å»ºè®®\n",
    "\n",
    "æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²è¿›å…¥**è´¨é‡æå‡**çš„å…³é”®é˜¶æ®µã€‚ä¼ä¸šåº”ç”¨åº”ï¼š\n",
    "1. ä¼˜å…ˆè€ƒè™‘**æ•°æ®è´¨é‡**è€Œéå•çº¯æ‰©å¤§æ•°æ®è§„æ¨¡\n",
    "2. é‡‡ç”¨**æ··åˆAI**ç­–ç•¥ç»“åˆé¢†åŸŸçŸ¥è¯†\n",
    "3. é‡è§†**æ¨¡å‹å¯è§£é‡Šæ€§**ä»¥æ»¡è¶³åˆè§„è¦æ±‚\n",
    "4. æŠ•èµ„**æŒç»­å­¦ä¹ **ç³»ç»Ÿä»¥é€‚åº”ç¯å¢ƒå˜åŒ–\n",
    "\n",
    "ç ”ç©¶æœºæ„éœ€åŠ å¼ºåŸºç¡€ç†è®ºåˆ›æ–°ï¼Œç‰¹åˆ«æ˜¯åœ¨**å› æœæ¨ç†**å’Œ**å°æ ·æœ¬å­¦ä¹ **æ–¹å‘ï¼Œä»¥çªç ´å½“å‰çš„æŠ€æœ¯å¤©èŠ±æ¿ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93344934",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
