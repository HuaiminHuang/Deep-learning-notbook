{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edbbb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MOEConfig:\n",
    "    def __init__(self, hidden_dim, expert_number, top_k, shared_expert_number=2):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "        self.shared_expert_number = shared_expert_number\n",
    "\n",
    "class BasicExpert(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, intermediate_dim=None):\n",
    "        super().__init__()\n",
    "        intermediate_dim = intermediate_dim or input_dim * 4\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, intermediate_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(intermediate_dim, output_dim),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.net:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                nn.init.normal_(module.bias, std=1e-6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_dim, config.expert_number)\n",
    "        self.expert_number = config.expert_number\n",
    "        self.top_k = config.top_k\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_dim, eps=1e-6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_norm = self.layer_norm(x)\n",
    "        router_logits = self.gate(x_norm)\n",
    "        router_probs = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "        \n",
    "        router_weights, selected_expert_indices = torch.topk(\n",
    "            router_probs,\n",
    "            self.top_k,\n",
    "            dim=-1,\n",
    "        )\n",
    "        \n",
    "        router_weights = router_weights / router_weights.sum(dim=-1, keepdim=True)\n",
    "        router_weights = router_weights.to(x.dtype)\n",
    "        \n",
    "        expert_mask = F.one_hot(\n",
    "            selected_expert_indices, \n",
    "            num_classes=self.expert_number,\n",
    "        ).permute(2, 1, 0)\n",
    "        \n",
    "        return router_logits, router_weights, selected_expert_indices, expert_mask, router_probs\n",
    "\n",
    "class SparseMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.top_k = config.top_k\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.expert_number = config.expert_number\n",
    "        \n",
    "        self.experts = nn.ModuleList([\n",
    "            BasicExpert(config.hidden_dim, config.hidden_dim) \n",
    "            for _ in range(config.expert_number)\n",
    "        ])\n",
    "        \n",
    "        self.router = MOERouter(config)\n",
    "        self.residual_weight = nn.Parameter(torch.tensor(1.0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "        hidden_states = x.view(-1, hidden_dim)\n",
    "        original_states = hidden_states\n",
    "        \n",
    "        router_logits, router_weights, _, expert_masks, router_probs = self.router(hidden_states)\n",
    "        \n",
    "        final_hidden_states = torch.zeros_like(hidden_states)\n",
    "        expert_usage = torch.zeros(self.expert_number, device=x.device)\n",
    "        \n",
    "        for expert_idx in range(self.expert_number):\n",
    "            expert_layer = self.experts[expert_idx]\n",
    "            current_expert_mask = expert_masks[expert_idx]\n",
    "            \n",
    "            router_weight_idx, token_indices = torch.where(current_expert_mask)\n",
    "            \n",
    "            if token_indices.numel() == 0:\n",
    "                continue\n",
    "                \n",
    "            expert_usage[expert_idx] = token_indices.numel()\n",
    "            \n",
    "            selected_states = hidden_states[token_indices]\n",
    "            expert_output = expert_layer(selected_states)\n",
    "            \n",
    "            weights = router_weights[token_indices, router_weight_idx].unsqueeze(1)\n",
    "            weighted_output = expert_output * weights\n",
    "            \n",
    "            final_hidden_states.index_add_(0, token_indices, weighted_output)\n",
    "        \n",
    "        final_hidden_states = final_hidden_states + self.residual_weight * original_states\n",
    "        final_hidden_states = final_hidden_states.reshape(batch_size, seq_len, hidden_dim)\n",
    "        router_logits = router_logits.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # 计算辅助损失\n",
    "        aux_loss = self._load_balancing_loss(router_probs, expert_usage)\n",
    "        \n",
    "        return final_hidden_states, router_logits, aux_loss\n",
    "    \n",
    "    def _load_balancing_loss(self, router_probs, expert_usage):\n",
    "        expert_prob = expert_usage / expert_usage.sum()\n",
    "        router_prob = router_probs.mean(dim=0)\n",
    "        load_balance_loss = self.expert_number * (expert_prob * router_prob).sum()\n",
    "        return load_balance_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb26bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
