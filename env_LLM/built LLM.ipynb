{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664a721b",
   "metadata": {},
   "source": [
    "# 从零构建一个LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9257e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数配置文件\n",
    "@dataclass\n",
    "class DeepSeekV2Config:\n",
    "    # 基础参数\n",
    "    vocab_size: int = 151936\n",
    "    hidden_size: int = 4096\n",
    "    num_hidden_layers: int = 32\n",
    "    num_attention_heads: int = 32\n",
    "    max_position_embeddings: int = 4096\n",
    "    initializer_range: float = 0.02   ###############\n",
    "    max_epochs: int = 100\n",
    "    \n",
    "    # MLA 参数\n",
    "    q_lora_rank: int = 1536\n",
    "    qk_rope_head_dim: int = 64\n",
    "    kv_lora_rank: int = 512\n",
    "    v_head_dim: int = 128\n",
    "    qk_nope_head_dim: int = 128\n",
    "    rope_theta: float = 10000.0\n",
    "    attention_bias: bool = False\n",
    "    \n",
    "    # MoE 参数\n",
    "    expert_number: int = 8\n",
    "    top_k: int = 2\n",
    "    shared_expert_number: int = 2\n",
    "    moe_load_balance_alpha: float = 0.01\n",
    "    expert_dropout: float = 0.1\n",
    "    \n",
    "    # 训练参数\n",
    "    batch_size: int = 4\n",
    "    seq_len: int = 2048\n",
    "    lr: float = 5e-5\n",
    "    weight_decay: float = 0.1   ####################\n",
    "    warmup_steps: int = 1000\n",
    "    total_steps: int = 100000\n",
    "    grad_accum_steps: int = 1   #####################\n",
    "    save_every: int = 1000\n",
    "    \n",
    "    # 其他参数\n",
    "    attention_dropout: float = 0.1\n",
    "    hidden_dropout: float = 0.1\n",
    "    tie_word_embeddings: bool = True\n",
    "    output_hidden_states: bool = False\n",
    "    output_attentions: bool = False\n",
    "    output_router_logits: bool = False\n",
    "\n",
    "    # 日志和检查点\n",
    "    log_dir: str = \"model/logs\"\n",
    "    checkpoint_dir: str = \"model/checkpoints\"\n",
    "    experiment_name: str = \"llm_experiment\"\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"保存配置到JSON文件\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(asdict(self), f, indent=4)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        \"\"\"从JSON文件加载配置\"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return cls(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd80c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "class DeepseekV2RMSNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        input_dtype = hidden_states.dtype\n",
    "        hidden_states = hidden_states.to(torch.float32)\n",
    "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "        return self.weight * hidden_states.to(input_dtype)\n",
    "    \n",
    "class DeepseekV2RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (\n",
    "            self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim)\n",
    "        )\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        # Build here to make `torch.jit.trace` work.\n",
    "        self._set_cos_sin_cache(\n",
    "            seq_len=max_position_embeddings,\n",
    "            device=self.inv_freq.device,\n",
    "            dtype=torch.get_default_dtype(),\n",
    "        )\n",
    "        self.max_seq_len_cached = max_position_embeddings\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        t = torch.arange(\n",
    "            self.max_seq_len_cached, device=device, dtype=self.inv_freq.dtype\n",
    "        )\n",
    "\n",
    "        freqs = torch.outer(t, self.inv_freq.to(t.device))\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        # x: [bs, num_attention_heads, seq_len, head_size]\n",
    "        if seq_len is not None and seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        return (\n",
    "            self.cos_cached[:seq_len].to(dtype=x.dtype),\n",
    "            self.sin_cached[:seq_len].to(dtype=x.dtype),\n",
    "        )\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "# 旋转位置编码MALA\n",
    "def apply_rotary_pos_emb_v2(q: torch.Tensor, cos, sin, position_ids, unsqueeze_dim=1):\n",
    "    cos = cos[position_ids].unsqueeze(unsqueeze_dim)\n",
    "    sin = sin[position_ids].unsqueeze(unsqueeze_dim)\n",
    "\n",
    "    b, h, s, d = q.shape\n",
    "    q = q.view(b, h, s, d // 2, 2).transpose(4, 3).reshape(b, h, s, d)\n",
    "\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    return q_embed\n",
    "\n",
    "# 学习率调度器\n",
    "class WarmupCosineScheduler:\n",
    "    def __init__(self, optimizer, warmup_steps, total_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Set initial learning rates\n",
    "        for group in self.optimizer.param_groups:\n",
    "            group.setdefault('initial_lr', group['lr'])\n",
    "        \n",
    "    def step(self):\n",
    "        self.current_step += 1\n",
    "        lr = self._get_lr()\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "    def _get_lr(self):\n",
    "        if self.current_step < self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            return self.current_step / self.warmup_steps * self.optimizer.param_groups[0]['initial_lr']\n",
    "        else:\n",
    "            # Cosine decay\n",
    "            progress = (self.current_step - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
    "            return 0.5 * (1 + math.cos(math.pi * progress)) * self.optimizer.param_groups[0]['initial_lr']\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'current_step': self.current_step,\n",
    "            'warmup_steps': self.warmup_steps,\n",
    "            'total_steps': self.total_steps,\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.current_step = state_dict['current_step']\n",
    "        self.warmup_steps = state_dict['warmup_steps']\n",
    "        self.total_steps = state_dict['total_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07a0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moe\n",
    "class FFNExpert(nn.Module):\n",
    "    def __init__(self, hidden_dim, expert_dropout):\n",
    "        super().__init__()\n",
    "        mid_dim = hidden_dim * 8 // 3\n",
    "\n",
    "        self.up = nn.Linear(hidden_dim, mid_dim, bias=False)\n",
    "        self.down = nn.Linear(mid_dim, hidden_dim, bias=False)\n",
    "        self.gate = nn.Linear(hidden_dim, mid_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(expert_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.dropout(\n",
    "            self.down(\n",
    "                F.silu(self.gate(x)) * self.up(x)\n",
    "            )\n",
    "        )\n",
    "        return output\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_size, config.expert_number)\n",
    "        self.expert_number = config.expert_number\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        router_logits = self.gate(x)\n",
    "        router_probs = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "        \n",
    "        router_weights, selected_expert_indices = torch.topk(\n",
    "            router_probs,\n",
    "            self.top_k,\n",
    "            dim=-1,\n",
    "        )\n",
    "        \n",
    "        router_weights = router_weights / router_weights.sum(dim=-1, keepdim=True)\n",
    "        router_weights = router_weights.to(x.dtype)\n",
    "        \n",
    "        expert_mask = F.one_hot(\n",
    "            selected_expert_indices, \n",
    "            num_classes=self.expert_number,\n",
    "        )\n",
    "        \n",
    "        expert_mask = expert_mask.permute(2, 1, 0)\n",
    "        \n",
    "        return router_logits, router_weights, selected_expert_indices, expert_mask, router_probs\n",
    "\n",
    "class SparseMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.top_k = config.top_k\n",
    "        self.hidden_dim = config.hidden_size\n",
    "        self.expert_number = config.expert_number\n",
    "\n",
    "        self.experts = nn.ModuleList(\n",
    "            [FFNExpert(config.hidden_size, config.expert_dropout) for _ in range(config.expert_number)]\n",
    "        )\n",
    "        self.router = MOERouter(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "        hidden_states = x.view(-1, hidden_dim)\n",
    "        \n",
    "        router_logits, router_weights, _, expert_masks, router_probs= self.router(hidden_states)\n",
    "        \n",
    "        final_hidden_states = torch.zeros(\n",
    "            (batch_size * seq_len, hidden_dim),\n",
    "            dtype=hidden_states.dtype,\n",
    "            device=hidden_states.device\n",
    "        )\n",
    "\n",
    "        for expert_idx in range(self.expert_number):\n",
    "            expert_layer = self.experts[expert_idx]\n",
    "            current_expert_mask = expert_masks[expert_idx]\n",
    "            \n",
    "            router_weight_idx, top_x = torch.where(current_expert_mask)\n",
    "            \n",
    "            current_states = hidden_states[top_x, :]\n",
    "            current_states = expert_layer(current_states)\n",
    "            \n",
    "            current_token_router_weight = router_weights[top_x, router_weight_idx].unsqueeze(-1)\n",
    "            current_hidden_states = current_states * current_token_router_weight\n",
    "            \n",
    "            final_hidden_states.index_add_(0, top_x, current_hidden_states)\n",
    "        \n",
    "        final_hidden_states = final_hidden_states.reshape(batch_size, seq_len, hidden_dim)\n",
    "        router_logits = router_logits.view(batch_size, seq_len, -1)\n",
    "\n",
    "        return final_hidden_states, router_logits, expert_masks, router_probs  \n",
    "\n",
    "\n",
    "class ShareExpertMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.moe_model = SparseMOE(config)\n",
    "        self.shared_experts = nn.ModuleList([\n",
    "            FFNExpert(config.hidden_size, config.expert_dropout) \n",
    "            for _ in range(config.shared_expert_number)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        sparse_moe_out, router_logits, expert_masks, router_probs= self.moe_model(x)\n",
    "        \n",
    "        shared_experts_out = torch.stack(\n",
    "            [expert(x) for expert in self.shared_experts], dim=0\n",
    "        ).sum(dim=0)\n",
    "        \n",
    "        return sparse_moe_out + shared_experts_out, router_logits, expert_masks, router_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e492fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLA注意力机制\n",
    "class MLAV2(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention_dropout = config.attention_dropout\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.max_position_embeddings = config.max_position_embeddings\n",
    "        self.rope_theta = config.rope_theta\n",
    "\n",
    "        self.q_lora_rank = config.q_lora_rank\n",
    "        self.qk_rope_head_dim = config.qk_rope_head_dim\n",
    "        self.kv_lora_rank = config.kv_lora_rank\n",
    "        self.v_head_dim = config.v_head_dim\n",
    "        self.qk_nope_head_dim = config.qk_nope_head_dim\n",
    "        self.q_head_dim = config.qk_nope_head_dim + config.qk_rope_head_dim\n",
    "\n",
    "        self.q_down_proj = nn.Linear(\n",
    "            self.hidden_size,\n",
    "            self.q_lora_rank,\n",
    "            bias=config.attention_bias,\n",
    "        )\n",
    "        self.q_down_layernorm = DeepseekV2RMSNorm(self.q_lora_rank)\n",
    "\n",
    "        self.q_up_proj = nn.Linear(\n",
    "            self.q_lora_rank,\n",
    "            self.num_heads * self.q_head_dim,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.kv_down_proj = nn.Linear(\n",
    "            self.hidden_size,\n",
    "            self.kv_lora_rank + self.qk_rope_head_dim,\n",
    "            bias=config.attention_bias,\n",
    "        )\n",
    "        self.kv_down_layernorm = DeepseekV2RMSNorm(self.kv_lora_rank)\n",
    "        self.kv_up_proj = nn.Linear(\n",
    "            self.kv_lora_rank,\n",
    "            self.num_heads * (self.q_head_dim - self.qk_rope_head_dim + self.v_head_dim),\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.o_proj = nn.Linear(\n",
    "            self.num_heads * self.v_head_dim,\n",
    "            self.hidden_size,\n",
    "            bias=config.attention_bias,\n",
    "        )\n",
    "\n",
    "        self.rotary_emb = DeepseekV2RotaryEmbedding(\n",
    "            self.qk_rope_head_dim,\n",
    "            self.max_position_embeddings,\n",
    "            self.rope_theta,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        compressed_kv: Optional[torch.Tensor] = None,\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "        # Query projection and split\n",
    "        q = self.q_up_proj(self.q_down_layernorm(self.q_down_proj(hidden_states)))\n",
    "        q = q.view(bsz, q_len, self.num_heads, self.q_head_dim).transpose(1, 2)\n",
    "        q_nope, q_pe = torch.split(q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1)\n",
    "\n",
    "        # Key/Value projection and split\n",
    "        if compressed_kv is None:\n",
    "            compressed_kv = self.kv_down_proj(hidden_states)  # [B, L, kv_lora_rank + qk_rope_head_dim]\n",
    "            raw_kv, k_pe = torch.split(compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)\n",
    "            # 对低秩部分做 layernorm（和你在 init 中定义的一致）\n",
    "            compressed_kv = self.kv_down_layernorm(raw_kv)  # [B, seq, kv_lora_rank]\n",
    "        else:\n",
    "            # 兼容上层传入的合并张量（假设传入的就是 kv_lora_rank + qk_rope_head_dim 的合并形式）\n",
    "            raw_kv, k_pe = torch.split(compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1)\n",
    "            compressed_kv = raw_kv  # 不在此处额外做 layernorm（假定上层缓存已处理）\n",
    "\n",
    "        kv_seq_len = compressed_kv.size(1)\n",
    "        k_pe = k_pe.view(bsz, kv_seq_len, 1, self.qk_rope_head_dim).transpose(1, 2)\n",
    "\n",
    "        # Split kv_up_proj into heads\n",
    "        kv_up_proj = self.kv_up_proj.weight.view(self.num_heads, -1, self.kv_lora_rank)\n",
    "        q_absorb = kv_up_proj[:, :self.qk_nope_head_dim, :]\n",
    "        out_absorb = kv_up_proj[:, self.qk_nope_head_dim:, :]\n",
    "\n",
    "        # Apply RoPE\n",
    "        cos, sin = self.rotary_emb(q_pe, seq_len=q_len)\n",
    "        q_pe = apply_rotary_pos_emb_v2(q_pe, cos, sin, position_ids)\n",
    "\n",
    "        # Project q_nope\n",
    "        q_nope = torch.matmul(q_nope, q_absorb)\n",
    "\n",
    "        # Attention score calculation\n",
    "        attn_weights = (\n",
    "            torch.matmul(q_pe, k_pe.mT)\n",
    "            + torch.matmul(q_nope, compressed_kv.unsqueeze(-3).mT)\n",
    "        ) / math.sqrt(self.q_head_dim)\n",
    "\n",
    "        # Apply causal mask（合并causal mask和padding mask） \n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # [bsz, 1, 1, seq_len]\n",
    "            attention_mask = attention_mask.expand(-1, self.num_heads, q_len, -1)\n",
    "            # 创建causal mask\n",
    "            causal_mask = torch.tril(\n",
    "                torch.ones((q_len, kv_seq_len), device=attn_weights.device, dtype=torch.bool)\n",
    "            )\n",
    "            causal_mask = causal_mask.view(1, 1, q_len, kv_seq_len)\n",
    "            attn_weights = attn_weights.masked_fill(~causal_mask, float(\"-inf\"))\n",
    "\n",
    "        attn_weights = nn.functional.softmax(\n",
    "            attn_weights, dim=-1, dtype=torch.float32\n",
    "        ).to(q_nope.dtype)\n",
    "\n",
    "        # Compute attention output\n",
    "        attn_output = torch.einsum(\"bhql,blc->bhqc\", attn_weights, compressed_kv)\n",
    "        attn_output = torch.matmul(attn_output, out_absorb.mT)\n",
    "\n",
    "        # Merge heads and project\n",
    "        attn_output = attn_output.transpose(1, 2).reshape(bsz, q_len, -1)\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "\n",
    "        return attn_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe30196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Pre-LN architecture\n",
    "        self.ln1 = DeepseekV2RMSNorm(config.hidden_size)\n",
    "        self.attn = MLAV2(config)\n",
    "        self.ln2 = DeepseekV2RMSNorm(config.hidden_size)\n",
    "        self.moe = ShareExpertMOE(config)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        compressed_kv: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "        output_router_logits: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        # Self Attention\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.ln1(hidden_states)\n",
    "        attn_output, attn_weights = self.attn(\n",
    "            hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            # compressed_kv=compressed_kv,\n",
    "        )\n",
    "        hidden_states = residual + self.dropout(attn_output)\n",
    "\n",
    "        # MoE FFN\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.ln2(hidden_states)\n",
    "        ffn_output, router_logits, expert_masks, router_probs = self.moe(hidden_states)  \n",
    "        hidden_states = residual + self.dropout(ffn_output)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if output_attentions:\n",
    "            outputs += (attn_weights,)\n",
    "        if output_router_logits:\n",
    "            outputs += (router_logits,)\n",
    "            \n",
    "        return outputs, expert_masks, router_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d2a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSeekV2Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        self.embed_positions = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(config) for _ in range(config.num_hidden_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = DeepseekV2RMSNorm(config.hidden_size)\n",
    "        \n",
    "        if config.tie_word_embeddings:\n",
    "            self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "            self.lm_head.weight = self.embed_tokens.weight\n",
    "        else:\n",
    "            self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "            \n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_router_logits: Optional[bool] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        output_router_logits = output_router_logits if output_router_logits is not None else self.config.output_router_logits\n",
    "\n",
    "        # Prepare inputs\n",
    "        batch_size, seq_length = input_ids.shape\n",
    "        device = input_ids.device\n",
    "        \n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(0, seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones((batch_size, seq_length), device=device)\n",
    "        \n",
    "        # Embed positions and tokens\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "        position_embeds = self.embed_positions(position_ids)\n",
    "        hidden_states = inputs_embeds + position_embeds\n",
    "        \n",
    "        # Prepare compressed KV for MLA \n",
    "        # compressed_kv = hidden_states\n",
    "        \n",
    "        # Initialize output containers\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_router_logits = () if output_router_logits else None\n",
    "        all_router_probs = () if output_router_logits else None\n",
    "        all_expert_masks = () if output_router_logits else None\n",
    "\n",
    "        # Forward through layers\n",
    "        for layer in self.layers:\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "                \n",
    "            layer_outputs, expert_masks, router_probs = layer(\n",
    "                hidden_states,\n",
    "                attention_mask=attention_mask,\n",
    "                position_ids=position_ids,\n",
    "                # compressed_kv=compressed_kv,\n",
    "                output_attentions=output_attentions,\n",
    "                output_router_logits=output_router_logits,\n",
    "            )\n",
    "            \n",
    "            hidden_states = layer_outputs[0]\n",
    "            \n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                \n",
    "            if output_router_logits and len(layer_outputs) > 2:\n",
    "                all_router_logits = all_router_logits + (layer_outputs[2],)\n",
    "                all_router_probs = all_router_probs + (layer_outputs[3],) if len(layer_outputs) > 3 else all_router_probs\n",
    "                all_expert_masks = all_expert_masks + (expert_masks,)\n",
    "        \n",
    "        hidden_states = self.norm(hidden_states)\n",
    "        \n",
    "        # Add last hidden state\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "            \n",
    "        # Compute logits\n",
    "        logits = self.lm_head(hidden_states)\n",
    "        \n",
    "        # Calculate MoE load balancing loss\n",
    "        moe_loss = 0.0\n",
    "        if output_router_logits and all_router_logits is not None:\n",
    "             for router_logits, expert_masks in zip(all_router_logits, all_expert_masks):\n",
    "                # 需要从router_logits计算router_probs\n",
    "                router_probs = F.softmax(router_logits, dim=-1, dtype=torch.float)\n",
    "                moe_loss += self._calculate_moe_loss(expert_masks, router_probs)\n",
    "        \n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"hidden_states\": all_hidden_states,\n",
    "            \"attentions\": all_self_attentions,\n",
    "            \"router_logits\": all_router_logits,\n",
    "            \"moe_loss\": moe_loss,\n",
    "        }\n",
    "    \n",
    "    def _calculate_moe_loss(self, expert_masks, router_probs):\n",
    "        \"\"\"\n",
    "        expert_masks: [num_experts, top_k, batch*seq_len]\n",
    "        router_probs: [batch*seq_len, num_experts]\n",
    "        \"\"\"\n",
    "        # importance / router_fraction\n",
    "        router_fraction = router_probs.mean(dim=0)  # [num_experts]\n",
    "\n",
    "        # load / expert_fraction\n",
    "        load = expert_masks.float().mean(dim=[1,2])  # [num_experts]\n",
    "\n",
    "        # load balancing loss\n",
    "        moe_loss = self.config.moe_load_balance_alpha * torch.sum(load * router_fraction)\n",
    "        \n",
    "        return moe_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff74d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练器\n",
    "class LLMTrainer:\n",
    "    def __init__(self, model, config, train_dataset, val_dataset=None):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        \n",
    "        # 设备设置\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # 优化器和学习率调度器\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=config.lr, \n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "        \n",
    "        self.scheduler = WarmupCosineScheduler(\n",
    "            self.optimizer, \n",
    "            config.warmup_steps, \n",
    "            config.total_steps\n",
    "        )\n",
    "        \n",
    "        # 混合精度训练\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        # TensorBoard 记录器\n",
    "        log_dir = os.path.join(config.log_dir, config.experiment_name)\n",
    "        self.writer = SummaryWriter(log_dir=log_dir)\n",
    "        \n",
    "        # 训练状态\n",
    "        self.global_step = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        input_ids, attention_mask = batch  # 解包batch\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        attention_mask = attention_mask.to(self.device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = self.model(input_ids, \n",
    "                                 attention_mask, \n",
    "                                 output_router_logits=True)\n",
    "            logits = outputs[\"logits\"]\n",
    "            \n",
    "            # 计算语言建模损失\n",
    "            shift_logits = logits[:, :-1, :].contiguous()\n",
    "            shift_labels = input_ids[:, 1:].contiguous()\n",
    "            lm_loss = F.cross_entropy(\n",
    "                shift_logits.view(-1, shift_logits.size(-1)), \n",
    "                shift_labels.view(-1)\n",
    "            )\n",
    "            \n",
    "            # 添加MoE负载均衡损失\n",
    "            moe_loss = outputs.get(\"moe_loss\", 0.0)\n",
    "            if isinstance(moe_loss, float):\n",
    "                moe_loss = torch.tensor(moe_loss, device=self.device)\n",
    "\n",
    "            total_loss = lm_loss + moe_loss\n",
    "            # 梯度累积（注意：这里不再除以grad_accum_steps）\n",
    "            # 因为MoE损失已经是整个batch的平均值\n",
    "        \n",
    "        # 反向传播\n",
    "        self.scaler.scale(total_loss).backward()\n",
    "        \n",
    "        # 记录损失到 TensorBoard\n",
    "        self.writer.add_scalar('train/lm_loss', lm_loss.item(), self.global_step)\n",
    "        self.writer.add_scalar('train/moe_loss', moe_loss.item(), self.global_step)\n",
    "        self.writer.add_scalar('train/total_loss', total_loss.item() * self.config.grad_accum_steps, self.global_step)\n",
    "        self.writer.add_scalar('train/learning_rate', self.optimizer.param_groups[0]['lr'], self.global_step)\n",
    "        \n",
    "        # 梯度累积步骤\n",
    "        if (self.global_step + 1) % self.config.grad_accum_steps == 0:\n",
    "            self.scaler.unscale_(self.optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        return {\n",
    "            \"lm_loss\": lm_loss.item(),\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"moe_loss\": moe_loss.item()\n",
    "        }\n",
    "    \n",
    "    # 在veli时候验证moe_loss\n",
    "    def validate(self):\n",
    "        if self.val_dataset is None:\n",
    "            return None\n",
    "            \n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_dataset:\n",
    "                input_ids, attention_mask = batch\n",
    "                input_ids = input_ids.to(self.device)\n",
    "                attention_mask = attention_mask.to(self.device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = self.model(input_ids, \n",
    "                                         attention_mask, \n",
    "                                         output_router_logits=True)\n",
    "                    logits = outputs[\"logits\"]\n",
    "                    \n",
    "                    # 计算LM损失\n",
    "                    shift_logits = logits[:, :-1, :].contiguous()\n",
    "                    shift_labels = input_ids[:, 1:].contiguous()\n",
    "                    loss = F.cross_entropy(\n",
    "                        shift_logits.view(-1, shift_logits.size(-1)), \n",
    "                        shift_labels.view(-1)\n",
    "                    )\n",
    "\n",
    "                    # 获取MoE损失\n",
    "                    moe_loss = outputs.get(\"moe_loss\", 0.0)\n",
    "                    if isinstance(moe_loss, float):\n",
    "                        moe_loss = torch.tensor(moe_loss, device=self.device)\n",
    "                \n",
    "                total_loss += loss.item() * input_ids.size(0)\n",
    "                total_moe_loss += moe_loss.item() * input_ids.size(0)\n",
    "                total_samples += input_ids.size(0)\n",
    "        \n",
    "        avg_lm_loss = total_loss / total_samples\n",
    "        avg_moe_loss = total_moe_loss / total_samples\n",
    "        avg_total_loss = avg_lm_loss + avg_moe_loss\n",
    "\n",
    "        self.writer.add_scalar('val/lm_loss', avg_lm_loss, self.global_step)\n",
    "        self.writer.add_scalar('val/moe_loss', avg_moe_loss, self.global_step)\n",
    "        self.writer.add_scalar('val/total_loss', avg_total_loss, self.global_step)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if avg_lm_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_checkpoint(f\"best_model.pt\")\n",
    "        \n",
    "        return avg_lm_loss\n",
    "    \n",
    "    def train(self):\n",
    "        # 数据加载器\n",
    "        def collate_fn(batch):\n",
    "            # train_dataset is dict，cloumns 'input_ids' and 'attention_mask'\n",
    "            input_ids_list = [item['input_ids'] for item in batch]\n",
    "            attention_mask_list = [item['attention_mask'] for item in batch]\n",
    "            \n",
    "            # 计算最大长度，不超过config.seq_len\n",
    "            max_len = min(max([len(ids) for ids in input_ids_list]), self.config.seq_len)\n",
    "            \n",
    "            # 初始化填充后的张量\n",
    "            padded_input_ids = torch.zeros((len(batch), max_len), dtype=torch.long)\n",
    "            padded_attention_mask = torch.zeros((len(batch), max_len), dtype=torch.long)\n",
    "            \n",
    "            for i, (ids, mask) in enumerate(zip(input_ids_list, attention_mask_list)):\n",
    "                l = min(len(ids), max_len)\n",
    "                padded_input_ids[i, :l] = ids[:l]\n",
    "                padded_attention_mask[i, :l] = mask[:l]\n",
    "            \n",
    "            return padded_input_ids, padded_attention_mask\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.config.batch_size, \n",
    "            shuffle=True, \n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        \n",
    "        # 训练循环\n",
    "        progress_bar = tqdm(total=self.config.total_steps, desc=\"Training\")\n",
    "        \n",
    "        for epoch in range(self.config.max_epochs):  # 足够大的epoch数，通过total_steps控制\n",
    "            for batch in train_loader:\n",
    "                if self.global_step >= self.config.total_steps:\n",
    "                    break\n",
    "                \n",
    "                # 训练步骤\n",
    "                metrics = self.train_step(batch)\n",
    "                \n",
    "                # 更新进度条\n",
    "                progress_bar.set_postfix({\n",
    "                    \"loss\": f\"{metrics['total_loss']:.4f}\",\n",
    "                    \"lr\": f\"{self.optimizer.param_groups[0]['lr']:.2e}\"\n",
    "                })\n",
    "                progress_bar.update(1)\n",
    "                \n",
    "                # 验证和保存检查点\n",
    "                if self.global_step % 100 == 0:\n",
    "                    val_loss = self.validate()\n",
    "                    if val_loss is not None:\n",
    "                        tqdm.write(f\"Step {self.global_step}: val_loss = {val_loss:.4f}\")\n",
    "                \n",
    "                if self.global_step % self.config.save_every == 0:\n",
    "                    self.save_checkpoint(f\"checkpoint_step_{self.global_step}.pt\")\n",
    "                \n",
    "                self.global_step += 1\n",
    "            \n",
    "            if self.global_step >= self.config.total_steps:\n",
    "                break\n",
    "        \n",
    "        progress_bar.close()\n",
    "        self.writer.close()\n",
    "        \n",
    "        # 保存最终模型\n",
    "        self.save_checkpoint(\"final_model.pt\")\n",
    "    \n",
    "    def save_checkpoint(self, filename):\n",
    "        checkpoint_path = os.path.join(self.config.checkpoint_dir, self.config.experiment_name, filename)\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'global_step': self.global_step,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'scaler_state_dict': self.scaler.state_dict(),\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'config': asdict(self.config)\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        self.global_step = checkpoint['global_step']\n",
    "        self.best_val_loss = checkpoint['best_val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc88f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSeekV2Model(\n",
       "  (embed_tokens): Embedding(151936, 256)\n",
       "  (embed_positions): Embedding(512, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (ln1): DeepseekV2RMSNorm()\n",
       "      (attn): MLAV2(\n",
       "        (q_down_proj): Linear(in_features=256, out_features=32, bias=False)\n",
       "        (q_down_layernorm): DeepseekV2RMSNorm()\n",
       "        (q_up_proj): Linear(in_features=32, out_features=192, bias=False)\n",
       "        (kv_down_proj): Linear(in_features=256, out_features=32, bias=False)\n",
       "        (kv_down_layernorm): DeepseekV2RMSNorm()\n",
       "        (kv_up_proj): Linear(in_features=16, out_features=256, bias=False)\n",
       "        (o_proj): Linear(in_features=128, out_features=256, bias=False)\n",
       "        (rotary_emb): DeepseekV2RotaryEmbedding()\n",
       "      )\n",
       "      (ln2): DeepseekV2RMSNorm()\n",
       "      (moe): ShareExpertMOE(\n",
       "        (moe_model): SparseMOE(\n",
       "          (experts): ModuleList(\n",
       "            (0-1): 2 x FFNExpert(\n",
       "              (up): Linear(in_features=256, out_features=682, bias=False)\n",
       "              (down): Linear(in_features=682, out_features=256, bias=False)\n",
       "              (gate): Linear(in_features=256, out_features=682, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (router): MOERouter(\n",
       "            (gate): Linear(in_features=256, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (shared_experts): ModuleList(\n",
       "          (0): FFNExpert(\n",
       "            (up): Linear(in_features=256, out_features=682, bias=False)\n",
       "            (down): Linear(in_features=682, out_features=256, bias=False)\n",
       "            (gate): Linear(in_features=256, out_features=682, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): DeepseekV2RMSNorm()\n",
       "  (lm_head): Linear(in_features=256, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = DeepSeekV2Config(\n",
    "    # 基础参数（极小化）\n",
    "    vocab_size = 151936,            # Qwen的词表\n",
    "    hidden_size = 256,              # embedding 维度设置 MLA里\n",
    "    num_hidden_layers = 4,          # 仅 4 层\n",
    "    num_attention_heads = 4,        # 4 个注意力头\n",
    "    max_position_embeddings = 512,\n",
    "    initializer_range = 0.02,\n",
    "    # max_epochs = 100, deafult\n",
    "\n",
    "    # MLA 参数（极小化）\n",
    "    q_lora_rank = 32,\n",
    "    qk_rope_head_dim = 16,\n",
    "    kv_lora_rank = 16,\n",
    "    v_head_dim = 32,\n",
    "    qk_nope_head_dim = 32,\n",
    "    rope_theta = 10000.0,\n",
    "    attention_bias = False,\n",
    "\n",
    "    # MoE 参数（小规模测试）\n",
    "    expert_number = 2,          # 仅 2 个专家\n",
    "    top_k = 1,                  # 每次只激活 1 个\n",
    "    shared_expert_number = 1,\n",
    "    moe_load_balance_alpha= 0.01,\n",
    "    expert_dropout = 0.1,\n",
    "\n",
    "    # 训练参数（快速实验）\n",
    "    batch_size = 2,\n",
    "    seq_len = 128,              # 短序列，快\n",
    "    lr = 1e-3,\n",
    "    weight_decay = 0.0,\n",
    "    warmup_steps = 50,\n",
    "    total_steps = 1000,         # 千步内收敛玩具任务\n",
    "    grad_accum_steps = 1,\n",
    "    save_every = 200,\n",
    "\n",
    "    # 其他参数\n",
    "    attention_dropout = 0.1,\n",
    "    hidden_dropout = 0.1,\n",
    "    tie_word_embeddings = True,\n",
    "    output_hidden_states = False,\n",
    "    output_attentions = False,\n",
    "    output_router_logits = True,\n",
    "\n",
    "    # 日志和检查点\n",
    "    log_dir = \".model/logs\",\n",
    "    checkpoint_dir= \".model/checkpoints\",\n",
    "    experiment_name = \"llm_experiment_toy\",\n",
    ")\n",
    "model = DeepSeekV2Model(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a52ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_LLM\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 50000\n",
       " }),\n",
       " {'text': '中新网3月13日电 《澳门日报》今日在头条刊发报道称，澳门一名处于停职期的海关关务监督涉嫌在某赌厅内从事“沓码”活动，2月初联同在该赌厅任职账房的妻子，利用厅主对两夫妇的信任，取走赌厅5000多万元现金及筹码，潜逃内地。厅主向澳门司警报案求助，在内地警方协助下于日前在重庆将涉案夫妇拘捕，并于12日移送司警接手调查。目前，内地警方已起回2000多万元赃款，并正追查其余赃款下落。司警现正调查案中是否有其余涉案人士在逃。涉案海关关务监督姓傅，37岁，据悉由于涉及纪律问题，目前正处于停职期。其妻姓毛，35岁，在赌厅任职账房。司警初步调查后，相信两夫妇并没有债务问题，也不是嗜赌之辈，犯案相信为一时贪念。据了解，涉案海关关务监督傅某(警司级)，一向交游广阔，早前被处以停职后，便到?仔某赌厅从事“沓码”活动。厅主对其甚为信任及器重，并招揽其妻到赌厅内任职账房。至今年2月4日，该赌厅厅主要傅某往账房支取4000多万现金筹码及1000万现金，交给另一赌厅。有人眼见半亿巨款，即起贪念，两夫妇一同带同巨款潜往内地。厅主得知被爱将“起尾注”后，即向司警报案求助。司警调查后，证实两夫妇已潜往内地，遂立即通知内地警方协助。至日前，内地警方成功在重庆将涉案傅某夫妇拘捕归案，并起回2000多万元现金及筹码，现金及筹码约各占一半。至12日上午10时，内地警方将涉案傅某夫妇移交司警接手调查。司警初步调查后，发现内地警方所检获的现金较两人偷取的1000万元现金为多，故不排除有同党协助两疑人兑换筹码，现正展开调查。至于其余2000多万元筹码的下落，司警目前正透过内地警方协助追查。'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "dataset = load_dataset(\"parquet\",\n",
    "                            data_files = \"./dataset/THUCNewsText/train-00000-of-00001-2fbb64c5d8f2434e.parquet\", \n",
    "                            split=\"train\")\n",
    "train_dataset = dataset.remove_columns(\"label\")#.select(range(2000))\n",
    "train_dataset, train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a31ea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 50000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../model/Qwen2.5-0.5B-Instruct\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 把文本转为 token ids\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"], \n",
    "        truncation=True, \n",
    "        max_length=512, \n",
    "        return_tensors=None,\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "tokenized_datasets = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\", \n",
    "    columns=[\"input_ids\", \"attention_mask\"]  # 注意是 columns 不是 colums\n",
    ")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c14c8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0数据的长度为512\n",
      "第1数据的长度为335\n",
      "第2数据的长度为512\n",
      "第3数据的长度为452\n",
      "第4数据的长度为512\n",
      "第5数据的长度为279\n",
      "第6数据的长度为512\n",
      "第7数据的长度为512\n",
      "第8数据的长度为395\n",
      "第9数据的长度为375\n",
      "第10数据的长度为510\n",
      "第11数据的长度为512\n",
      "第12数据的长度为512\n",
      "第13数据的长度为218\n",
      "第14数据的长度为363\n",
      "第15数据的长度为512\n",
      "第16数据的长度为117\n",
      "第17数据的长度为512\n",
      "第18数据的长度为213\n",
      "第19数据的长度为512\n"
     ]
    }
   ],
   "source": [
    "# 查看短数据\n",
    "for k in range(20):\n",
    "    first_sample = tokenized_datasets[k]\n",
    "    l = first_sample[\"attention_mask\"].sum()\n",
    "    if l >= len(tokenized_datasets):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"第{k}数据的长度为{l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b4bd382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token id: Column([tensor([101187,  59074, 107445,  99606,   4102,   4102, 100339,  99686, 105791,\n",
      "        117860,   9370, 102247, 113221, 108001, 102436, 100187,  26940, 113221,\n",
      "        102247,  87243,  41146,  58695,  40301, 100378,  26940, 113221, 102247,\n",
      "          5122,  58695,  25067,     23,   9754,     16,     15, 115582,  34317,\n",
      "        100261,   1773, 102033, 118621,  56006, 100625,  40301, 110167,  99438,\n",
      "         34187, 106721,   3837,  77288,  26940, 113221, 102247,   5122,  58695,\n",
      "         25067,  18493,  31905,  17447, 116196,   2073, 112308,  97907,   8545,\n",
      "          2293, 117247,   3837,  58695, 104485, 105042, 104483, 102247, 113221,\n",
      "        100378,   1773, 100131,   3837, 103037,  59879,  21887,  36587, 100629,\n",
      "        106775,  33071, 100240, 105474,  99786,  36407,  49828, 101895, 110530,\n",
      "         42192,  22226,   3837,  99555, 104143, 100636, 103950,     23, 104081,\n",
      "        115712, 104342,  53222,  99899, 105042, 100378,  14053,  26940, 113221,\n",
      "        102247,   5122,  58695,  25067, 104499, 101073, 107107,  11319, 105538,\n",
      "        102247, 113221,  34718, 104499, 114733, 101068, 107381,  11319,  18493,\n",
      "         26940, 113221, 102247,   5122,  58695,  25067, 103922,   3837,  58695,\n",
      "         36993,  32376, 108805, 105498, 102247, 113221,  34718,   9370, 106294,\n",
      "         11319, 103152,  42192,  99608,   9370, 108379, 106427, 111816, 108915,\n",
      "        110762,  96050,     23,   9754,     16,     15,   8903,   9370,  26940,\n",
      "        113221, 102247,   5122,  58695,  25067,  59975, 100261,   8903,   3837,\n",
      "        101127,  91680, 103956, 112096,   3837, 107470, 100132, 105083,     16,\n",
      "            16,  13343,   9370,  82224,  32571,   1773, 101961, 106789, 106427,\n",
      "          9370, 100625,  40301,  26940, 113221, 102247,  25067,   9370, 104574,\n",
      "         18493,  59975, 100261,   8903,  99970, 106951, 100378,   3837,  99786,\n",
      "         99851, 108419,  99879,  58695,  40301, 104377, 110762, 101994, 100684,\n",
      "         99204, 102089,   1773, 104677,  90919, 101949, 110762,  99565,  94444,\n",
      "        112939,  33447,   3837,  99879,  82224,  31843, 104143, 111531, 101043,\n",
      "         94498,  13072,   3837, 100630, 109066,  18493,  31843,   1773,  99606,\n",
      "        101923,  33447,  99879,  91111, 113221, 102247,   5122,  58695,  25067,\n",
      "        113100,   9370,  59975, 100261,  82224,  32571, 111277,  23836,  23836,\n",
      "            17,     23,  82224,   3837, 104606, 101040, 116644, 101143,  70074,\n",
      "         22704,   9370,  26940, 109374, 102689,  99974,  25067, 104489, 113100,\n",
      "         99937,  18830,     17,     23,     15,  82224,  32571,   9370, 103956,\n",
      "          3837,  20412,  24562, 106017, 110167,     16,     15,  97306,  53647,\n",
      "         26940, 113221, 102247,   5122,  58695,  25067,  18493,  59975, 100261,\n",
      "          8903,   9370, 104928,   3837,  36667, 108169, 103941,   9370, 108155,\n",
      "        105353,  99365,  34187, 101593,  75061,  32945, 100378, 100010, 105129,\n",
      "        102001,   3837, 101961,  57222,  99589, 100330,  44793,   1773,  18493,\n",
      "         26940, 113221, 102247,   5122,  58695,  25067,   9370,  59975, 100261,\n",
      "         40542,   3837, 104678,     17,     15,  32948, 104869,  96555, 108379,\n",
      "          1773, 113767,   3837, 105320,     23,  32948, 104869,  34317, 100261,\n",
      "          3837, 101963, 111970, 100104,  99191,  99305,   3837, 110568, 101919,\n",
      "        100625,   9370,  26940, 109088,  99497, 100809,  99316,     19,  25067,\n",
      "         33108,  26940, 100245,  99561,  82166,  25067,   1773, 107738, 111970,\n",
      "        100104, 100378,  74763, 100492, 111523,   2073, 102247,    854,  33108,\n",
      "          2073, 102932,  97907, 113398,   3837, 105566,  26940, 109374, 102689,\n",
      "         99974,  25067,   9370,   2073,  88683,  99974,  33590,  26940, 113221,\n",
      "        102247,   5122,  58695,  25067, 101310,  88308, 118626,  31235,  99398,\n",
      "        102382,   9370, 100104,  22704, 106290,  53647, 102130, 100161,  26232,\n",
      "         50009, 110026,  99195, 105574,   9370, 108155,   3837, 108222,  31207,\n",
      "         99747,  32945, 101961, 107455, 104711,   1773, 112757, 105217,  69249,\n",
      "         99309,  13935, 102038,  99798,  51463,   3837,  42411,  99165, 106076,\n",
      "         34718, 101047, 102990, 104534,  36993,  99519, 116084,  68536,  99314,\n",
      "         99425,  41505, 113307,   3837,  99650,  15946,  99992,  99659, 105314,\n",
      "         36993, 104377,  26288,  99425,  26288, 101168,   9370,  55807, 105791,\n",
      "          3837, 102522, 108405, 101893,   8545,   2293,  26940, 113221, 102247,\n",
      "         25067,  44991,  32948, 100036,   9370, 104534,  79478,  99601,  71268,\n",
      "         99425,  34187,   1773,  77288, 107974,  58695,   3837, 105812]), tensor([113339,  38903,    101,  99438,   3837, 104099,  99838, 101578,  18493,\n",
      "        102034,  15946, 101992,  45995, 101949, 113300, 114437, 117750,  99928,\n",
      "        100734,   3837, 103968,  26939,     23,  27442,     18,     15,  17177,\n",
      "        101081,   3837,  99838, 101578, 112991,  80565,  13343,   3837, 101347,\n",
      "        104098, 117245, 103976, 105007,   3837,  98641,  18830,  59258,     16,\n",
      "            15,  31207,   2073,  69442,  44729,  99428,  97907, 115232,  67279,\n",
      "         16530, 101401,  68536,  99723,   1773, 112351,     24,  27442,     18,\n",
      "            15,   3837,  99606,  29077,  42278, 108186,  29826,  99879,  82224,\n",
      "         13343,   3837,  99838, 101578,  99461,  80565,   3837, 102990,  33108,\n",
      "        118138, 108445, 104093,   3837, 101078, 104058, 104276,  96555, 113820,\n",
      "        100200,   1773, 104746, 101078, 106376, 102205,   3837,   8863,  13072,\n",
      "        104834,  96555,  32664, 101883, 104058,  71817, 105396,  90395, 110671,\n",
      "         11622, 100041,  18493,  65577,   1773, 101177, 107709,  99838, 101578,\n",
      "        100647,  47874,   9370, 104058, 104912,   3837,  99916, 108132, 104030,\n",
      "            23, 111394, 101081,   3837,  42411,  99879,  35568, 100299, 102205,\n",
      "        106701,  99851, 118289,   3837, 104221,  80158,  88970, 102990, 104204,\n",
      "        104271,  18493, 110084, 109547, 110648,   3837, 101889,  80158, 102654,\n",
      "         98641,  18830,  94237,     16,     15,  91455,  69442,  44729,  99428,\n",
      "          9370, 104165, 115232,  67279, 115096,   1773,  99606, 105300, 101066,\n",
      "         33447,  72064,  34187,  99838, 101578,  17447,  99774,  24156, 118138,\n",
      "          3837,  16038, 104269, 100660, 100157,   3837, 102990,   9370,  99838,\n",
      "        101578, 104678,     17,     15, 100299,   3837,    220, 111810,  24562,\n",
      "         71268, 112991, 108647,   1773, 101075, 101095, 104165, 115232,  67279,\n",
      "         99250, 104132,  34187, 110202,  17447,   3837, 101889, 102990,  33108,\n",
      "         99595, 100103,  99595, 104462, 100018,  89012, 105315, 100098,  99525,\n",
      "          3837, 104311, 108352,     20, 118330,   3837, 104150,  33447,  80158,\n",
      "         99879,  67279, 115096,   1773, 104269, 100660, 114653, 100157,   3837,\n",
      "            16,     15,  91455,  20412, 101892, 100299,   8863, 114703, 104355,\n",
      "          1773, 100888, 109801,  80565,  13343,   3837, 104269, 100660, 104584,\n",
      "         36587,   3837, 105139,  99650, 103957,  67338, 100111, 101078, 104814,\n",
      "          3837,  99879,     23,  27442,     17,     18,  17177,  13343,   3837,\n",
      "        101177, 102828,  15946,   7948, 104253, 104469,  38182, 101095, 110202,\n",
      "          3837, 106911, 101994,  97706, 115232,  99164, 101095, 104165,   9370,\n",
      "         67279,   1773, 104814, 100009, 100172,  99495,  75882, 104253, 110503,\n",
      "          3837,  77288, 104269, 100660, 104912,   3837,  99650, 100684, 100720,\n",
      "        112738,   3837, 104583, 108600, 108051,  41299, 104672,   1773, 100004,\n",
      "          3837, 118838, 104241, 100613,  99577, 101225,  58359, 104161,  14777,\n",
      "        104403,   7552, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]), tensor([111900,  93920,    245, 101428, 108956, 106799,  99222, 105521,  11319,\n",
      "        106703,  83751, 105353,  16628, 109620,  45181,  26940,  99493,  27091,\n",
      "        100773,  25067,  26939,  26940,  99445,  99582,  57218, 115768,  87243,\n",
      "        107947,  26940, 119459,  99435,  25067,   9370,  79599,  43268, 122024,\n",
      "         99425,   3837, 104727, 113473,  85361, 104699,  99581,  99901, 100156,\n",
      "         31235,  99615,  99579, 105720, 104727,   9370, 111169,   1773, 100632,\n",
      "          3837, 107912,  34204, 100378, 111653,   9370, 113473,  85361, 104699,\n",
      "          3837, 104003, 100565,  99998,  18493, 100378,  99522,   1773,  26940,\n",
      "        119459,  99435,  25067, 107855,   3837, 102361, 112096, 100378,  40301,\n",
      "          9370, 108477, 107425,   3837, 109112, 110537, 102031,   9370, 111517,\n",
      "          5373,  30709,  44991,   5373,  99218, 101694,  49567, 105521, 105167,\n",
      "         68536, 114733,  80443, 114094,   3837, 109755,  12857, 100378,   9370,\n",
      "          2073, 101052, 110589,    854, 101886, 108696,   1773,  39165,  99606,\n",
      "        115855, 113473,  85361, 104699,  30918,  33477, 100378,  26940, 119459,\n",
      "         99435,  25067,   9370, 101159, 104449,  13343,   3837,  42411, 104392,\n",
      "         99491, 106703,   3837, 100009,  51463,  36987, 104789, 100372,  22382,\n",
      "        100194,   3837,  99601, 102441, 105317, 100003,  32945,  99606, 105810,\n",
      "          3837, 113473,  85361, 104699, 106717,  42140,  36587, 104249,   3837,\n",
      "        100040,  99408, 102046,  99998,  99519, 106799,  99222, 105521,  41505,\n",
      "         80443, 113187,  67338,  24562,   3837, 100165, 116578,  42140,  36587,\n",
      "        100003,  32945,  52183, 103430, 104584,  36987, 100378,  40301,  99260,\n",
      "         53930, 105720, 101108, 101144, 101174,  99750, 116565,   3837, 104013,\n",
      "        100145,  74763,  45181, 108355,  99195,  32664, 105013, 110487,  17714,\n",
      "        103219, 100271, 103947, 101108,   3837,  99519, 102199, 104249, 100673,\n",
      "        107609, 115919,  17177,  17177,  39762,  39762,   1773, 101045,   3837,\n",
      "        102630,  14009, 119459,  99435,    527, 115127,   3837, 106779, 112662,\n",
      "        108155,  34187,  32945,  82025,  87256,  99312,   2073,  30709, 100458,\n",
      "           854,  11319, 100780,  43918,  18830,  99604, 105720,  26940, 119459,\n",
      "         99435,  87243,  99258,  55135,  79766, 104015, 116222, 105963, 119112,\n",
      "        100254, 102194,  57750, 104534,   9370, 111169,   3837, 110537, 104013,\n",
      "        102215,  86341, 100731, 102610,   5373, 100339,  99376,   5373,  82025,\n",
      "          3837,  34718, 101763, 106260,  99852, 105836,   1773,  68536, 100378,\n",
      "         40301,   9370, 104534, 107134,   3837, 111291, 105990,  31235, 100020,\n",
      "          9370, 104763,   1773,  99606, 104958,   3837, 100004, 101162,  60610,\n",
      "        100146, 107709, 105720,  26940, 119459,  99435,  25067,  15946,  19108,\n",
      "        111162,   2073,  30709, 100458,  97907,  82025,   3837,  31991,  86117,\n",
      "        104677, 100378,  40301,  15946, 111162,  70108, 108365,   3837, 102200,\n",
      "         99212,  32664, 115919, 101047, 105571,   1773, 100632,   3837, 104869,\n",
      "        100780,  99730,  99670,  35987,  99665, 119111, 100458, 105720,  15946,\n",
      "        109624,  43918,   3837, 104330, 107771, 101921,   1773,  99606, 117976,\n",
      "        113473,  85361, 104699,   3837,  82025,  36993,  32376, 100233,  11319,\n",
      "         42411,  95312, 101660,  51463,  36987,  82025,  20412, 102900,  30540,\n",
      "        104534,  15946,   3837,  99792, 117586, 104111,   3837, 113097,  33108,\n",
      "         42411,  87256,  99721,  32945, 104859,   3837, 113473,  85361, 104699,\n",
      "         33108,  82025,  59258, 104672, 114746,  99314,  27733,  74763, 112071,\n",
      "        106689,   3837, 104183,  99250, 100172,  26939, 106196, 104636, 116889,\n",
      "          3837,  52183, 103430,  24641,   3837, 104101, 101206,  18493,  17714,\n",
      "        100378,  40301, 107298, 108811, 104449,   1773,  99606, 104221,  99518,\n",
      "        115855,  82025,   9370, 110410, 100348,  99776,   3837,  99517,  51463,\n",
      "         36987,  30709,  16744,  33108, 113473, 104727, 104612, 102664, 100832,\n",
      "          1773, 100632,  56568, 104496,   9370, 100378,  26940, 119459,  99435,\n",
      "         87243, 100622, 104534,  23384,   3837,  97639,  87267, 101068,  99661,\n",
      "         34718,  23384, 101274,  32945,  52183, 103430, 103922,  97706, 104584,\n",
      "          3837,  82025, 101974, 104036,  26288,  99660,  99710, 101913,   2073,\n",
      "         30709, 100458,  33590,  36993,  99573, 101883,  99389, 105178, 106313,\n",
      "          3837,  99670,  65101, 105720, 101047,  30709, 100458,   3837,  99250,\n",
      "        100411, 100744, 100140,   2073,  99222, 107749,    854,  91956]), tensor([101718, 100170,  99837,  22441,  99606,  44636, 116627,  86227,  73562,\n",
      "         99259,  79599,  44991, 106240,  15946,   3837,  99804,  99217,  20412,\n",
      "        113959, 100034, 110640, 104111,   1773, 104746, 110488,     19,   9754,\n",
      "            16,     22,   8903,   3837,  99259,  79599,  57218,     22,     21,\n",
      "        103947,  99363,  99191,  99273,  24562,   3837,  42411, 100000,  44991,\n",
      "        106240,  15946, 100683, 105907, 102538, 100623,   1773,  77288, 101928,\n",
      "        102334, 101950,   3837,  99804,  99217,  99786, 108267,  35987,  82166,\n",
      "        106667,     17,     20,  17177,   3837, 100076,  49828,     16,     17,\n",
      "         18947, 112490,   3837, 100364, 102151,     24,     22,  56006,     23,\n",
      "            24,  47534,  99316,     22,     21,  17340,   3837, 101094,  26288,\n",
      "        107906,     16,  56006,     15, 101446,  53647,  12979,      7,  99804,\n",
      "         99217,      8, 105075, 102151, 104509, 104251,   3837,    854, 114126,\n",
      "        107582,  99804,  99217,   9370, 100689,   3837, 108038,  99709,  16530,\n",
      "         99631,  39426,  41505,  39165,  12979, 112865,  99226,  99415, 102109,\n",
      "         33071,   3837,  39165,  12979,  79072, 100926, 114945, 100844,   3837,\n",
      "        101885, 100076, 107682, 100537, 112490,  77959,  13343,   3837, 106235,\n",
      "        104286,  99593,  45356,  99491, 110248, 100769,   1773,  62244, 102151,\n",
      "         73157,  99438, 104297, 101051, 100648, 102007,   3837, 100624, 106235,\n",
      "        107138, 106947, 104528,  99959,  77959, 101135,   1773,  42411, 100644,\n",
      "         75437, 112096,  99631, 100279, 108451,   3837,  42411, 108717, 104923,\n",
      "        104629,  32945, 108038,  31991,  77144,  99631,  65676, 111042, 102203,\n",
      "        102894,   1773,  39165,  99259,  79599,  23031,     16,     24,  56006,\n",
      "            18,     16,   9370, 107906,  80565,  59975,  55502,  33447,   3837,\n",
      "        101206,  99804,  99217,  18493, 117430, 116102, 104813, 104005,  99193,\n",
      "         99546,   3837, 100125, 101467, 100894,  99727,  27641,   9370,  94443,\n",
      "        102498, 115532,   1773, 104746, 118714,   3837, 111530,  99804,  99217,\n",
      "        108795, 102151,  44063,  17177,  99572, 107166,  56137,     16,     21,\n",
      "         17177,   1773, 116910, 100146,   3837, 105177, 105695, 109904,   3837,\n",
      "        100659,  71268, 104848,  99804,  99217, 107650,  33447, 122107, 101363,\n",
      "        102210, 108953,   9370, 103181, 108679,   1773,  43288, 104700, 104098,\n",
      "        105545,  99593,  40542,  24562,   3837,  99259,  79599, 107760,  99641,\n",
      "         99191, 104156,  99079,  65278,  17340,  13343, 109794,   1773,  99212,\n",
      "         82224,  77959,   3837,  99804,  99217, 103925,  99373, 101051,     16,\n",
      "            18,  17177,   3837,  99786, 110437,  32571,  75437, 107429,  33071,\n",
      "          3837, 100636,  18493,  99796, 107330,  99713, 100554,  13343,  44063,\n",
      "        100446,  99619, 102125,  99495, 102709,  17447,   1773, 105408, 101073,\n",
      "         96050, 113959,  29767,  75437,  24562,   3837,  99754, 101194, 107455,\n",
      "        103988,   3837, 104470, 106111, 101969,  38182, 117917,   9370,  99804,\n",
      "         99217,   3837,  99165, 104309, 107566,  29258,  99451,   3837, 118556,\n",
      "        113959,   1773,  99804,  99217,  99795,  70927, 111031,  85336,  99557,\n",
      "         43288,  99663,  17340, 101911,   3837, 103955,  50404,  11622, 100675,\n",
      "         85336, 104022, 101109,   1773,  18493,  57218,  51827,  99533,  99462,\n",
      "         33108,  99273, 100222,  99295,  13935,  99770,   9370, 107126,  15946,\n",
      "          3837,  99804,  99217, 110437,  32571, 101966,  99297, 114906,  99557,\n",
      "        107777,  30534,  77959,  99583,  75437,  53647, 102119,  99883,   3837,\n",
      "        104110,  35946,  55286, 102109,   3837, 102788,  33108, 102151,  99883,\n",
      "         59743, 104330,  52801,  99916,  99726,   3837,    854,  99804,  99217,\n",
      "         36587,   1773,  68536, 105181,  99462,  46448, 103988,  36987, 100165,\n",
      "        102563, 109345, 108305,   3837,  77288,     17,     20,  17177,  33108,\n",
      "            16,     17,  18947, 112490,   3837,  43288,  20074, 116493, 100664,\n",
      "         34187,  32945, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]), tensor([ 87140,   5122,  12857, 109367,  50285, 101718, 111481,  38433,     99,\n",
      "         28951,  18830,     17,     15,  42140, 104252, 101518, 102126, 101718,\n",
      "        100415,  99837,    220, 100378,  26940,  26288,  57443,  99223,  99315,\n",
      "         25067, 102238,  34204,     23,   9754,     18,   8903, 105527, 108379,\n",
      "         96050, 106068, 100633, 112975,  17447,   3837, 116360,  35568,  99186,\n",
      "         99653,  99810,  68396,  16744,   5373, 100349,  45629,  82847,   5373,\n",
      "         12857, 109367,  50285,   5373, 101773, 100697, 100396,  49567, 104038,\n",
      "        104869,  36407,  33108,  99905, 105838,   3837,     21,   9754,     16,\n",
      "            22, 102884,  75882,  34718,   9370, 104154, 101279,  82224,  74763,\n",
      "         14777,  94444,  99349,  30918,   3837,  40542,  77419, 101656,  99431,\n",
      "         99413,  33108,  26940, 113322,  47815,  41683,  25067, 103932, 101220,\n",
      "          9370, 100235, 100095,  99258, 104869,  38342, 100261,  60726,  99259,\n",
      "          3837, 100644, 101718, 100415, 106147, 105051,  75882,  34718, 107119,\n",
      "         12857, 109367,  50285,   1773,  12857, 109367,  50285,  18493,  34718,\n",
      "         15946,  99312, 104023, 104202, 104213,   3837, 101045, 104104, 112313,\n",
      "        111770,   9370, 100250, 100464,   3837,  99258,  44934, 101169, 100117,\n",
      "        104389,  99428,  53647,  99810,  68396,  16744,  99312, 100146,  35946,\n",
      "        110436,   3837, 108965, 118925,  73218, 103976,   3837,  91777, 105391,\n",
      "        108727,  99250,  35946, 104543,   3837,  40542,  55135, 103459,  98220,\n",
      "             8,  99312,  35946, 108508,  77288,  91680,  99992,  82224, 102304,\n",
      "         99293,  32945, 104255, 104599,  18493, 100378, 100234,  15946,  99760,\n",
      "         27091,   9370,  12857, 109367,  50285, 101974,  29077, 100172, 111234,\n",
      "         99801,  99491, 102313,  96050,  34718,  82224, 100000, 115042,  99607,\n",
      "         41505,  99810,  68396,  16744, 100000,  18947, 111234, 104534,   3837,\n",
      "         97639,  32664,  99293,  13343,  36587, 102053,  57443,  99491, 102088,\n",
      "          3837,  77288, 116360, 101106,  87267,  49187, 102658,   3837, 102053,\n",
      "         57443,  33108, 116103,   9370, 109620,  99604,   3837, 104168,  99165,\n",
      "        106097,   3837, 104854,  99360,  32664,  99243, 116893, 113113, 105302,\n",
      "          1773,  97639, 104882, 111809,  99293, 111809,   9370,  99165,  38182,\n",
      "        108886,  96050, 116360,  99165, 103075, 113368,   3837, 103925,  20450,\n",
      "        104421,   9370,  16530,  45861,   3837,  77288,  99466, 106822,   9370,\n",
      "        105037,  99368, 103249,   3837, 104213,  59743,  18493,  14880,  97639,\n",
      "         99405, 100413,   3837,  85336, 103958,  99719, 106920,   1773,  18987,\n",
      "         18493, 109731,   9370, 100378,  15946, 104143,  79478, 102384,  45181,\n",
      "         64355,  48738,  26939, 101143,  96050, 100172,  99293,  13343,   9370,\n",
      "         34718,  82224,  31235,  99258,   2073, 104888,  99826,    854,  99801,\n",
      "        108257,   9370, 104461, 111346,   9370,  64754,  51575,  41505, 101075,\n",
      "         18493,  39953, 111570, 100172, 112096,  99293,   3837,  99360, 103952,\n",
      "        111346,  14880,  99898,  99312,  46944,  56652,  99328, 108207,   3837,\n",
      "         42411, 118220,  99312,  38182,  99293,   3837,  99999, 100654,  52801,\n",
      "         48738,   3837,  54926,  99314,  99724,  45995,  71268,  99314,  28726,\n",
      "          3837,  77288, 109262, 101243,   3837,  54926, 105555,  99526,  32664,\n",
      "         99243, 109823,   3837,  97639,  48738,  26939, 105925, 100909,   3837,\n",
      "        104791, 109262, 100624,  99692,  17340, 100380, 107859,  99312,  99293,\n",
      "         32945, 103925,  99312,   9370, 114292,  33108, 104023, 101063,   9370,\n",
      "        100378,   3837, 101163, 102438,  12857, 109367,  50285, 103933,   2073,\n",
      "         14777,  99676,  99428, 104023,  70927,  99565,  38182,  33590, 106773,\n",
      "        107247,  99520, 100006, 111677, 100623,  41505, 102223,  26939,  99428,\n",
      "         80158,  99565, 102199,   3837, 103982, 107994, 102396, 101482, 105593,\n",
      "         99428,   3837, 111020,  36993, 113997, 100623,   3837,  99999,  99998,\n",
      "         21894,  21894,  69442,  69442, 106784,   1773,  99565, 104023, 104892,\n",
      "        112323, 104526, 100047, 107164,   3837, 109528,  56568, 111406,  64471,\n",
      "         99308,   3837,  35946, 113208, 101893, 104313,  32945,  24562, 104986,\n",
      "         99798,  99250, 102378,  18493, 105963, 104627, 101518, 102126,  41505,\n",
      "        104888,  99826,    854, 100644,  74763, 116423,  36587,  88051, 116605,\n",
      "         26232, 104627, 100624,  99750, 101518, 102126,   3837, 100632,  99212,\n",
      "        100132, 113487,  41505, 108743, 100397,  36587,   3837, 104560])])\n"
     ]
    }
   ],
   "source": [
    "max_id = tokenized_datasets['input_ids']\n",
    "print(\"Max token id:\", max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272b7131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '一双高跟鞋是出席派对的必备，夏天的高跟凉鞋你备好了吗？今夏环保复古风大潮让木质底的高跟站到潮流最前线，搭配动物纹简直Hit到极点。在夏日尝试叠穿，一件牛仔连身裤+背心是不错的选择，怕热的话就尝试热裤款咯。建筑感觉的高跟，金属感中不乏逗趣诙谐，让人一眼就能记住，还分外清凉。又是木屐！不过这双比起鱼嘴款式显得更为清凉，咖啡色应该也会受到更多复古潮人的追捧。', 'label': 2} \n",
      " {'input_ids': tensor([108161,  44636,  99557, 102097,  20412, 102399,  99890,  32664,   9370,\n",
      "        109457,   3837, 104797,   9370,  44636,  99557, 102058, 102097,  56568,\n",
      "         56278, 104334, 101037,  11319,  36171, 100039, 101117, 111455,  99208,\n",
      "         26288, 100227,  99258, 115534,  99413,   9370,  44636,  99557,  70790,\n",
      "         26939, 106294,  31235, 114715,   3837, 104402, 101239, 100526, 101605,\n",
      "         19498,  26939,  99226,  27442,   1773,  18493, 112381, 104482, 101684,\n",
      "         99621,   3837, 101347, 100664, 102437,  54926,  95256, 102693,     10,\n",
      "         99583,  63109,  20412, 100832, 105340,   3837,  99756,  99259, 100363,\n",
      "         80158, 104482,  99259, 102693,  68153, 110789,   1773,  99893, 100681,\n",
      "          9370,  44636,  99557,   3837, 100843,  98650,  15946, 112226, 107463,\n",
      "         99594, 119977, 102191,   3837, 103973, 105065, 104077, 105712,   3837,\n",
      "         97706,  17177,  47815, 112922,   1773, 104458,  75405, 120524,   6313,\n",
      "        100632,  43288,  99493, 107957, 100655, 100457, 108756, 104392, 104652,\n",
      "        112922,   3837, 104602,  38035,  99730, 103977, 100683,  99573, 111455,\n",
      "        100227, 103947, 113248,   1773, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[170], \"\\n\", tokenized_datasets[170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "513c9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LLMTrainer(model, config, tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b336685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████| 1000/1000 [02:43<00:00,  6.13it/s, loss=10.7251, lr=0.00e+00]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a25b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
