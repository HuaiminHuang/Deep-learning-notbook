{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f3b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: peft in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: trackio in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: accelerate in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (4.56.0)\n",
      "Requirement already satisfied: trl in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (2.3.1+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from peft) (0.34.4)\n",
      "Requirement already satisfied: gradio in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from trackio) (4.44.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from trackio) (2.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from torch>=1.13.0->peft) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (4.7.0)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.28.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (6.5.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (3.9.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (3.11.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.12.11)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.17.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio->trackio) (0.35.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from gradio-client==1.3.0->gradio->trackio) (12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from anyio<5.0,>=3.0->gradio->trackio) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from anyio<5.0,>=3.0->gradio->trackio) (1.3.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from fastapi<1.0->gradio->trackio) (0.47.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio->trackio) (3.21.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from matplotlib~=3.0->gradio->trackio) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from matplotlib~=3.0->gradio->trackio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from matplotlib~=3.0->gradio->trackio) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from matplotlib~=3.0->gradio->trackio) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from matplotlib~=3.0->gradio->trackio) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from matplotlib~=3.0->gradio->trackio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from pandas->trackio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from pandas->trackio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from pydantic>=2.0->gradio->trackio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from pydantic>=2.0->gradio->trackio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from pydantic>=2.0->gradio->trackio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from typer<1.0,>=0.12->gradio->trackio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from typer<1.0,>=0.12->gradio->trackio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from typer<1.0,>=0.12->gradio->trackio) (14.1.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from httpx>=0.24.1->gradio->trackio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->trackio) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->trackio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->trackio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->trackio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->trackio) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hhm18\\miniconda3\\envs\\env_drl\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft trackio accelerate datasets transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba66178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_DRL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from accelerate import PartialState\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    PPOConfig,\n",
    "    PPOTrainer,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    ")\n",
    "from trl.trainer.utils import SIMPLE_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15427c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trl version:  0.22.2\n",
      "transformers version:  4.56.0\n",
      "torch veion:  2.3.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import trl\n",
    "import transformers\n",
    "import torch\n",
    "print(\"trl version: \", trl.__version__)\n",
    "print(\"transformers version: \", transformers.__version__)\n",
    "print(\"torch veion: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e103b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ¬åœ°æ–‡ä»¶ä½ç½®\n",
    "reward_model_path = r\"C:/Users/hhm18/Desktop/æ·±åº¦å­¦ä¹ /env_DRL/model/reward\"\n",
    "save_path = \"C:/Users/hhm18/Desktop/æ·±åº¦å­¦ä¹ /env_DRL/model\"\n",
    "base_model_path = r\"C:/Users/hhm18/Desktop/æ·±åº¦å­¦ä¹ /env_DRL/model/QwenQwen2.5-0.5B-Instruct\"\n",
    "\n",
    "# # openbayes\n",
    "# reward_model_path = r\"./home/model/reward\"\n",
    "# save_path = \"./home/model\"\n",
    "# base_model_path = r\"./home/model/Qwen2-5-0-5b-instruct\"\n",
    "\n",
    "# script_args = {\n",
    "#     \"dataset_name\": \"trl-internal-testing/descriptiveness-sentiment-trl-style\",\n",
    "#     \"dataset_config\": None,\n",
    "#     \"dataset_train_split\": \"descriptiveness\",\n",
    "# }\n",
    "\n",
    "training_args = PPOConfig(\n",
    "    output_dir=save_path,\n",
    "    learning_rate=3e-6,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,    # å°çš„batchå‡å°‘æ˜¾å­˜å ç”¨\n",
    "    total_episodes=20,               # å¯ä»¥å…ˆå°ä¸€ç‚¹\n",
    "    num_ppo_epochs=1,\n",
    "    num_mini_batches=1,\n",
    "    push_to_hub=False,\n",
    "    reward_model_path=reward_model_path,\n",
    "    sft_model_path=base_model_path,\n",
    "    logging_strategy=\"no\",             # ğŸš« å…³é—­æ—¥å¿— python 3.10ä»¥ä¸Šå¯ä»¥ä¸éœ€è¦ä¸€ä¸‹å…¼å®¹\n",
    "    # eval_strategy=\"no\",                # ğŸš« ä¸åš evalï¼ˆæƒ³åšå°±æ”¹æˆ \"steps\"ï¼‰\n",
    "    save_strategy=\"no\",                # ğŸš« ä¸è‡ªåŠ¨ä¿å­˜ checkpoint\n",
    "    report_to=\"none\",\n",
    "    logging_steps=10,                   # ğŸš« ç¦ç”¨æ‰€æœ‰é›†æˆ\n",
    ")\n",
    "\n",
    "model_args = ModelConfig(\n",
    "    model_name_or_path=base_model_path,\n",
    "    trust_remote_code=True,     # å¦‚æœæ¨¡å‹è‡ªå¸¦è‡ªå®šä¹‰ tokenizer ä»£ç \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7901f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# æ¨¡å‹å’Œ Tokenizer\n",
    "# -----------------------------\n",
    "# torch_dtype = (\n",
    "#     model_args.torch_dtype\n",
    "#     if model_args.torch_dtype in [\"auto\", None]\n",
    "#     else getattr(torch, model_args.torch_dtype)\n",
    "# )\n",
    "\n",
    "quantization_config = get_quantization_config(model_args)\n",
    "model_kwargs = dict(\n",
    "    revision=model_args.model_revision,\n",
    "    attn_implementation=model_args.attn_implementation,\n",
    "    torch_dtype=model_args.torch_dtype,\n",
    "    device_map=get_kbit_device_map() if quantization_config is not None else None,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    padding_side=\"left\",\n",
    "    trust_remote_code=model_args.trust_remote_code,\n",
    ")\n",
    "\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "if tokenizer.chat_template is None:\n",
    "    tokenizer.chat_template = SIMPLE_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051475db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C:/Users/hhm18/Desktop/æ·±åº¦å­¦ä¹ /env_DRL/model/QwenQwen2.5-0.5B-Instruct'\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(repr(base_model_path))   # åº”è¯¥æ˜¾ç¤ºåˆæ³•ç»å¯¹è·¯å¾„ï¼Œä¸èƒ½å¤š/å°‘æ–œæ \n",
    "print(os.path.exists(base_model_path))  # å¿…é¡» True\n",
    "print(os.path.isfile(os.path.join(base_model_path, \"config.json\")))  # å¿…é¡» True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e44c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '<|im_end|>',\n",
       " 'pad_token': '[PAD]',\n",
       " 'additional_special_tokens': ['<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<|object_ref_start|>',\n",
       "  '<|object_ref_end|>',\n",
       "  '<|box_start|>',\n",
       "  '<|box_end|>',\n",
       "  '<|quad_start|>',\n",
       "  '<|quad_end|>',\n",
       "  '<|vision_start|>',\n",
       "  '<|vision_end|>',\n",
       "  '<|vision_pad|>',\n",
       "  '<|image_pad|>',\n",
       "  '<|video_pad|>']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5d82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    training_args.reward_model_path,\n",
    "    trust_remote_code=model_args.trust_remote_code,\n",
    "    num_labels=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15910693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForSequenceClassification(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896, padding_idx=151645)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=896, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e93c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForSequenceClassification(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896, padding_idx=151645)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=896, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    training_args.reward_model_path,\n",
    "    trust_remote_code=model_args.trust_remote_code,\n",
    "    num_labels=1,\n",
    ")\n",
    "reward_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c8a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = AutoModelForCausalLM.from_pretrained(\n",
    "    training_args.sft_model_path,\n",
    "    trust_remote_code=model_args.trust_remote_code,\n",
    ")\n",
    "# policy.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f20f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(151936, 896)\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=896, out_features=2, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=2, out_features=896, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=896, out_features=2, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=2, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "              (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "              (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (rotary_emb): Qwen2RotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# æ­£ç¡®æ„é€  LoRA é…ç½®\n",
    "peft_config = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=4,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# åº”ç”¨åˆ°æ¨¡å‹\n",
    "policy_model = get_peft_model(policy, peft_config)\n",
    "# æ‰“å°çœ‹çœ‹\n",
    "print(policy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95e1bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(policy_model.is_gradient_checkpointing)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8009d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = get_peft_config(model_args)\n",
    "if peft_config is None:\n",
    "    ref_policy = AutoModelForCausalLM.from_pretrained(\n",
    "        training_args.sft_model_path, trust_remote_code=model_args.trust_remote_code\n",
    "    )\n",
    "else:\n",
    "    ref_policy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3db7031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0af00d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    sentiment: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 5480\n",
      "    })\n",
      "    descriptiveness: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 5425\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_path = \"C:/Users/hhm18/Desktop/æ·±åº¦å­¦ä¹ /env_DRL/data\"\n",
    "\n",
    "dataset = load_dataset(data_path, data_files={\n",
    "    \"sentiment\": \"sentiment-00000-of-00001.parquet\",\n",
    "    \"descriptiveness\": \"descriptiveness-00000-of-00001.parquet\",\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33314bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, tokenizer, text_field=\"prompt\"):\n",
    "    def tokenize(element):\n",
    "        outputs = tokenizer(\n",
    "            element[text_field],\n",
    "            padding=False,\n",
    "        )\n",
    "        return {\"input_ids\": outputs[\"input_ids\"]}\n",
    "    \n",
    "    return dataset.map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,\n",
    "    )\n",
    "\n",
    "\n",
    "# with PartialState().local_main_process_first():  #åˆ†å¸ƒå¼\n",
    "train_dataset = prepare_dataset(dataset[\"descriptiveness\"], tokenizer).select(range(100))\n",
    "eval_dataset = prepare_dataset(dataset[\"sentiment\"], tokenizer).select(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f66d5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Dataset({\n",
      "    features: ['input_ids'],\n",
      "    num_rows: 100\n",
      "}) /n 50 Dataset({\n",
      "    features: ['input_ids'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), train_dataset,\n",
    "      \"/n\", len(eval_dataset), eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33d8c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===training policy===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhm18\\miniconda3\\envs\\env_DRL\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:83: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m\n\u001b[0;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_DISABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m PPOTrainer(\n\u001b[0;32m     11\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     12\u001b[0m     processing_class\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     peft_config\u001b[38;5;241m=\u001b[39mpeft_config,\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\env_DRL\\lib\\site-packages\\trl\\trainer\\ppo_trainer.py:593\u001b[0m, in \u001b[0;36mPPOTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    590\u001b[0m     pg_clipfrac \u001b[38;5;241m=\u001b[39m masked_mean(\n\u001b[0;32m    591\u001b[0m         (pg_losses2 \u001b[38;5;241m>\u001b[39m pg_losses)\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;241m~\u001b[39mpadding_mask[micro_batch_inds]\n\u001b[0;32m    592\u001b[0m     )\n\u001b[1;32m--> 593\u001b[0m     prob_dist \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m     entropy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlogsumexp(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(prob_dist \u001b[38;5;241m*\u001b[39m logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    595\u001b[0m     approxkl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (logprobs_diff\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\env_DRL\\lib\\site-packages\\torch\\nn\\functional.py:1885\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1885\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# è®­ç»ƒ\n",
    "# -----------------------------\n",
    "\n",
    "# ğŸš« ç¦ç”¨ trackio / wandb ç­‰æ—¥å¿—\n",
    "os.environ[\"DISABLE_TRACKIO\"] = \"1\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "trainer = PPOTrainer(\n",
    "    args=training_args,\n",
    "    processing_class=tokenizer,\n",
    "    model=policy_model,\n",
    "    ref_model=ref_policy,\n",
    "    reward_model=reward_model,\n",
    "    value_model=value_model,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9701dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3436ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
